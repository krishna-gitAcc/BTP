{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2023-04-07 10:03:56.399146: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
                        "2023-04-07 10:03:56.405007: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
                        "2023-04-07 10:03:56.532413: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
                        "2023-04-07 10:03:56.534603: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
                        "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
                        "2023-04-07 10:04:01.176181: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
                    ]
                }
            ],
            "source": [
                "import matplotlib.pyplot as plt\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import tensorflow as tf\n",
                "from joblib import Parallel, delayed\n",
                "from keras.models import model_from_json\n",
                "from sklearn.preprocessing import MinMaxScaler\n",
                "from tensorflow.keras.layers import Dense\n",
                "from tensorflow.keras.models import Sequential\n",
                "\n",
                "\n",
                "import constitutive\n",
                "import displacement_solver\n",
                "import gauss_pt_coord\n",
                "import mesh_gen\n",
                "import quadrature\n",
                "import stress_gauss\n",
                "import spr_stress\n",
                "import patch_n_int_nodes\n",
                "import stress_nodes_dc\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "# # 1) Inputs\n",
                "# a) Problem parameters\n",
                "# Domain geometry\n",
                "domain_coord = np.array([[0, 0], [48, 44], [48, 60], [0, 44], [\n",
                "                        24, 22], [48, 52], [24, 52], [0, 22]])\n",
                "# Body force components\n",
                "b = np.array([[0], [0]])\n",
                "# Traction components\n",
                "q = 1/16\n",
                "T = np.array([[0, 0], [0, q], [0, 0]])\n",
                "# b) Young's modulus\n",
                "E = 1.0\n",
                "# c) Poisson's ratio\n",
                "nu = 1/3\n",
                "# d) Problem type (0 ----> plane stress, 1 -----> plane strain)\n",
                "problem_type = 0\n",
                "# e) Element used for meshing (0 ---> 4 node quadrilateral, 1 -----> 8 node quadrilateral)\n",
                "el_type_q4 = 0\n",
                "el_type_q8 = 1\n",
                "el_type_q9 = 2\n",
                "# f) No. of Gauss points required for integration\n",
                "ngp2d = 1\n",
                "ngp1d = 2\n",
                "\n",
                "# # g) Mesh sizes to be tested\n",
                "N = [5]\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
                        "(25, 8)\n",
                        "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    1.4s\n",
                        "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    1.4s finished\n",
                        "[24.364007351422813]\n"
                    ]
                }
            ],
            "source": [
                "# Q4 elements\n",
                "u_list_q4 = Parallel(n_jobs=-1, verbose=100)(\n",
                "    delayed(displacement_solver.solve_fem)(N[i], E, nu, ngp2d, ngp1d, el_type_q4, problem_type, domain_coord, b, T)\n",
                "    for i in range(len(N)))\n",
                "\n",
                "u_q4 = []\n",
                "for i in range(len(N)):\n",
                "    nx = N[i]\n",
                "    ny = N[i]\n",
                "    node_2d = np.arange((nx + 1) * (ny + 1)).reshape(nx + 1, ny + 1)\n",
                "    node = node_2d[int(ny / 2), -1]\n",
                "    dof = 2 * node + 1\n",
                "    u_q4.append(u_list_q4[i][dof])\n",
                "print(u_q4)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "ms=N[0]\n",
                "u=u_list_q4[N.index(ms)]\n",
                "nel=ms*ms  "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "C = constitutive.constitutive(E, nu, problem_type)\n",
                "#nodal coordinates\n",
                "nx = ms\n",
                "ny = ms\n",
                "el_type = 0\n",
                "mesh_obj = mesh_gen.MeshGenerator(nx, ny, domain_coord.reshape(16, 1), el_type)\n",
                "connect = mesh_obj.connectivity()\n",
                "coord = mesh_obj.coord_array()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": [
                "strs_ref=pd.read_csv('Data/ms256_ref_q9.csv')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": [
                "X = pd.read_csv('Coord/mesh_256.csv')\n",
                "Y = strs_ref;\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [],
            "source": [
                "# print(X);\n",
                "# print(Y);"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [],
            "source": [
                "X = X.loc[:, ~X.columns.str.contains('^Unnamed')]\n",
                "Y = Y.loc[:, ~Y.columns.str.contains('^Unnamed')]\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": [
                "# print(X);\n",
                "# print(Y);"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/krishna/Desktop/btp_499_code/btp_env/lib/python3.10/site-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
                        "  warnings.warn(\n"
                    ]
                }
            ],
            "source": [
                "from sklearn.preprocessing import MinMaxScaler\n",
                "scaler = MinMaxScaler()\n",
                "scaler.fit(X)\n",
                "scaled_x=scaler.transform(X)\n",
                "scaled_test=scaler.transform(coord)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 163,
            "metadata": {},
            "outputs": [],
            "source": [
                "#ANN one model in whole domain\n",
                "model1 = Sequential()\n",
                "model1.add(Dense(units=50, activation='relu'))\n",
                "model1.add(Dense(units=44, activation='relu'))\n",
                "model1.add(Dense(units=37, activation='relu'))\n",
                "model1.add(Dense(units=30, activation='relu'))\n",
                "model1.add(Dense(units=24, activation='relu'))\n",
                "model1.add(Dense(units=17, activation='relu'))\n",
                "model1.add(Dense(units=10, activation='relu'))\n",
                "model1.add(Dense(units=3, activation='relu'))\n",
                "model1.add(Dense(units=3, activation='linear'))\n",
                "model1.compile(\n",
                "    loss='mse', optimizer=tf.keras.optimizers.SGD(learning_rate=0.01))\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 164,
            "metadata": {},
            "outputs": [],
            "source": [
                "# es = tf.keras.callbacks.EarlyStopping(\n",
                "#     monitor='val_loss', mode='min', verbose=1, patience=50)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 165,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Training from different optimizer\n",
                "es = tf.keras.callbacks.EarlyStopping(\n",
                "    monitor='val_loss', mode='min', verbose=1, patience=50)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 166,
            "metadata": {},
            "outputs": [],
            "source": [
                "# np.random.seed(1)\n",
                "# history=model1.fit(x=scaled_x, y=Y, batch_size=256, epochs=500, verbose=1, validation_split=0.1,callbacks=[es])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 167,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 1/500\n",
                        "233/233 [==============================] - 13s 28ms/step - loss: 0.0029 - val_loss: 0.0130\n",
                        "Epoch 2/500\n",
                        "233/233 [==============================] - 5s 22ms/step - loss: 0.0026 - val_loss: 0.0132\n",
                        "Epoch 3/500\n",
                        "233/233 [==============================] - 5s 23ms/step - loss: 0.0025 - val_loss: 0.0130\n",
                        "Epoch 4/500\n",
                        "233/233 [==============================] - 5s 21ms/step - loss: 0.0025 - val_loss: 0.0129\n",
                        "Epoch 5/500\n",
                        "233/233 [==============================] - 5s 22ms/step - loss: 0.0025 - val_loss: 0.0129\n",
                        "Epoch 6/500\n",
                        "233/233 [==============================] - 5s 21ms/step - loss: 0.0025 - val_loss: 0.0128\n",
                        "Epoch 7/500\n",
                        "233/233 [==============================] - 5s 20ms/step - loss: 0.0024 - val_loss: 0.0127\n",
                        "Epoch 8/500\n",
                        "233/233 [==============================] - 5s 20ms/step - loss: 0.0024 - val_loss: 0.0122\n",
                        "Epoch 9/500\n",
                        "233/233 [==============================] - 5s 21ms/step - loss: 0.0023 - val_loss: 0.0120\n",
                        "Epoch 10/500\n",
                        "233/233 [==============================] - 5s 21ms/step - loss: 0.0023 - val_loss: 0.0118\n",
                        "Epoch 11/500\n",
                        "233/233 [==============================] - 5s 21ms/step - loss: 0.0022 - val_loss: 0.0115\n",
                        "Epoch 12/500\n",
                        "233/233 [==============================] - 5s 21ms/step - loss: 0.0022 - val_loss: 0.0115\n",
                        "Epoch 13/500\n",
                        "233/233 [==============================] - 5s 20ms/step - loss: 0.0021 - val_loss: 0.0113\n",
                        "Epoch 14/500\n",
                        "233/233 [==============================] - 4s 19ms/step - loss: 0.0021 - val_loss: 0.0111\n",
                        "Epoch 15/500\n",
                        "233/233 [==============================] - 5s 19ms/step - loss: 0.0021 - val_loss: 0.0109\n",
                        "Epoch 16/500\n",
                        "233/233 [==============================] - 5s 21ms/step - loss: 0.0020 - val_loss: 0.0108\n",
                        "Epoch 17/500\n",
                        "233/233 [==============================] - 5s 20ms/step - loss: 0.0020 - val_loss: 0.0107\n",
                        "Epoch 18/500\n",
                        "233/233 [==============================] - 5s 20ms/step - loss: 0.0020 - val_loss: 0.0104\n",
                        "Epoch 19/500\n",
                        "233/233 [==============================] - 5s 20ms/step - loss: 0.0019 - val_loss: 0.0103\n",
                        "Epoch 20/500\n",
                        "233/233 [==============================] - 5s 19ms/step - loss: 0.0019 - val_loss: 0.0101\n",
                        "Epoch 21/500\n",
                        "233/233 [==============================] - 5s 20ms/step - loss: 0.0018 - val_loss: 0.0099\n",
                        "Epoch 22/500\n",
                        "233/233 [==============================] - 4s 19ms/step - loss: 0.0018 - val_loss: 0.0097\n",
                        "Epoch 23/500\n",
                        "233/233 [==============================] - 5s 21ms/step - loss: 0.0017 - val_loss: 0.0095\n",
                        "Epoch 24/500\n",
                        "233/233 [==============================] - 4s 18ms/step - loss: 0.0017 - val_loss: 0.0091\n",
                        "Epoch 25/500\n",
                        "233/233 [==============================] - 5s 21ms/step - loss: 0.0016 - val_loss: 0.0090\n",
                        "Epoch 26/500\n",
                        "233/233 [==============================] - 5s 21ms/step - loss: 0.0016 - val_loss: 0.0087\n",
                        "Epoch 27/500\n",
                        "233/233 [==============================] - 5s 20ms/step - loss: 0.0016 - val_loss: 0.0085\n",
                        "Epoch 28/500\n",
                        "233/233 [==============================] - 5s 19ms/step - loss: 0.0015 - val_loss: 0.0083\n",
                        "Epoch 29/500\n",
                        "233/233 [==============================] - 4s 18ms/step - loss: 0.0015 - val_loss: 0.0080\n",
                        "Epoch 30/500\n",
                        "233/233 [==============================] - 4s 18ms/step - loss: 0.0014 - val_loss: 0.0078\n",
                        "Epoch 31/500\n",
                        "233/233 [==============================] - 4s 18ms/step - loss: 0.0014 - val_loss: 0.0077\n",
                        "Epoch 32/500\n",
                        "233/233 [==============================] - 4s 19ms/step - loss: 0.0014 - val_loss: 0.0073\n",
                        "Epoch 33/500\n",
                        "233/233 [==============================] - 4s 17ms/step - loss: 0.0013 - val_loss: 0.0072\n",
                        "Epoch 34/500\n",
                        "233/233 [==============================] - 5s 21ms/step - loss: 0.0013 - val_loss: 0.0070\n",
                        "Epoch 35/500\n",
                        "233/233 [==============================] - 4s 17ms/step - loss: 0.0013 - val_loss: 0.0068\n",
                        "Epoch 36/500\n",
                        "233/233 [==============================] - 3s 15ms/step - loss: 0.0012 - val_loss: 0.0066\n",
                        "Epoch 37/500\n",
                        "233/233 [==============================] - 4s 16ms/step - loss: 0.0012 - val_loss: 0.0064\n",
                        "Epoch 38/500\n",
                        "233/233 [==============================] - 3s 15ms/step - loss: 0.0012 - val_loss: 0.0062\n",
                        "Epoch 39/500\n",
                        "233/233 [==============================] - 4s 16ms/step - loss: 0.0011 - val_loss: 0.0061\n",
                        "Epoch 40/500\n",
                        "233/233 [==============================] - 3s 15ms/step - loss: 0.0011 - val_loss: 0.0059\n",
                        "Epoch 41/500\n",
                        "233/233 [==============================] - 4s 16ms/step - loss: 0.0011 - val_loss: 0.0057\n",
                        "Epoch 42/500\n",
                        "233/233 [==============================] - 4s 17ms/step - loss: 0.0011 - val_loss: 0.0056\n",
                        "Epoch 43/500\n",
                        "233/233 [==============================] - 5s 23ms/step - loss: 0.0010 - val_loss: 0.0054\n",
                        "Epoch 44/500\n",
                        "233/233 [==============================] - 4s 17ms/step - loss: 0.0010 - val_loss: 0.0052\n",
                        "Epoch 45/500\n",
                        "233/233 [==============================] - 4s 18ms/step - loss: 9.9083e-04 - val_loss: 0.0051\n",
                        "Epoch 46/500\n",
                        "233/233 [==============================] - 4s 17ms/step - loss: 9.7197e-04 - val_loss: 0.0050\n",
                        "Epoch 47/500\n",
                        "233/233 [==============================] - 4s 17ms/step - loss: 9.5439e-04 - val_loss: 0.0049\n",
                        "Epoch 48/500\n",
                        "233/233 [==============================] - 4s 16ms/step - loss: 9.3794e-04 - val_loss: 0.0047\n",
                        "Epoch 49/500\n",
                        "233/233 [==============================] - 4s 17ms/step - loss: 9.2250e-04 - val_loss: 0.0046\n",
                        "Epoch 50/500\n",
                        "233/233 [==============================] - 4s 17ms/step - loss: 9.0805e-04 - val_loss: 0.0045\n",
                        "Epoch 51/500\n",
                        "233/233 [==============================] - 4s 15ms/step - loss: 8.9451e-04 - val_loss: 0.0044\n",
                        "Epoch 52/500\n",
                        "233/233 [==============================] - 4s 16ms/step - loss: 8.8179e-04 - val_loss: 0.0043\n",
                        "Epoch 53/500\n",
                        "233/233 [==============================] - 4s 18ms/step - loss: 8.6973e-04 - val_loss: 0.0042\n",
                        "Epoch 54/500\n",
                        "233/233 [==============================] - 4s 17ms/step - loss: 8.5839e-04 - val_loss: 0.0041\n",
                        "Epoch 55/500\n",
                        "233/233 [==============================] - 3s 14ms/step - loss: 8.4761e-04 - val_loss: 0.0041\n",
                        "Epoch 56/500\n",
                        "233/233 [==============================] - 3s 14ms/step - loss: 8.3741e-04 - val_loss: 0.0040\n",
                        "Epoch 57/500\n",
                        "233/233 [==============================] - 4s 15ms/step - loss: 8.2774e-04 - val_loss: 0.0039\n",
                        "Epoch 58/500\n",
                        "233/233 [==============================] - 3s 15ms/step - loss: 8.1855e-04 - val_loss: 0.0038\n",
                        "Epoch 59/500\n",
                        "233/233 [==============================] - 4s 17ms/step - loss: 8.0989e-04 - val_loss: 0.0038\n",
                        "Epoch 60/500\n",
                        "233/233 [==============================] - 4s 16ms/step - loss: 8.0177e-04 - val_loss: 0.0037\n",
                        "Epoch 61/500\n",
                        "233/233 [==============================] - 3s 15ms/step - loss: 7.9412e-04 - val_loss: 0.0037\n",
                        "Epoch 62/500\n",
                        "233/233 [==============================] - 4s 15ms/step - loss: 7.8696e-04 - val_loss: 0.0036\n",
                        "Epoch 63/500\n",
                        "233/233 [==============================] - 3s 15ms/step - loss: 7.8026e-04 - val_loss: 0.0035\n",
                        "Epoch 64/500\n",
                        "233/233 [==============================] - 4s 15ms/step - loss: 7.7401e-04 - val_loss: 0.0035\n",
                        "Epoch 65/500\n",
                        "233/233 [==============================] - 3s 14ms/step - loss: 7.6815e-04 - val_loss: 0.0034\n",
                        "Epoch 66/500\n",
                        "233/233 [==============================] - 4s 16ms/step - loss: 7.6268e-04 - val_loss: 0.0034\n",
                        "Epoch 67/500\n",
                        "233/233 [==============================] - 4s 16ms/step - loss: 7.5754e-04 - val_loss: 0.0033\n",
                        "Epoch 68/500\n",
                        "233/233 [==============================] - 4s 16ms/step - loss: 7.5270e-04 - val_loss: 0.0033\n",
                        "Epoch 69/500\n",
                        "233/233 [==============================] - 3s 14ms/step - loss: 7.4808e-04 - val_loss: 0.0033\n",
                        "Epoch 70/500\n",
                        "233/233 [==============================] - 3s 15ms/step - loss: 7.4364e-04 - val_loss: 0.0032\n",
                        "Epoch 71/500\n",
                        "233/233 [==============================] - 3s 14ms/step - loss: 7.3937e-04 - val_loss: 0.0032\n",
                        "Epoch 72/500\n",
                        "233/233 [==============================] - 3s 14ms/step - loss: 7.3526e-04 - val_loss: 0.0031\n",
                        "Epoch 73/500\n",
                        "233/233 [==============================] - 4s 15ms/step - loss: 7.3128e-04 - val_loss: 0.0031\n",
                        "Epoch 74/500\n",
                        "233/233 [==============================] - 3s 14ms/step - loss: 7.2741e-04 - val_loss: 0.0031\n",
                        "Epoch 75/500\n",
                        "233/233 [==============================] - 3s 14ms/step - loss: 7.2363e-04 - val_loss: 0.0031\n",
                        "Epoch 76/500\n",
                        "233/233 [==============================] - 3s 15ms/step - loss: 7.1993e-04 - val_loss: 0.0030\n",
                        "Epoch 77/500\n",
                        "233/233 [==============================] - 3s 14ms/step - loss: 7.1632e-04 - val_loss: 0.0030\n",
                        "Epoch 78/500\n",
                        "233/233 [==============================] - 4s 16ms/step - loss: 7.1278e-04 - val_loss: 0.0030\n",
                        "Epoch 79/500\n",
                        "233/233 [==============================] - 3s 14ms/step - loss: 7.0931e-04 - val_loss: 0.0029\n",
                        "Epoch 80/500\n",
                        "233/233 [==============================] - 4s 17ms/step - loss: 7.0589e-04 - val_loss: 0.0029\n",
                        "Epoch 81/500\n",
                        "233/233 [==============================] - 4s 17ms/step - loss: 7.0253e-04 - val_loss: 0.0029\n",
                        "Epoch 82/500\n",
                        "233/233 [==============================] - 3s 15ms/step - loss: 6.9918e-04 - val_loss: 0.0029\n",
                        "Epoch 83/500\n",
                        "233/233 [==============================] - 4s 15ms/step - loss: 6.9591e-04 - val_loss: 0.0028\n",
                        "Epoch 84/500\n",
                        "233/233 [==============================] - 3s 14ms/step - loss: 6.9265e-04 - val_loss: 0.0028\n",
                        "Epoch 85/500\n",
                        "233/233 [==============================] - 4s 17ms/step - loss: 6.8940e-04 - val_loss: 0.0028\n",
                        "Epoch 86/500\n",
                        "233/233 [==============================] - 4s 17ms/step - loss: 6.8616e-04 - val_loss: 0.0028\n",
                        "Epoch 87/500\n",
                        "233/233 [==============================] - 4s 15ms/step - loss: 6.8291e-04 - val_loss: 0.0027\n",
                        "Epoch 88/500\n",
                        "233/233 [==============================] - 4s 18ms/step - loss: 6.7964e-04 - val_loss: 0.0027\n",
                        "Epoch 89/500\n",
                        "233/233 [==============================] - 4s 19ms/step - loss: 6.7637e-04 - val_loss: 0.0027\n",
                        "Epoch 90/500\n",
                        "233/233 [==============================] - 4s 17ms/step - loss: 6.7311e-04 - val_loss: 0.0027\n",
                        "Epoch 91/500\n",
                        "233/233 [==============================] - 4s 17ms/step - loss: 6.6988e-04 - val_loss: 0.0027\n",
                        "Epoch 92/500\n",
                        "233/233 [==============================] - 4s 17ms/step - loss: 6.6669e-04 - val_loss: 0.0027\n",
                        "Epoch 93/500\n",
                        "233/233 [==============================] - 4s 17ms/step - loss: 6.6360e-04 - val_loss: 0.0026\n",
                        "Epoch 94/500\n",
                        "233/233 [==============================] - 4s 16ms/step - loss: 6.6053e-04 - val_loss: 0.0026\n",
                        "Epoch 95/500\n",
                        "233/233 [==============================] - 4s 16ms/step - loss: 6.5752e-04 - val_loss: 0.0026\n",
                        "Epoch 96/500\n",
                        "233/233 [==============================] - 4s 19ms/step - loss: 6.5460e-04 - val_loss: 0.0026\n",
                        "Epoch 97/500\n",
                        "233/233 [==============================] - 4s 16ms/step - loss: 6.5172e-04 - val_loss: 0.0026\n",
                        "Epoch 98/500\n",
                        "233/233 [==============================] - 4s 17ms/step - loss: 6.4889e-04 - val_loss: 0.0026\n",
                        "Epoch 99/500\n",
                        "233/233 [==============================] - 4s 16ms/step - loss: 6.4612e-04 - val_loss: 0.0025\n",
                        "Epoch 100/500\n",
                        "233/233 [==============================] - 4s 16ms/step - loss: 6.4336e-04 - val_loss: 0.0025\n",
                        "Epoch 101/500\n",
                        "233/233 [==============================] - 4s 15ms/step - loss: 6.4067e-04 - val_loss: 0.0025\n",
                        "Epoch 102/500\n",
                        "233/233 [==============================] - 4s 17ms/step - loss: 6.3804e-04 - val_loss: 0.0025\n",
                        "Epoch 103/500\n",
                        "233/233 [==============================] - 4s 18ms/step - loss: 6.3542e-04 - val_loss: 0.0025\n",
                        "Epoch 104/500\n",
                        "233/233 [==============================] - 4s 18ms/step - loss: 6.3286e-04 - val_loss: 0.0024\n",
                        "Epoch 105/500\n",
                        "233/233 [==============================] - 4s 17ms/step - loss: 6.3031e-04 - val_loss: 0.0024\n",
                        "Epoch 106/500\n",
                        "233/233 [==============================] - 4s 16ms/step - loss: 6.2781e-04 - val_loss: 0.0024\n",
                        "Epoch 107/500\n",
                        "233/233 [==============================] - 4s 17ms/step - loss: 6.2533e-04 - val_loss: 0.0024\n",
                        "Epoch 108/500\n",
                        "233/233 [==============================] - 4s 17ms/step - loss: 6.2290e-04 - val_loss: 0.0024\n",
                        "Epoch 109/500\n",
                        "233/233 [==============================] - 3s 15ms/step - loss: 6.2049e-04 - val_loss: 0.0024\n",
                        "Epoch 110/500\n",
                        "233/233 [==============================] - 4s 16ms/step - loss: 6.1812e-04 - val_loss: 0.0023\n",
                        "Epoch 111/500\n",
                        "233/233 [==============================] - 4s 17ms/step - loss: 6.1579e-04 - val_loss: 0.0023\n",
                        "Epoch 112/500\n",
                        "233/233 [==============================] - 4s 15ms/step - loss: 6.1348e-04 - val_loss: 0.0023\n",
                        "Epoch 113/500\n",
                        "233/233 [==============================] - 4s 17ms/step - loss: 6.1119e-04 - val_loss: 0.0023\n",
                        "Epoch 114/500\n",
                        "233/233 [==============================] - 4s 16ms/step - loss: 6.0894e-04 - val_loss: 0.0023\n",
                        "Epoch 115/500\n",
                        "233/233 [==============================] - 4s 17ms/step - loss: 6.0673e-04 - val_loss: 0.0023\n",
                        "Epoch 116/500\n",
                        "233/233 [==============================] - 4s 18ms/step - loss: 6.0453e-04 - val_loss: 0.0023\n",
                        "Epoch 117/500\n",
                        "233/233 [==============================] - 5s 20ms/step - loss: 6.0237e-04 - val_loss: 0.0023\n",
                        "Epoch 118/500\n",
                        "233/233 [==============================] - 4s 16ms/step - loss: 6.0022e-04 - val_loss: 0.0022\n",
                        "Epoch 119/500\n",
                        "233/233 [==============================] - 5s 21ms/step - loss: 5.9813e-04 - val_loss: 0.0022\n",
                        "Epoch 120/500\n",
                        "233/233 [==============================] - 5s 20ms/step - loss: 5.9605e-04 - val_loss: 0.0022\n",
                        "Epoch 121/500\n",
                        "233/233 [==============================] - 5s 21ms/step - loss: 5.9400e-04 - val_loss: 0.0022\n",
                        "Epoch 122/500\n",
                        "233/233 [==============================] - 5s 21ms/step - loss: 5.9198e-04 - val_loss: 0.0022\n",
                        "Epoch 123/500\n",
                        "233/233 [==============================] - 5s 21ms/step - loss: 5.8997e-04 - val_loss: 0.0022\n",
                        "Epoch 124/500\n",
                        "233/233 [==============================] - 5s 21ms/step - loss: 5.8798e-04 - val_loss: 0.0022\n",
                        "Epoch 125/500\n",
                        "233/233 [==============================] - 5s 20ms/step - loss: 5.8602e-04 - val_loss: 0.0021\n",
                        "Epoch 126/500\n",
                        "233/233 [==============================] - 4s 19ms/step - loss: 5.8407e-04 - val_loss: 0.0021\n",
                        "Epoch 127/500\n",
                        "233/233 [==============================] - 5s 20ms/step - loss: 5.8214e-04 - val_loss: 0.0021\n",
                        "Epoch 128/500\n",
                        "233/233 [==============================] - 5s 21ms/step - loss: 5.8024e-04 - val_loss: 0.0021\n",
                        "Epoch 129/500\n",
                        "233/233 [==============================] - 5s 20ms/step - loss: 5.7835e-04 - val_loss: 0.0021\n",
                        "Epoch 130/500\n",
                        "233/233 [==============================] - 5s 20ms/step - loss: 5.7651e-04 - val_loss: 0.0021\n",
                        "Epoch 131/500\n",
                        "233/233 [==============================] - 5s 20ms/step - loss: 5.7466e-04 - val_loss: 0.0021\n",
                        "Epoch 132/500\n",
                        "233/233 [==============================] - 5s 22ms/step - loss: 5.7286e-04 - val_loss: 0.0021\n",
                        "Epoch 133/500\n",
                        "233/233 [==============================] - 6s 24ms/step - loss: 5.7104e-04 - val_loss: 0.0021\n",
                        "Epoch 134/500\n",
                        "233/233 [==============================] - 5s 23ms/step - loss: 5.6930e-04 - val_loss: 0.0021\n",
                        "Epoch 135/500\n",
                        "233/233 [==============================] - 5s 23ms/step - loss: 5.6756e-04 - val_loss: 0.0020\n",
                        "Epoch 136/500\n",
                        "233/233 [==============================] - 7s 30ms/step - loss: 5.6584e-04 - val_loss: 0.0020\n",
                        "Epoch 137/500\n",
                        "233/233 [==============================] - 6s 24ms/step - loss: 5.6414e-04 - val_loss: 0.0020\n",
                        "Epoch 138/500\n",
                        "233/233 [==============================] - 5s 20ms/step - loss: 5.6246e-04 - val_loss: 0.0020\n",
                        "Epoch 139/500\n",
                        "233/233 [==============================] - 5s 23ms/step - loss: 5.6084e-04 - val_loss: 0.0020\n",
                        "Epoch 140/500\n",
                        "233/233 [==============================] - 6s 25ms/step - loss: 5.5921e-04 - val_loss: 0.0020\n",
                        "Epoch 141/500\n",
                        "233/233 [==============================] - 6s 27ms/step - loss: 5.5761e-04 - val_loss: 0.0020\n",
                        "Epoch 142/500\n",
                        "233/233 [==============================] - 6s 26ms/step - loss: 5.5602e-04 - val_loss: 0.0020\n",
                        "Epoch 143/500\n",
                        "233/233 [==============================] - 7s 31ms/step - loss: 5.5446e-04 - val_loss: 0.0020\n",
                        "Epoch 144/500\n",
                        "233/233 [==============================] - 6s 27ms/step - loss: 5.5292e-04 - val_loss: 0.0019\n",
                        "Epoch 145/500\n",
                        "233/233 [==============================] - 5s 23ms/step - loss: 5.5140e-04 - val_loss: 0.0019\n",
                        "Epoch 146/500\n",
                        "233/233 [==============================] - 6s 27ms/step - loss: 5.4990e-04 - val_loss: 0.0019\n",
                        "Epoch 147/500\n",
                        "233/233 [==============================] - 8s 34ms/step - loss: 5.4842e-04 - val_loss: 0.0019\n",
                        "Epoch 148/500\n",
                        "233/233 [==============================] - 5s 21ms/step - loss: 5.4695e-04 - val_loss: 0.0019\n",
                        "Epoch 149/500\n",
                        "233/233 [==============================] - 4s 17ms/step - loss: 5.4549e-04 - val_loss: 0.0019\n",
                        "Epoch 150/500\n",
                        "233/233 [==============================] - 4s 17ms/step - loss: 5.4405e-04 - val_loss: 0.0019\n",
                        "Epoch 151/500\n",
                        "233/233 [==============================] - 4s 19ms/step - loss: 5.4265e-04 - val_loss: 0.0019\n",
                        "Epoch 152/500\n",
                        "233/233 [==============================] - 4s 17ms/step - loss: 5.4125e-04 - val_loss: 0.0019\n",
                        "Epoch 153/500\n",
                        "233/233 [==============================] - 4s 18ms/step - loss: 5.3986e-04 - val_loss: 0.0019\n",
                        "Epoch 154/500\n",
                        "233/233 [==============================] - 4s 19ms/step - loss: 5.3850e-04 - val_loss: 0.0018\n",
                        "Epoch 155/500\n",
                        "233/233 [==============================] - 4s 17ms/step - loss: 5.3715e-04 - val_loss: 0.0018\n",
                        "Epoch 156/500\n",
                        "233/233 [==============================] - 4s 17ms/step - loss: 5.3581e-04 - val_loss: 0.0018\n",
                        "Epoch 157/500\n",
                        "233/233 [==============================] - 4s 17ms/step - loss: 5.3448e-04 - val_loss: 0.0018\n",
                        "Epoch 158/500\n",
                        "233/233 [==============================] - 4s 17ms/step - loss: 5.3318e-04 - val_loss: 0.0018\n",
                        "Epoch 159/500\n",
                        "233/233 [==============================] - 4s 17ms/step - loss: 5.3188e-04 - val_loss: 0.0018\n",
                        "Epoch 160/500\n",
                        "233/233 [==============================] - 4s 18ms/step - loss: 5.3060e-04 - val_loss: 0.0018\n",
                        "Epoch 161/500\n",
                        "233/233 [==============================] - 4s 16ms/step - loss: 5.2933e-04 - val_loss: 0.0018\n",
                        "Epoch 162/500\n",
                        "233/233 [==============================] - 3s 14ms/step - loss: 5.2806e-04 - val_loss: 0.0018\n",
                        "Epoch 163/500\n",
                        "233/233 [==============================] - 3s 14ms/step - loss: 5.2683e-04 - val_loss: 0.0018\n",
                        "Epoch 164/500\n",
                        "233/233 [==============================] - 4s 15ms/step - loss: 5.2561e-04 - val_loss: 0.0018\n",
                        "Epoch 165/500\n",
                        "233/233 [==============================] - 3s 14ms/step - loss: 5.2440e-04 - val_loss: 0.0018\n",
                        "Epoch 166/500\n",
                        "233/233 [==============================] - 3s 14ms/step - loss: 5.2319e-04 - val_loss: 0.0018\n",
                        "Epoch 167/500\n",
                        "233/233 [==============================] - 3s 15ms/step - loss: 5.2201e-04 - val_loss: 0.0017\n",
                        "Epoch 168/500\n",
                        "233/233 [==============================] - 3s 14ms/step - loss: 5.2082e-04 - val_loss: 0.0017\n",
                        "Epoch 169/500\n",
                        "233/233 [==============================] - 4s 15ms/step - loss: 5.1967e-04 - val_loss: 0.0017\n",
                        "Epoch 170/500\n",
                        "233/233 [==============================] - 3s 13ms/step - loss: 5.1850e-04 - val_loss: 0.0017\n",
                        "Epoch 171/500\n",
                        "233/233 [==============================] - 3s 15ms/step - loss: 5.1735e-04 - val_loss: 0.0017\n",
                        "Epoch 172/500\n",
                        "233/233 [==============================] - 3s 14ms/step - loss: 5.1622e-04 - val_loss: 0.0017\n",
                        "Epoch 173/500\n",
                        "233/233 [==============================] - 3s 15ms/step - loss: 5.1509e-04 - val_loss: 0.0017\n",
                        "Epoch 174/500\n",
                        "233/233 [==============================] - 3s 14ms/step - loss: 5.1399e-04 - val_loss: 0.0017\n",
                        "Epoch 175/500\n",
                        "233/233 [==============================] - 3s 15ms/step - loss: 5.1290e-04 - val_loss: 0.0017\n",
                        "Epoch 176/500\n",
                        "233/233 [==============================] - 3s 14ms/step - loss: 5.1180e-04 - val_loss: 0.0017\n",
                        "Epoch 177/500\n",
                        "233/233 [==============================] - 4s 15ms/step - loss: 5.1072e-04 - val_loss: 0.0017\n",
                        "Epoch 178/500\n",
                        "233/233 [==============================] - 4s 16ms/step - loss: 5.0964e-04 - val_loss: 0.0017\n",
                        "Epoch 179/500\n",
                        "233/233 [==============================] - 4s 16ms/step - loss: 5.0859e-04 - val_loss: 0.0017\n",
                        "Epoch 180/500\n",
                        "233/233 [==============================] - 4s 15ms/step - loss: 5.0753e-04 - val_loss: 0.0017\n",
                        "Epoch 181/500\n",
                        "233/233 [==============================] - 3s 14ms/step - loss: 5.0649e-04 - val_loss: 0.0016\n",
                        "Epoch 182/500\n",
                        "233/233 [==============================] - 4s 15ms/step - loss: 5.0546e-04 - val_loss: 0.0016\n",
                        "Epoch 183/500\n",
                        "233/233 [==============================] - 3s 13ms/step - loss: 5.0443e-04 - val_loss: 0.0016\n",
                        "Epoch 184/500\n",
                        "233/233 [==============================] - 4s 15ms/step - loss: 5.0342e-04 - val_loss: 0.0016\n",
                        "Epoch 185/500\n",
                        "233/233 [==============================] - 3s 14ms/step - loss: 5.0240e-04 - val_loss: 0.0016\n",
                        "Epoch 186/500\n",
                        "233/233 [==============================] - 3s 15ms/step - loss: 5.0141e-04 - val_loss: 0.0016\n",
                        "Epoch 187/500\n",
                        "233/233 [==============================] - 3s 14ms/step - loss: 5.0042e-04 - val_loss: 0.0016\n",
                        "Epoch 188/500\n",
                        "233/233 [==============================] - 3s 14ms/step - loss: 4.9944e-04 - val_loss: 0.0016\n",
                        "Epoch 189/500\n",
                        "233/233 [==============================] - 3s 14ms/step - loss: 4.9846e-04 - val_loss: 0.0016\n",
                        "Epoch 190/500\n",
                        "233/233 [==============================] - 3s 15ms/step - loss: 4.9751e-04 - val_loss: 0.0016\n",
                        "Epoch 191/500\n",
                        "233/233 [==============================] - 3s 14ms/step - loss: 4.9655e-04 - val_loss: 0.0016\n",
                        "Epoch 192/500\n",
                        "233/233 [==============================] - 3s 14ms/step - loss: 4.9559e-04 - val_loss: 0.0016\n",
                        "Epoch 193/500\n",
                        "233/233 [==============================] - 3s 14ms/step - loss: 4.9465e-04 - val_loss: 0.0016\n",
                        "Epoch 194/500\n",
                        "233/233 [==============================] - 4s 15ms/step - loss: 4.9372e-04 - val_loss: 0.0016\n",
                        "Epoch 195/500\n",
                        "233/233 [==============================] - 3s 14ms/step - loss: 4.9280e-04 - val_loss: 0.0016\n",
                        "Epoch 196/500\n",
                        "233/233 [==============================] - 3s 15ms/step - loss: 4.9187e-04 - val_loss: 0.0016\n",
                        "Epoch 197/500\n",
                        "233/233 [==============================] - 3s 14ms/step - loss: 4.9096e-04 - val_loss: 0.0016\n",
                        "Epoch 198/500\n",
                        "233/233 [==============================] - 3s 15ms/step - loss: 4.9005e-04 - val_loss: 0.0015\n",
                        "Epoch 199/500\n",
                        "233/233 [==============================] - 3s 14ms/step - loss: 4.8916e-04 - val_loss: 0.0015\n",
                        "Epoch 200/500\n",
                        "233/233 [==============================] - 3s 15ms/step - loss: 4.8827e-04 - val_loss: 0.0015\n",
                        "Epoch 201/500\n",
                        "233/233 [==============================] - 3s 13ms/step - loss: 4.8737e-04 - val_loss: 0.0015\n",
                        "Epoch 202/500\n",
                        "233/233 [==============================] - 4s 15ms/step - loss: 4.8650e-04 - val_loss: 0.0015\n",
                        "Epoch 203/500\n",
                        "233/233 [==============================] - 3s 14ms/step - loss: 4.8562e-04 - val_loss: 0.0015\n",
                        "Epoch 204/500\n",
                        "233/233 [==============================] - 4s 15ms/step - loss: 4.8476e-04 - val_loss: 0.0015\n",
                        "Epoch 205/500\n",
                        "233/233 [==============================] - 3s 13ms/step - loss: 4.8388e-04 - val_loss: 0.0015\n",
                        "Epoch 206/500\n",
                        "233/233 [==============================] - 4s 16ms/step - loss: 4.8305e-04 - val_loss: 0.0015\n",
                        "Epoch 207/500\n",
                        "233/233 [==============================] - 3s 14ms/step - loss: 4.8219e-04 - val_loss: 0.0015\n",
                        "Epoch 208/500\n",
                        "233/233 [==============================] - 3s 15ms/step - loss: 4.8135e-04 - val_loss: 0.0015\n",
                        "Epoch 209/500\n",
                        "233/233 [==============================] - 3s 15ms/step - loss: 4.8051e-04 - val_loss: 0.0015\n",
                        "Epoch 210/500\n",
                        "233/233 [==============================] - 4s 15ms/step - loss: 4.7970e-04 - val_loss: 0.0015\n",
                        "Epoch 211/500\n",
                        "233/233 [==============================] - 3s 15ms/step - loss: 4.7887e-04 - val_loss: 0.0015\n",
                        "Epoch 212/500\n",
                        "233/233 [==============================] - 3s 15ms/step - loss: 4.7805e-04 - val_loss: 0.0015\n",
                        "Epoch 213/500\n",
                        "233/233 [==============================] - 4s 15ms/step - loss: 4.7724e-04 - val_loss: 0.0015\n",
                        "Epoch 214/500\n",
                        "233/233 [==============================] - 3s 14ms/step - loss: 4.7644e-04 - val_loss: 0.0015\n",
                        "Epoch 215/500\n",
                        "233/233 [==============================] - 4s 15ms/step - loss: 4.7563e-04 - val_loss: 0.0015\n",
                        "Epoch 216/500\n",
                        "233/233 [==============================] - 3s 14ms/step - loss: 4.7484e-04 - val_loss: 0.0015\n",
                        "Epoch 217/500\n",
                        "233/233 [==============================] - 4s 15ms/step - loss: 4.7404e-04 - val_loss: 0.0015\n",
                        "Epoch 218/500\n",
                        "233/233 [==============================] - 3s 13ms/step - loss: 4.7326e-04 - val_loss: 0.0014\n",
                        "Epoch 219/500\n",
                        "233/233 [==============================] - 4s 15ms/step - loss: 4.7249e-04 - val_loss: 0.0014\n",
                        "Epoch 220/500\n",
                        "233/233 [==============================] - 3s 14ms/step - loss: 4.7170e-04 - val_loss: 0.0014\n",
                        "Epoch 221/500\n",
                        "233/233 [==============================] - 4s 17ms/step - loss: 4.7095e-04 - val_loss: 0.0014\n",
                        "Epoch 222/500\n",
                        "233/233 [==============================] - 5s 20ms/step - loss: 4.7018e-04 - val_loss: 0.0014\n",
                        "Epoch 223/500\n",
                        "233/233 [==============================] - 6s 26ms/step - loss: 4.6942e-04 - val_loss: 0.0014\n",
                        "Epoch 224/500\n",
                        "233/233 [==============================] - 4s 18ms/step - loss: 4.6866e-04 - val_loss: 0.0014\n",
                        "Epoch 225/500\n",
                        "233/233 [==============================] - 4s 16ms/step - loss: 4.6791e-04 - val_loss: 0.0014\n",
                        "Epoch 226/500\n",
                        "233/233 [==============================] - 4s 18ms/step - loss: 4.6717e-04 - val_loss: 0.0014\n",
                        "Epoch 227/500\n",
                        "233/233 [==============================] - 4s 15ms/step - loss: 4.6643e-04 - val_loss: 0.0014\n",
                        "Epoch 228/500\n",
                        "233/233 [==============================] - 4s 18ms/step - loss: 4.6569e-04 - val_loss: 0.0014\n",
                        "Epoch 229/500\n",
                        "233/233 [==============================] - 4s 18ms/step - loss: 4.6495e-04 - val_loss: 0.0014\n",
                        "Epoch 230/500\n",
                        "233/233 [==============================] - 4s 16ms/step - loss: 4.6424e-04 - val_loss: 0.0014\n",
                        "Epoch 231/500\n",
                        "233/233 [==============================] - 4s 17ms/step - loss: 4.6351e-04 - val_loss: 0.0014\n",
                        "Epoch 232/500\n",
                        "233/233 [==============================] - 4s 18ms/step - loss: 4.6278e-04 - val_loss: 0.0014\n",
                        "Epoch 233/500\n",
                        "233/233 [==============================] - 5s 22ms/step - loss: 4.6206e-04 - val_loss: 0.0014\n",
                        "Epoch 234/500\n",
                        "233/233 [==============================] - 4s 18ms/step - loss: 4.6136e-04 - val_loss: 0.0014\n",
                        "Epoch 235/500\n",
                        "233/233 [==============================] - 4s 17ms/step - loss: 4.6063e-04 - val_loss: 0.0014\n",
                        "Epoch 236/500\n",
                        "233/233 [==============================] - 5s 20ms/step - loss: 4.5994e-04 - val_loss: 0.0014\n",
                        "Epoch 237/500\n",
                        "233/233 [==============================] - 4s 17ms/step - loss: 4.5925e-04 - val_loss: 0.0014\n",
                        "Epoch 238/500\n",
                        "233/233 [==============================] - 4s 19ms/step - loss: 4.5855e-04 - val_loss: 0.0014\n",
                        "Epoch 239/500\n",
                        "233/233 [==============================] - 4s 18ms/step - loss: 4.5786e-04 - val_loss: 0.0014\n",
                        "Epoch 240/500\n",
                        "233/233 [==============================] - 4s 18ms/step - loss: 4.5717e-04 - val_loss: 0.0014\n",
                        "Epoch 241/500\n",
                        "233/233 [==============================] - 4s 18ms/step - loss: 4.5649e-04 - val_loss: 0.0014\n",
                        "Epoch 242/500\n",
                        "233/233 [==============================] - 5s 21ms/step - loss: 4.5581e-04 - val_loss: 0.0014\n",
                        "Epoch 243/500\n",
                        "233/233 [==============================] - 5s 21ms/step - loss: 4.5512e-04 - val_loss: 0.0014\n",
                        "Epoch 244/500\n",
                        "233/233 [==============================] - 4s 18ms/step - loss: 4.5446e-04 - val_loss: 0.0014\n",
                        "Epoch 245/500\n",
                        "233/233 [==============================] - 4s 17ms/step - loss: 4.5379e-04 - val_loss: 0.0013\n",
                        "Epoch 246/500\n",
                        "233/233 [==============================] - 4s 17ms/step - loss: 4.5313e-04 - val_loss: 0.0013\n",
                        "Epoch 247/500\n",
                        "233/233 [==============================] - 5s 19ms/step - loss: 4.5246e-04 - val_loss: 0.0013\n",
                        "Epoch 248/500\n",
                        "233/233 [==============================] - 5s 20ms/step - loss: 4.5180e-04 - val_loss: 0.0013\n",
                        "Epoch 249/500\n",
                        "233/233 [==============================] - 4s 19ms/step - loss: 4.5115e-04 - val_loss: 0.0013\n",
                        "Epoch 250/500\n",
                        "233/233 [==============================] - 5s 19ms/step - loss: 4.5049e-04 - val_loss: 0.0013\n",
                        "Epoch 251/500\n",
                        "233/233 [==============================] - 5s 20ms/step - loss: 4.4983e-04 - val_loss: 0.0013\n",
                        "Epoch 252/500\n",
                        "233/233 [==============================] - 5s 20ms/step - loss: 4.4918e-04 - val_loss: 0.0013\n",
                        "Epoch 253/500\n",
                        "233/233 [==============================] - 4s 19ms/step - loss: 4.4854e-04 - val_loss: 0.0013\n",
                        "Epoch 254/500\n",
                        "233/233 [==============================] - 5s 20ms/step - loss: 4.4791e-04 - val_loss: 0.0013\n",
                        "Epoch 255/500\n",
                        "233/233 [==============================] - 4s 19ms/step - loss: 4.4725e-04 - val_loss: 0.0013\n",
                        "Epoch 256/500\n",
                        "233/233 [==============================] - 5s 20ms/step - loss: 4.4663e-04 - val_loss: 0.0013\n",
                        "Epoch 257/500\n",
                        "233/233 [==============================] - 5s 21ms/step - loss: 4.4600e-04 - val_loss: 0.0013\n",
                        "Epoch 258/500\n",
                        "233/233 [==============================] - 5s 20ms/step - loss: 4.4536e-04 - val_loss: 0.0013\n",
                        "Epoch 259/500\n",
                        "233/233 [==============================] - 5s 20ms/step - loss: 4.4474e-04 - val_loss: 0.0013\n",
                        "Epoch 260/500\n",
                        "233/233 [==============================] - 5s 20ms/step - loss: 4.4411e-04 - val_loss: 0.0013\n",
                        "Epoch 261/500\n",
                        "233/233 [==============================] - 5s 20ms/step - loss: 4.4349e-04 - val_loss: 0.0013\n",
                        "Epoch 262/500\n",
                        "233/233 [==============================] - 5s 20ms/step - loss: 4.4287e-04 - val_loss: 0.0013\n",
                        "Epoch 263/500\n",
                        "233/233 [==============================] - 5s 20ms/step - loss: 4.4226e-04 - val_loss: 0.0013\n",
                        "Epoch 264/500\n",
                        "233/233 [==============================] - 4s 19ms/step - loss: 4.4165e-04 - val_loss: 0.0013\n",
                        "Epoch 265/500\n",
                        "233/233 [==============================] - 5s 19ms/step - loss: 4.4103e-04 - val_loss: 0.0013\n",
                        "Epoch 266/500\n",
                        "233/233 [==============================] - 4s 19ms/step - loss: 4.4042e-04 - val_loss: 0.0013\n",
                        "Epoch 267/500\n",
                        "233/233 [==============================] - 4s 19ms/step - loss: 4.3980e-04 - val_loss: 0.0013\n",
                        "Epoch 268/500\n",
                        "233/233 [==============================] - 5s 20ms/step - loss: 4.3920e-04 - val_loss: 0.0013\n",
                        "Epoch 269/500\n",
                        "233/233 [==============================] - 5s 20ms/step - loss: 4.3861e-04 - val_loss: 0.0013\n",
                        "Epoch 270/500\n",
                        "233/233 [==============================] - 4s 19ms/step - loss: 4.3800e-04 - val_loss: 0.0013\n",
                        "Epoch 271/500\n",
                        "233/233 [==============================] - 5s 20ms/step - loss: 4.3740e-04 - val_loss: 0.0013\n",
                        "Epoch 272/500\n",
                        "233/233 [==============================] - 5s 20ms/step - loss: 4.3681e-04 - val_loss: 0.0013\n",
                        "Epoch 273/500\n",
                        "233/233 [==============================] - 5s 19ms/step - loss: 4.3622e-04 - val_loss: 0.0013\n",
                        "Epoch 274/500\n",
                        "233/233 [==============================] - 5s 22ms/step - loss: 4.3561e-04 - val_loss: 0.0013\n",
                        "Epoch 275/500\n",
                        "233/233 [==============================] - 4s 19ms/step - loss: 4.3503e-04 - val_loss: 0.0013\n",
                        "Epoch 276/500\n",
                        "233/233 [==============================] - 5s 20ms/step - loss: 4.3444e-04 - val_loss: 0.0013\n",
                        "Epoch 277/500\n",
                        "233/233 [==============================] - 5s 21ms/step - loss: 4.3386e-04 - val_loss: 0.0013\n",
                        "Epoch 278/500\n",
                        "233/233 [==============================] - 5s 23ms/step - loss: 4.3327e-04 - val_loss: 0.0013\n",
                        "Epoch 279/500\n",
                        "233/233 [==============================] - 6s 24ms/step - loss: 4.3269e-04 - val_loss: 0.0013\n",
                        "Epoch 280/500\n",
                        "233/233 [==============================] - 6s 25ms/step - loss: 4.3210e-04 - val_loss: 0.0013\n",
                        "Epoch 281/500\n",
                        "233/233 [==============================] - 5s 20ms/step - loss: 4.3152e-04 - val_loss: 0.0013\n",
                        "Epoch 282/500\n",
                        "233/233 [==============================] - 5s 19ms/step - loss: 4.3095e-04 - val_loss: 0.0012\n",
                        "Epoch 283/500\n",
                        "233/233 [==============================] - 4s 19ms/step - loss: 4.3037e-04 - val_loss: 0.0013\n",
                        "Epoch 284/500\n",
                        "233/233 [==============================] - 4s 19ms/step - loss: 4.2979e-04 - val_loss: 0.0012\n",
                        "Epoch 285/500\n",
                        "233/233 [==============================] - 5s 21ms/step - loss: 4.2922e-04 - val_loss: 0.0012\n",
                        "Epoch 286/500\n",
                        "233/233 [==============================] - 6s 24ms/step - loss: 4.2865e-04 - val_loss: 0.0012\n",
                        "Epoch 287/500\n",
                        "233/233 [==============================] - 6s 25ms/step - loss: 4.2808e-04 - val_loss: 0.0012\n",
                        "Epoch 288/500\n",
                        "233/233 [==============================] - 6s 26ms/step - loss: 4.2752e-04 - val_loss: 0.0012\n",
                        "Epoch 289/500\n",
                        "233/233 [==============================] - 6s 25ms/step - loss: 4.2695e-04 - val_loss: 0.0012\n",
                        "Epoch 290/500\n",
                        "233/233 [==============================] - 6s 26ms/step - loss: 4.2638e-04 - val_loss: 0.0012\n",
                        "Epoch 291/500\n",
                        "233/233 [==============================] - 5s 23ms/step - loss: 4.2582e-04 - val_loss: 0.0012\n",
                        "Epoch 292/500\n",
                        "233/233 [==============================] - 5s 22ms/step - loss: 4.2526e-04 - val_loss: 0.0012\n",
                        "Epoch 293/500\n",
                        "233/233 [==============================] - 5s 21ms/step - loss: 4.2470e-04 - val_loss: 0.0012\n",
                        "Epoch 294/500\n",
                        "233/233 [==============================] - 5s 22ms/step - loss: 4.2414e-04 - val_loss: 0.0012\n",
                        "Epoch 295/500\n",
                        "233/233 [==============================] - 5s 22ms/step - loss: 4.2358e-04 - val_loss: 0.0012\n",
                        "Epoch 296/500\n",
                        "233/233 [==============================] - 5s 22ms/step - loss: 4.2302e-04 - val_loss: 0.0012\n",
                        "Epoch 297/500\n",
                        "233/233 [==============================] - 5s 20ms/step - loss: 4.2247e-04 - val_loss: 0.0012\n",
                        "Epoch 298/500\n",
                        "233/233 [==============================] - 5s 20ms/step - loss: 4.2191e-04 - val_loss: 0.0012\n",
                        "Epoch 299/500\n",
                        "233/233 [==============================] - 5s 20ms/step - loss: 4.2137e-04 - val_loss: 0.0012\n",
                        "Epoch 300/500\n",
                        "233/233 [==============================] - 5s 20ms/step - loss: 4.2082e-04 - val_loss: 0.0012\n",
                        "Epoch 301/500\n",
                        "233/233 [==============================] - 5s 20ms/step - loss: 4.2026e-04 - val_loss: 0.0012\n",
                        "Epoch 302/500\n",
                        "233/233 [==============================] - 5s 20ms/step - loss: 4.1972e-04 - val_loss: 0.0012\n",
                        "Epoch 303/500\n",
                        "233/233 [==============================] - 5s 20ms/step - loss: 4.1917e-04 - val_loss: 0.0012\n",
                        "Epoch 304/500\n",
                        "233/233 [==============================] - 5s 20ms/step - loss: 4.1861e-04 - val_loss: 0.0012\n",
                        "Epoch 305/500\n",
                        "233/233 [==============================] - 5s 20ms/step - loss: 4.1807e-04 - val_loss: 0.0012\n",
                        "Epoch 306/500\n",
                        "233/233 [==============================] - 5s 20ms/step - loss: 4.1752e-04 - val_loss: 0.0012\n",
                        "Epoch 307/500\n",
                        "233/233 [==============================] - 5s 21ms/step - loss: 4.1699e-04 - val_loss: 0.0012\n",
                        "Epoch 308/500\n",
                        "233/233 [==============================] - 7s 29ms/step - loss: 4.1641e-04 - val_loss: 0.0012\n",
                        "Epoch 309/500\n",
                        "233/233 [==============================] - 5s 23ms/step - loss: 4.1590e-04 - val_loss: 0.0012\n",
                        "Epoch 310/500\n",
                        "233/233 [==============================] - 5s 23ms/step - loss: 4.1535e-04 - val_loss: 0.0012\n",
                        "Epoch 311/500\n",
                        "233/233 [==============================] - 6s 26ms/step - loss: 4.1481e-04 - val_loss: 0.0012\n",
                        "Epoch 312/500\n",
                        "233/233 [==============================] - 6s 24ms/step - loss: 4.1427e-04 - val_loss: 0.0012\n",
                        "Epoch 313/500\n",
                        "233/233 [==============================] - 5s 21ms/step - loss: 4.1374e-04 - val_loss: 0.0012\n",
                        "Epoch 314/500\n",
                        "233/233 [==============================] - 5s 20ms/step - loss: 4.1320e-04 - val_loss: 0.0012\n",
                        "Epoch 315/500\n",
                        "233/233 [==============================] - 5s 20ms/step - loss: 4.1266e-04 - val_loss: 0.0012\n",
                        "Epoch 316/500\n",
                        "233/233 [==============================] - 5s 20ms/step - loss: 4.1212e-04 - val_loss: 0.0012\n",
                        "Epoch 317/500\n",
                        "233/233 [==============================] - 4s 19ms/step - loss: 4.1159e-04 - val_loss: 0.0012\n",
                        "Epoch 318/500\n",
                        "233/233 [==============================] - 5s 20ms/step - loss: 4.1105e-04 - val_loss: 0.0012\n",
                        "Epoch 319/500\n",
                        "233/233 [==============================] - 4s 19ms/step - loss: 4.1052e-04 - val_loss: 0.0012\n",
                        "Epoch 320/500\n",
                        "233/233 [==============================] - 5s 20ms/step - loss: 4.0999e-04 - val_loss: 0.0012\n",
                        "Epoch 321/500\n",
                        "233/233 [==============================] - 4s 19ms/step - loss: 4.0944e-04 - val_loss: 0.0012\n",
                        "Epoch 322/500\n",
                        "233/233 [==============================] - 5s 20ms/step - loss: 4.0892e-04 - val_loss: 0.0012\n",
                        "Epoch 323/500\n",
                        "233/233 [==============================] - 4s 19ms/step - loss: 4.0839e-04 - val_loss: 0.0012\n",
                        "Epoch 324/500\n",
                        "233/233 [==============================] - 5s 20ms/step - loss: 4.0786e-04 - val_loss: 0.0012\n",
                        "Epoch 325/500\n",
                        "233/233 [==============================] - 4s 19ms/step - loss: 4.0732e-04 - val_loss: 0.0012\n",
                        "Epoch 326/500\n",
                        "233/233 [==============================] - 5s 20ms/step - loss: 4.0678e-04 - val_loss: 0.0012\n",
                        "Epoch 327/500\n",
                        "233/233 [==============================] - 5s 21ms/step - loss: 4.0626e-04 - val_loss: 0.0012\n",
                        "Epoch 328/500\n",
                        "233/233 [==============================] - 6s 24ms/step - loss: 4.0574e-04 - val_loss: 0.0012\n",
                        "Epoch 329/500\n",
                        "233/233 [==============================] - 9s 37ms/step - loss: 4.0520e-04 - val_loss: 0.0012\n",
                        "Epoch 330/500\n",
                        "233/233 [==============================] - 8s 33ms/step - loss: 4.0467e-04 - val_loss: 0.0012\n",
                        "Epoch 331/500\n",
                        "233/233 [==============================] - 7s 31ms/step - loss: 4.0414e-04 - val_loss: 0.0012\n",
                        "Epoch 332/500\n",
                        "233/233 [==============================] - 7s 30ms/step - loss: 4.0362e-04 - val_loss: 0.0012\n",
                        "Epoch 333/500\n",
                        "233/233 [==============================] - 4s 18ms/step - loss: 4.0309e-04 - val_loss: 0.0012\n",
                        "Epoch 334/500\n",
                        "233/233 [==============================] - 4s 19ms/step - loss: 4.0256e-04 - val_loss: 0.0012\n",
                        "Epoch 335/500\n",
                        "233/233 [==============================] - 5s 20ms/step - loss: 4.0203e-04 - val_loss: 0.0012\n",
                        "Epoch 336/500\n",
                        "233/233 [==============================] - 5s 21ms/step - loss: 4.0151e-04 - val_loss: 0.0012\n",
                        "Epoch 337/500\n",
                        "233/233 [==============================] - 8s 33ms/step - loss: 4.0098e-04 - val_loss: 0.0012\n",
                        "Epoch 338/500\n",
                        "233/233 [==============================] - 6s 25ms/step - loss: 4.0045e-04 - val_loss: 0.0011\n",
                        "Epoch 339/500\n",
                        "233/233 [==============================] - 5s 20ms/step - loss: 3.9993e-04 - val_loss: 0.0012\n",
                        "Epoch 340/500\n",
                        "233/233 [==============================] - 4s 19ms/step - loss: 3.9939e-04 - val_loss: 0.0012\n",
                        "Epoch 341/500\n",
                        "233/233 [==============================] - 6s 26ms/step - loss: 3.9886e-04 - val_loss: 0.0011\n",
                        "Epoch 342/500\n",
                        "233/233 [==============================] - 7s 29ms/step - loss: 3.9834e-04 - val_loss: 0.0011\n",
                        "Epoch 343/500\n",
                        "233/233 [==============================] - 7s 32ms/step - loss: 3.9781e-04 - val_loss: 0.0011\n",
                        "Epoch 344/500\n",
                        "233/233 [==============================] - 8s 33ms/step - loss: 3.9728e-04 - val_loss: 0.0011\n",
                        "Epoch 345/500\n",
                        "233/233 [==============================] - 5s 21ms/step - loss: 3.9676e-04 - val_loss: 0.0011\n",
                        "Epoch 346/500\n",
                        "233/233 [==============================] - 6s 28ms/step - loss: 3.9623e-04 - val_loss: 0.0011\n",
                        "Epoch 347/500\n",
                        "233/233 [==============================] - 8s 35ms/step - loss: 3.9569e-04 - val_loss: 0.0011\n",
                        "Epoch 348/500\n",
                        "233/233 [==============================] - 8s 36ms/step - loss: 3.9518e-04 - val_loss: 0.0011\n",
                        "Epoch 349/500\n",
                        "233/233 [==============================] - 8s 33ms/step - loss: 3.9464e-04 - val_loss: 0.0011\n",
                        "Epoch 350/500\n",
                        "233/233 [==============================] - 7s 31ms/step - loss: 3.9410e-04 - val_loss: 0.0011\n",
                        "Epoch 351/500\n",
                        "233/233 [==============================] - 7s 31ms/step - loss: 3.9358e-04 - val_loss: 0.0011\n",
                        "Epoch 352/500\n",
                        "233/233 [==============================] - 7s 31ms/step - loss: 3.9305e-04 - val_loss: 0.0011\n",
                        "Epoch 353/500\n",
                        "233/233 [==============================] - 6s 25ms/step - loss: 3.9251e-04 - val_loss: 0.0011\n",
                        "Epoch 354/500\n",
                        "233/233 [==============================] - 8s 33ms/step - loss: 3.9197e-04 - val_loss: 0.0011\n",
                        "Epoch 355/500\n",
                        "233/233 [==============================] - 8s 35ms/step - loss: 3.9144e-04 - val_loss: 0.0011\n",
                        "Epoch 356/500\n",
                        "233/233 [==============================] - 8s 35ms/step - loss: 3.9089e-04 - val_loss: 0.0011\n",
                        "Epoch 357/500\n",
                        "233/233 [==============================] - 7s 28ms/step - loss: 3.9034e-04 - val_loss: 0.0011\n",
                        "Epoch 358/500\n",
                        "233/233 [==============================] - 7s 31ms/step - loss: 3.8981e-04 - val_loss: 0.0011\n",
                        "Epoch 359/500\n",
                        "233/233 [==============================] - 6s 26ms/step - loss: 3.8925e-04 - val_loss: 0.0011\n",
                        "Epoch 360/500\n",
                        "233/233 [==============================] - 5s 23ms/step - loss: 3.8869e-04 - val_loss: 0.0011\n",
                        "Epoch 361/500\n",
                        "233/233 [==============================] - 5s 21ms/step - loss: 3.8813e-04 - val_loss: 0.0011\n",
                        "Epoch 362/500\n",
                        "233/233 [==============================] - 5s 22ms/step - loss: 3.8757e-04 - val_loss: 0.0011\n",
                        "Epoch 363/500\n",
                        "233/233 [==============================] - 5s 20ms/step - loss: 3.8701e-04 - val_loss: 0.0011\n",
                        "Epoch 364/500\n",
                        "233/233 [==============================] - 5s 23ms/step - loss: 3.8643e-04 - val_loss: 0.0011\n",
                        "Epoch 365/500\n",
                        "233/233 [==============================] - 5s 22ms/step - loss: 3.8586e-04 - val_loss: 0.0011\n",
                        "Epoch 366/500\n",
                        "233/233 [==============================] - 5s 21ms/step - loss: 3.8529e-04 - val_loss: 0.0011\n",
                        "Epoch 367/500\n",
                        "233/233 [==============================] - 6s 24ms/step - loss: 3.8471e-04 - val_loss: 0.0011\n",
                        "Epoch 368/500\n",
                        "233/233 [==============================] - 5s 21ms/step - loss: 3.8412e-04 - val_loss: 0.0011\n",
                        "Epoch 369/500\n",
                        "233/233 [==============================] - 5s 22ms/step - loss: 3.8353e-04 - val_loss: 0.0011\n",
                        "Epoch 370/500\n",
                        "233/233 [==============================] - 7s 30ms/step - loss: 3.8294e-04 - val_loss: 0.0011\n",
                        "Epoch 371/500\n",
                        "233/233 [==============================] - 6s 27ms/step - loss: 3.8235e-04 - val_loss: 0.0011\n",
                        "Epoch 372/500\n",
                        "233/233 [==============================] - 5s 22ms/step - loss: 3.8176e-04 - val_loss: 0.0011\n",
                        "Epoch 373/500\n",
                        "233/233 [==============================] - 5s 21ms/step - loss: 3.8116e-04 - val_loss: 0.0011\n",
                        "Epoch 374/500\n",
                        "233/233 [==============================] - 5s 22ms/step - loss: 3.8057e-04 - val_loss: 0.0011\n",
                        "Epoch 375/500\n",
                        "233/233 [==============================] - 5s 21ms/step - loss: 3.7998e-04 - val_loss: 0.0011\n",
                        "Epoch 376/500\n",
                        "233/233 [==============================] - 5s 21ms/step - loss: 3.7939e-04 - val_loss: 0.0011\n",
                        "Epoch 377/500\n",
                        "233/233 [==============================] - 5s 23ms/step - loss: 3.7880e-04 - val_loss: 0.0011\n",
                        "Epoch 378/500\n",
                        "233/233 [==============================] - 5s 20ms/step - loss: 3.7820e-04 - val_loss: 0.0011\n",
                        "Epoch 379/500\n",
                        "233/233 [==============================] - 4s 19ms/step - loss: 3.7762e-04 - val_loss: 0.0011\n",
                        "Epoch 380/500\n",
                        "233/233 [==============================] - 5s 22ms/step - loss: 3.7703e-04 - val_loss: 0.0011\n",
                        "Epoch 381/500\n",
                        "233/233 [==============================] - 5s 20ms/step - loss: 3.7645e-04 - val_loss: 0.0011\n",
                        "Epoch 382/500\n",
                        "233/233 [==============================] - 5s 21ms/step - loss: 3.7588e-04 - val_loss: 0.0011\n",
                        "Epoch 383/500\n",
                        "233/233 [==============================] - 5s 22ms/step - loss: 3.7531e-04 - val_loss: 0.0011\n",
                        "Epoch 384/500\n",
                        "233/233 [==============================] - 5s 23ms/step - loss: 3.7474e-04 - val_loss: 0.0011\n",
                        "Epoch 385/500\n",
                        "233/233 [==============================] - 8s 34ms/step - loss: 3.7415e-04 - val_loss: 0.0011\n",
                        "Epoch 386/500\n",
                        "233/233 [==============================] - 7s 31ms/step - loss: 3.7360e-04 - val_loss: 0.0011\n",
                        "Epoch 387/500\n",
                        "233/233 [==============================] - 8s 33ms/step - loss: 3.7302e-04 - val_loss: 0.0011\n",
                        "Epoch 388/500\n",
                        "233/233 [==============================] - 8s 34ms/step - loss: 3.7245e-04 - val_loss: 0.0011\n",
                        "Epoch 389/500\n",
                        "233/233 [==============================] - 9s 37ms/step - loss: 3.7189e-04 - val_loss: 0.0011\n",
                        "Epoch 390/500\n",
                        "233/233 [==============================] - 5s 23ms/step - loss: 3.7133e-04 - val_loss: 0.0011\n",
                        "Epoch 391/500\n",
                        "233/233 [==============================] - 7s 31ms/step - loss: 3.7076e-04 - val_loss: 0.0011\n",
                        "Epoch 392/500\n",
                        "233/233 [==============================] - 6s 26ms/step - loss: 3.7020e-04 - val_loss: 0.0011\n",
                        "Epoch 393/500\n",
                        "233/233 [==============================] - 9s 38ms/step - loss: 3.6964e-04 - val_loss: 0.0011\n",
                        "Epoch 394/500\n",
                        "233/233 [==============================] - 8s 33ms/step - loss: 3.6908e-04 - val_loss: 0.0011\n",
                        "Epoch 395/500\n",
                        "233/233 [==============================] - 6s 27ms/step - loss: 3.6853e-04 - val_loss: 0.0011\n",
                        "Epoch 396/500\n",
                        "233/233 [==============================] - 8s 32ms/step - loss: 3.6797e-04 - val_loss: 0.0011\n",
                        "Epoch 397/500\n",
                        "233/233 [==============================] - 6s 27ms/step - loss: 3.6741e-04 - val_loss: 0.0011\n",
                        "Epoch 398/500\n",
                        "233/233 [==============================] - 7s 30ms/step - loss: 3.6686e-04 - val_loss: 0.0011\n",
                        "Epoch 399/500\n",
                        "233/233 [==============================] - 8s 33ms/step - loss: 3.6630e-04 - val_loss: 0.0011\n",
                        "Epoch 400/500\n",
                        "233/233 [==============================] - 7s 28ms/step - loss: 3.6574e-04 - val_loss: 0.0011\n",
                        "Epoch 401/500\n",
                        "233/233 [==============================] - 7s 31ms/step - loss: 3.6520e-04 - val_loss: 0.0011\n",
                        "Epoch 402/500\n",
                        "233/233 [==============================] - 7s 31ms/step - loss: 3.6464e-04 - val_loss: 0.0011\n",
                        "Epoch 403/500\n",
                        "233/233 [==============================] - 7s 31ms/step - loss: 3.6408e-04 - val_loss: 0.0011\n",
                        "Epoch 404/500\n",
                        "233/233 [==============================] - 6s 25ms/step - loss: 3.6353e-04 - val_loss: 0.0011\n",
                        "Epoch 405/500\n",
                        "233/233 [==============================] - 6s 25ms/step - loss: 3.6298e-04 - val_loss: 0.0011\n",
                        "Epoch 406/500\n",
                        "233/233 [==============================] - 5s 23ms/step - loss: 3.6242e-04 - val_loss: 0.0011\n",
                        "Epoch 407/500\n",
                        "233/233 [==============================] - 6s 28ms/step - loss: 3.6188e-04 - val_loss: 0.0011\n",
                        "Epoch 408/500\n",
                        "233/233 [==============================] - 7s 28ms/step - loss: 3.6132e-04 - val_loss: 0.0011\n",
                        "Epoch 409/500\n",
                        "233/233 [==============================] - 9s 37ms/step - loss: 3.6077e-04 - val_loss: 0.0011\n",
                        "Epoch 410/500\n",
                        "233/233 [==============================] - 7s 29ms/step - loss: 3.6021e-04 - val_loss: 0.0011\n",
                        "Epoch 411/500\n",
                        "233/233 [==============================] - 5s 21ms/step - loss: 3.5966e-04 - val_loss: 0.0011\n",
                        "Epoch 412/500\n",
                        "233/233 [==============================] - 5s 20ms/step - loss: 3.5911e-04 - val_loss: 0.0011\n",
                        "Epoch 413/500\n",
                        "233/233 [==============================] - 5s 21ms/step - loss: 3.5855e-04 - val_loss: 0.0011\n",
                        "Epoch 414/500\n",
                        "233/233 [==============================] - 5s 20ms/step - loss: 3.5801e-04 - val_loss: 0.0011\n",
                        "Epoch 415/500\n",
                        "233/233 [==============================] - 5s 22ms/step - loss: 3.5745e-04 - val_loss: 0.0011\n",
                        "Epoch 416/500\n",
                        "233/233 [==============================] - 7s 29ms/step - loss: 3.5689e-04 - val_loss: 0.0011\n",
                        "Epoch 417/500\n",
                        "233/233 [==============================] - 10s 41ms/step - loss: 3.5634e-04 - val_loss: 0.0011\n",
                        "Epoch 418/500\n",
                        "233/233 [==============================] - 12s 53ms/step - loss: 3.5580e-04 - val_loss: 0.0011\n",
                        "Epoch 419/500\n",
                        "233/233 [==============================] - 14s 58ms/step - loss: 3.5524e-04 - val_loss: 0.0011\n",
                        "Epoch 420/500\n",
                        "233/233 [==============================] - 10s 42ms/step - loss: 3.5469e-04 - val_loss: 0.0011\n",
                        "Epoch 421/500\n",
                        "233/233 [==============================] - 7s 32ms/step - loss: 3.5413e-04 - val_loss: 0.0011\n",
                        "Epoch 422/500\n",
                        "233/233 [==============================] - 7s 31ms/step - loss: 3.5357e-04 - val_loss: 0.0011\n",
                        "Epoch 423/500\n",
                        "233/233 [==============================] - 7s 28ms/step - loss: 3.5302e-04 - val_loss: 0.0010\n",
                        "Epoch 424/500\n",
                        "233/233 [==============================] - 5s 23ms/step - loss: 3.5247e-04 - val_loss: 0.0010\n",
                        "Epoch 425/500\n",
                        "233/233 [==============================] - 5s 23ms/step - loss: 3.5191e-04 - val_loss: 0.0011\n",
                        "Epoch 426/500\n",
                        "233/233 [==============================] - 6s 25ms/step - loss: 3.5136e-04 - val_loss: 0.0010\n",
                        "Epoch 427/500\n",
                        "233/233 [==============================] - 8s 33ms/step - loss: 3.5080e-04 - val_loss: 0.0010\n",
                        "Epoch 428/500\n",
                        "233/233 [==============================] - 5s 22ms/step - loss: 3.5024e-04 - val_loss: 0.0011\n",
                        "Epoch 429/500\n",
                        "233/233 [==============================] - 5s 23ms/step - loss: 3.4969e-04 - val_loss: 0.0010\n",
                        "Epoch 430/500\n",
                        "233/233 [==============================] - 4s 17ms/step - loss: 3.4913e-04 - val_loss: 0.0010\n",
                        "Epoch 431/500\n",
                        "233/233 [==============================] - 4s 17ms/step - loss: 3.4858e-04 - val_loss: 0.0011\n",
                        "Epoch 432/500\n",
                        "233/233 [==============================] - 4s 17ms/step - loss: 3.4802e-04 - val_loss: 0.0010\n",
                        "Epoch 433/500\n",
                        "233/233 [==============================] - 4s 17ms/step - loss: 3.4746e-04 - val_loss: 0.0010\n",
                        "Epoch 434/500\n",
                        "233/233 [==============================] - 5s 19ms/step - loss: 3.4690e-04 - val_loss: 0.0010\n",
                        "Epoch 435/500\n",
                        "233/233 [==============================] - 4s 17ms/step - loss: 3.4635e-04 - val_loss: 0.0010\n",
                        "Epoch 436/500\n",
                        "233/233 [==============================] - 4s 18ms/step - loss: 3.4579e-04 - val_loss: 0.0010\n",
                        "Epoch 437/500\n",
                        "233/233 [==============================] - 4s 19ms/step - loss: 3.4524e-04 - val_loss: 0.0010\n",
                        "Epoch 438/500\n",
                        "233/233 [==============================] - 4s 18ms/step - loss: 3.4467e-04 - val_loss: 0.0010\n",
                        "Epoch 439/500\n",
                        "233/233 [==============================] - 4s 17ms/step - loss: 3.4411e-04 - val_loss: 0.0010\n",
                        "Epoch 440/500\n",
                        "233/233 [==============================] - 4s 19ms/step - loss: 3.4356e-04 - val_loss: 0.0010\n",
                        "Epoch 441/500\n",
                        "233/233 [==============================] - 4s 17ms/step - loss: 3.4300e-04 - val_loss: 0.0010\n",
                        "Epoch 442/500\n",
                        "233/233 [==============================] - 4s 18ms/step - loss: 3.4244e-04 - val_loss: 0.0010\n",
                        "Epoch 443/500\n",
                        "233/233 [==============================] - 5s 20ms/step - loss: 3.4188e-04 - val_loss: 0.0010\n",
                        "Epoch 444/500\n",
                        "233/233 [==============================] - 4s 19ms/step - loss: 3.4133e-04 - val_loss: 0.0010\n",
                        "Epoch 445/500\n",
                        "233/233 [==============================] - 4s 18ms/step - loss: 3.4077e-04 - val_loss: 0.0010\n",
                        "Epoch 446/500\n",
                        "233/233 [==============================] - 4s 19ms/step - loss: 3.4019e-04 - val_loss: 0.0010\n",
                        "Epoch 447/500\n",
                        "233/233 [==============================] - 4s 17ms/step - loss: 3.3963e-04 - val_loss: 0.0010\n",
                        "Epoch 448/500\n",
                        "233/233 [==============================] - 4s 18ms/step - loss: 3.3907e-04 - val_loss: 0.0010\n",
                        "Epoch 449/500\n",
                        "233/233 [==============================] - 4s 19ms/step - loss: 3.3852e-04 - val_loss: 0.0010\n",
                        "Epoch 450/500\n",
                        "233/233 [==============================] - 4s 18ms/step - loss: 3.3796e-04 - val_loss: 0.0010\n",
                        "Epoch 451/500\n",
                        "233/233 [==============================] - 4s 19ms/step - loss: 3.3739e-04 - val_loss: 0.0010\n",
                        "Epoch 452/500\n",
                        "233/233 [==============================] - 4s 18ms/step - loss: 3.3683e-04 - val_loss: 0.0010\n",
                        "Epoch 453/500\n",
                        "233/233 [==============================] - 4s 18ms/step - loss: 3.3627e-04 - val_loss: 0.0010\n",
                        "Epoch 454/500\n",
                        "233/233 [==============================] - 5s 21ms/step - loss: 3.3572e-04 - val_loss: 0.0010\n",
                        "Epoch 455/500\n",
                        "233/233 [==============================] - 4s 18ms/step - loss: 3.3515e-04 - val_loss: 0.0010\n",
                        "Epoch 456/500\n",
                        "233/233 [==============================] - 5s 21ms/step - loss: 3.3460e-04 - val_loss: 0.0010\n",
                        "Epoch 457/500\n",
                        "233/233 [==============================] - 4s 19ms/step - loss: 3.3401e-04 - val_loss: 0.0010\n",
                        "Epoch 458/500\n",
                        "233/233 [==============================] - 5s 20ms/step - loss: 3.3346e-04 - val_loss: 0.0010\n",
                        "Epoch 459/500\n",
                        "233/233 [==============================] - 4s 19ms/step - loss: 3.3290e-04 - val_loss: 0.0010\n",
                        "Epoch 460/500\n",
                        "233/233 [==============================] - 4s 17ms/step - loss: 3.3234e-04 - val_loss: 0.0010\n",
                        "Epoch 461/500\n",
                        "233/233 [==============================] - 4s 18ms/step - loss: 3.3177e-04 - val_loss: 0.0010\n",
                        "Epoch 462/500\n",
                        "233/233 [==============================] - 4s 17ms/step - loss: 3.3122e-04 - val_loss: 0.0010\n",
                        "Epoch 463/500\n",
                        "233/233 [==============================] - 5s 20ms/step - loss: 3.3065e-04 - val_loss: 0.0010\n",
                        "Epoch 464/500\n",
                        "233/233 [==============================] - 5s 20ms/step - loss: 3.3008e-04 - val_loss: 0.0010\n",
                        "Epoch 465/500\n",
                        "233/233 [==============================] - 4s 19ms/step - loss: 3.2953e-04 - val_loss: 0.0010\n",
                        "Epoch 466/500\n",
                        "233/233 [==============================] - 4s 18ms/step - loss: 3.2895e-04 - val_loss: 0.0010\n",
                        "Epoch 467/500\n",
                        "233/233 [==============================] - 5s 21ms/step - loss: 3.2839e-04 - val_loss: 0.0010\n",
                        "Epoch 468/500\n",
                        "233/233 [==============================] - 4s 18ms/step - loss: 3.2783e-04 - val_loss: 0.0010\n",
                        "Epoch 469/500\n",
                        "233/233 [==============================] - 4s 18ms/step - loss: 3.2726e-04 - val_loss: 0.0010\n",
                        "Epoch 470/500\n",
                        "233/233 [==============================] - 4s 19ms/step - loss: 3.2670e-04 - val_loss: 0.0010\n",
                        "Epoch 471/500\n",
                        "233/233 [==============================] - 4s 18ms/step - loss: 3.2614e-04 - val_loss: 0.0010\n",
                        "Epoch 472/500\n",
                        "233/233 [==============================] - 4s 19ms/step - loss: 3.2556e-04 - val_loss: 0.0010\n",
                        "Epoch 473/500\n",
                        "233/233 [==============================] - 4s 19ms/step - loss: 3.2500e-04 - val_loss: 0.0010\n",
                        "Epoch 474/500\n",
                        "233/233 [==============================] - 5s 19ms/step - loss: 3.2444e-04 - val_loss: 0.0010\n",
                        "Epoch 475/500\n",
                        "233/233 [==============================] - 5s 19ms/step - loss: 3.2388e-04 - val_loss: 0.0010\n",
                        "Epoch 476/500\n",
                        "233/233 [==============================] - 4s 18ms/step - loss: 3.2331e-04 - val_loss: 0.0010\n",
                        "Epoch 477/500\n",
                        "233/233 [==============================] - 4s 19ms/step - loss: 3.2274e-04 - val_loss: 0.0010\n",
                        "Epoch 478/500\n",
                        "233/233 [==============================] - 4s 18ms/step - loss: 3.2218e-04 - val_loss: 0.0010\n",
                        "Epoch 479/500\n",
                        "233/233 [==============================] - 5s 19ms/step - loss: 3.2160e-04 - val_loss: 0.0010\n",
                        "Epoch 480/500\n",
                        "233/233 [==============================] - 4s 18ms/step - loss: 3.2105e-04 - val_loss: 0.0010\n",
                        "Epoch 481/500\n",
                        "233/233 [==============================] - 5s 20ms/step - loss: 3.2048e-04 - val_loss: 0.0010\n",
                        "Epoch 482/500\n",
                        "233/233 [==============================] - 4s 18ms/step - loss: 3.1990e-04 - val_loss: 0.0010\n",
                        "Epoch 483/500\n",
                        "233/233 [==============================] - 4s 19ms/step - loss: 3.1935e-04 - val_loss: 0.0010\n",
                        "Epoch 484/500\n",
                        "233/233 [==============================] - 4s 18ms/step - loss: 3.1878e-04 - val_loss: 0.0010\n",
                        "Epoch 485/500\n",
                        "233/233 [==============================] - 5s 19ms/step - loss: 3.1821e-04 - val_loss: 0.0010\n",
                        "Epoch 486/500\n",
                        "233/233 [==============================] - 4s 18ms/step - loss: 3.1765e-04 - val_loss: 0.0010\n",
                        "Epoch 487/500\n",
                        "233/233 [==============================] - 5s 20ms/step - loss: 3.1709e-04 - val_loss: 0.0010\n",
                        "Epoch 488/500\n",
                        "233/233 [==============================] - 4s 19ms/step - loss: 3.1651e-04 - val_loss: 0.0010\n",
                        "Epoch 489/500\n",
                        "233/233 [==============================] - 4s 18ms/step - loss: 3.1595e-04 - val_loss: 0.0010\n",
                        "Epoch 490/500\n",
                        "233/233 [==============================] - 4s 19ms/step - loss: 3.1538e-04 - val_loss: 0.0010\n",
                        "Epoch 491/500\n",
                        "233/233 [==============================] - 4s 18ms/step - loss: 3.1481e-04 - val_loss: 0.0010\n",
                        "Epoch 492/500\n",
                        "233/233 [==============================] - 5s 20ms/step - loss: 3.1425e-04 - val_loss: 0.0010\n",
                        "Epoch 493/500\n",
                        "233/233 [==============================] - 4s 18ms/step - loss: 3.1368e-04 - val_loss: 0.0010\n",
                        "Epoch 494/500\n",
                        "233/233 [==============================] - 5s 19ms/step - loss: 3.1312e-04 - val_loss: 0.0010\n",
                        "Epoch 495/500\n",
                        "233/233 [==============================] - 4s 18ms/step - loss: 3.1254e-04 - val_loss: 0.0010\n",
                        "Epoch 496/500\n",
                        "233/233 [==============================] - 5s 19ms/step - loss: 3.1198e-04 - val_loss: 0.0010\n",
                        "Epoch 497/500\n",
                        "233/233 [==============================] - 4s 18ms/step - loss: 3.1141e-04 - val_loss: 0.0010\n",
                        "Epoch 498/500\n",
                        "233/233 [==============================] - 5s 22ms/step - loss: 3.1083e-04 - val_loss: 0.0010\n",
                        "Epoch 499/500\n",
                        "233/233 [==============================] - 5s 21ms/step - loss: 3.1028e-04 - val_loss: 0.0010\n",
                        "Epoch 500/500\n",
                        "233/233 [==============================] - 4s 18ms/step - loss: 3.0971e-04 - val_loss: 0.0010\n"
                    ]
                }
            ],
            "source": [
                "#Model fitting for different optimizer\n",
                "np.random.seed(1)\n",
                "history=model1.fit(x=scaled_x, y=Y, batch_size=256, epochs=500, verbose=1, validation_split=0.1,callbacks=[es])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 168,
            "metadata": {},
            "outputs": [],
            "source": [
                "# loss = pd.DataFrame(model1.history.history)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 169,
            "metadata": {},
            "outputs": [],
            "source": [
                "# plt.plot(history.history['loss'])\n",
                "# plt.plot(history.history['val_loss'])\n",
                "# plt.title('train_loss', fontsize=15)\n",
                "# plt.ylabel('Loss', fontsize=15)\n",
                "# plt.xlabel('Epoch', fontsize=15)\n",
                "# plt.legend(['train', 'val'], loc='upper right')\n",
                "# plt.xticks(fontsize=15)\n",
                "# plt.yticks(fontsize=15)\n",
                "# plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 170,
            "metadata": {},
            "outputs": [],
            "source": [
                "var = 'x_y_xy';"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 171,
            "metadata": {},
            "outputs": [],
            "source": [
                "# model_json = model1.to_json()\n",
                "# with open('Saved_model/train_model2_ref_'+var+'.json', 'w') as json_file:\n",
                "#     json_file.write(model_json)\n",
                "\n",
                "# #serialize weights to HDF5 file\n",
                "# model1.save_weights('Saved_model/train_model2_ref_'+var+'.h5')\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 172,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Saving train model with different optimizer.\n",
                "model_json = model1.to_json()\n",
                "with open('Model/Model2/SGD_'+var+'.json', 'w') as json_file:\n",
                "    json_file.write(model_json)\n",
                "\n",
                "#serialize weights to HDF5 file\n",
                "model1.save_weights('Model/Model2/SGD_'+var+'.h5')\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": 173,
            "metadata": {},
            "outputs": [],
            "source": [
                "# # load json and create model\n",
                "# json_file = open('Saved_model/train_model2_ref_'+var+'.json', 'r')\n",
                "# loaded_model_json = json_file.read()\n",
                "# json_file.close()\n",
                "# loaded_model = model_from_json(loaded_model_json);\n",
                "\n",
                "# #load weights into new model\n",
                "# loaded_model.load_weights('Saved_model/train_model2_ref_'+var+'.h5') "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 174,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Loding model with different optimizer.\n",
                "# load json and create model\n",
                "json_file = open('Model/Model2/SGD_'+var+'.json', 'r')\n",
                "loaded_model_json = json_file.read()\n",
                "json_file.close()\n",
                "loaded_model = model_from_json(loaded_model_json);\n",
                "\n",
                "#load weights into new model\n",
                "loaded_model.load_weights('Model/Model2/SGD_'+var+'.h5') "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 175,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Stress calculation at Gauss points\n",
                "stress = np.zeros((nel, ngp2d*ngp2d, 3))\n",
                "strains = np.zeros((nel, ngp2d*ngp2d, 3))\n",
                "\n",
                "for i in range(nel):\n",
                "    stress_i_g = np.zeros((ngp2d*ngp2d, 3))\n",
                "    strains_i_g = np.zeros((ngp2d*ngp2d, 3))\n",
                "\n",
                "    stress_i_g, strains_i_g = stress_gauss.get_element_stress(\n",
                "        i, ngp2d, el_type_q4, connect, coord, u, C)\n",
                "\n",
                "    stress[i][:][:] = stress_i_g\n",
                "    strains[i][:][:] = strains_i_g.reshape((1, 3))\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 176,
            "metadata": {},
            "outputs": [],
            "source": [
                "# calcuation of gauss coordinates.\n",
                "gauss_coords = np.zeros((nel, ngp2d*ngp2d, 2))\n",
                "gp, weights = quadrature.quadrature(ngp2d)\n",
                "for i in range(nel):\n",
                "    node = connect[i, :]\n",
                "    vertex_coord = coord[node, :].reshape(-1)\n",
                "    gauss_coords[i][:][:] = gauss_pt_coord.gauss_pts(\n",
                "        ngp2d, vertex_coord, gp, el_type)\n",
                "gauss_coords = gauss_coords.reshape(gauss_coords.shape[0], -1)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 177,
            "metadata": {},
            "outputs": [],
            "source": [
                "#creation of patches for spr_stress;\n",
                "patch, n_patches, int_nodes = patch_n_int_nodes.patch_n_int_nodes(ms)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 178,
            "metadata": {},
            "outputs": [],
            "source": [
                "#spr_stress STRESS Calculations\n",
                "stress_spr = spr_stress.spr(gauss_coords, coord, connect, stress,\n",
                "                            int_nodes, n_patches, patch, ms)\n",
                "# stress_spr\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 179,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Directly calculated stress\n",
                "stress_dc, strain_dc = stress_nodes_dc.stress_dc(\n",
                "    connect, coord, u, nel, el_type, C)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 180,
            "metadata": {},
            "outputs": [],
            "source": [
                "# coord\n",
                "# np.random.seed(1);\n",
                "# pts = np.random.choice(np.arange(36),5);\n",
                "# coord_test = coord[pts];\n",
                "# coord_test\n",
                "# stress_spr\n",
                "total_nodes = (ms+1)**2\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 181,
            "metadata": {},
            "outputs": [],
            "source": [
                "#outter points in\n",
                "sp = []\n",
                "# print(ms)\n",
                "temp = ms+1\n",
                "for i in range(ms-1):\n",
                "    sp.append(temp)\n",
                "    sp.append(temp+ms)\n",
                "    temp = temp+ms+1\n",
                "for i in range(ms+1):\n",
                "    sp.append(temp)\n",
                "    temp = temp+1\n",
                "\n",
                "for i in range(ms+1):\n",
                "    sp.append(i)\n",
                "\n",
                "sp = sorted(sp)\n",
                "# print(sp);\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 182,
            "metadata": {},
            "outputs": [],
            "source": [
                "coord_corner = coord[sp]\n",
                "# coord_corner\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 183,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/krishna/Desktop/btp_499_code/btp_env/lib/python3.10/site-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
                        "  warnings.warn(\n"
                    ]
                }
            ],
            "source": [
                "scaled_test_corner = scaler.transform(coord_corner)\n",
                "# scaled_test_corner\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 184,
            "metadata": {},
            "outputs": [],
            "source": [
                "ref_stress = pd.read_csv('Ref/ref_stress_for_ms_5_from_320.csv')\n",
                "ref_stress = ref_stress.loc[:, ~ref_stress.columns.str.contains('^Unnamed')]\n",
                "ref_stress = ref_stress.to_numpy()\n",
                "# ref_stress\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 185,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "3\n"
                    ]
                }
            ],
            "source": [
                "# a ---->reference stress\n",
                "a = ref_stress.T\n",
                "print(len(a))\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 186,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "3\n"
                    ]
                }
            ],
            "source": [
                "# a--->plane stress calculated from spr\n",
                "b = stress_spr.T\n",
                "print(len(b))\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 187,
            "metadata": {},
            "outputs": [],
            "source": [
                "err_spr_abs = np.abs((a-b))\n",
                "err_spr_perc = np.abs((a-b)/a)\n",
                "err_dc_abs = np.abs((a-stress_dc.T))\n",
                "err_dc_perc = np.abs((a-stress_dc.T)/a)\n",
                "# err_spr_abs\n",
                "# err_dc_abs\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 188,
            "metadata": {},
            "outputs": [],
            "source": [
                "test = pd.DataFrame(scaled_test, columns=['a', 'b'])\n",
                "# test\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 189,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f606d23fac0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
                        "2/2 [==============================] - 1s 39ms/step\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "36"
                        ]
                    },
                    "execution_count": 189,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# c --->stress calculated using ANN trained model\n",
                "c = loaded_model.predict(test)\n",
                "len(c)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 190,
            "metadata": {},
            "outputs": [],
            "source": [
                "err_ann_abs = np.abs((a-c.T))\n",
                "err_ann_perc = np.abs((a-c.T)/a)\n",
                "# err_ann_abs\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 191,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "alll = np.concatenate([coord,\n",
                "                       a.reshape(a.T.shape[0], 3),\n",
                "                       b.reshape(b.T.shape[0], 3),\n",
                "                       c.reshape(c.shape[0], 3),\n",
                "                       err_spr_abs.reshape(err_spr_abs.T.shape[0], 3),\n",
                "                       err_ann_abs.reshape(err_ann_abs.T.shape[0], 3),\n",
                "                       err_dc_abs.reshape(err_dc_abs.T.shape[0], 3),\n",
                "                       err_spr_perc.reshape(err_spr_perc.T.shape[0], 3),\n",
                "                       err_ann_perc.reshape(err_ann_perc.T.shape[0], 3),\n",
                "                       err_dc_perc.reshape(err_dc_perc.T.shape[0], 3)\n",
                "                       ],\n",
                "                      axis=1)\n",
                "# alll\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 192,
            "metadata": {},
            "outputs": [],
            "source": [
                "tdf = pd.DataFrame(alll, columns=['x',\n",
                "                                  'y',\n",
                "                                  'ref_stress_x',\n",
                "                                  'ref_stress_y',\n",
                "                                  'ref_stress_xy',\n",
                "                                  'spr_stress_x',\n",
                "                                  'spr_stress_y',\n",
                "                                  'spr_stress_xy',\n",
                "                                  'ann_stress_x',\n",
                "                                  'ann_stress_y',\n",
                "                                  'ann_stress_xy',\n",
                "                                  'err_spr_abs_x',\n",
                "                                  'err_spr_abs_y',\n",
                "                                  'err_spr_abs_xy',\n",
                "                                  'err_ann_abs_x',\n",
                "                                  'err_ann_abs_y',\n",
                "                                  'err_ann_abs_xy',\n",
                "                                  'err_dc_abs_x',\n",
                "                                  'err_dc_abs_y',\n",
                "                                  'err_dc_abs_xy',\n",
                "                                  'err_spr_perc_x',\n",
                "                                  'err_spr_perc_y',\n",
                "                                  'err_spr_perc_xy',\n",
                "                                  'err_ann_perc_x',\n",
                "                                  'err_ann_perc_y',\n",
                "                                  'err_ann_perc_xy',\n",
                "                                  'err_dc_perc_x',\n",
                "                                  'err_dc_perc_y',\n",
                "                                  'err_dc_perc_xy'\n",
                "                                  ])\n",
                "# print(tdf.head());\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 193,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>x</th>\n",
                            "      <th>y</th>\n",
                            "      <th>ref_stress_x</th>\n",
                            "      <th>ref_stress_y</th>\n",
                            "      <th>ref_stress_xy</th>\n",
                            "      <th>spr_stress_x</th>\n",
                            "      <th>spr_stress_y</th>\n",
                            "      <th>spr_stress_xy</th>\n",
                            "      <th>ann_stress_x</th>\n",
                            "      <th>ann_stress_y</th>\n",
                            "      <th>...</th>\n",
                            "      <th>err_dc_abs_xy</th>\n",
                            "      <th>err_spr_perc_x</th>\n",
                            "      <th>err_spr_perc_y</th>\n",
                            "      <th>err_spr_perc_xy</th>\n",
                            "      <th>err_ann_perc_x</th>\n",
                            "      <th>err_ann_perc_y</th>\n",
                            "      <th>err_ann_perc_xy</th>\n",
                            "      <th>err_dc_perc_x</th>\n",
                            "      <th>err_dc_perc_y</th>\n",
                            "      <th>err_dc_perc_xy</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.020590</td>\n",
                            "      <td>0.066856</td>\n",
                            "      <td>0.114837</td>\n",
                            "      <td>0.063443</td>\n",
                            "      <td>0.059761</td>\n",
                            "      <td>0.057295</td>\n",
                            "      <td>0.056644</td>\n",
                            "      <td>0.032010</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0.003450</td>\n",
                            "      <td>2.081206</td>\n",
                            "      <td>0.106128</td>\n",
                            "      <td>0.501073</td>\n",
                            "      <td>1.751031</td>\n",
                            "      <td>0.206221</td>\n",
                            "      <td>0.020695</td>\n",
                            "      <td>2.244944</td>\n",
                            "      <td>0.033750</td>\n",
                            "      <td>0.030039</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>9.6</td>\n",
                            "      <td>8.8</td>\n",
                            "      <td>0.142259</td>\n",
                            "      <td>0.142736</td>\n",
                            "      <td>0.116694</td>\n",
                            "      <td>0.060733</td>\n",
                            "      <td>0.062001</td>\n",
                            "      <td>0.065805</td>\n",
                            "      <td>0.080643</td>\n",
                            "      <td>0.041843</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0.285664</td>\n",
                            "      <td>0.573084</td>\n",
                            "      <td>0.565624</td>\n",
                            "      <td>0.436090</td>\n",
                            "      <td>0.059730</td>\n",
                            "      <td>0.205023</td>\n",
                            "      <td>0.399891</td>\n",
                            "      <td>0.489825</td>\n",
                            "      <td>0.133649</td>\n",
                            "      <td>2.447965</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>19.2</td>\n",
                            "      <td>17.6</td>\n",
                            "      <td>0.073042</td>\n",
                            "      <td>0.093437</td>\n",
                            "      <td>0.099048</td>\n",
                            "      <td>0.063212</td>\n",
                            "      <td>0.086114</td>\n",
                            "      <td>0.096941</td>\n",
                            "      <td>0.112460</td>\n",
                            "      <td>0.054878</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0.017992</td>\n",
                            "      <td>0.134571</td>\n",
                            "      <td>0.078366</td>\n",
                            "      <td>0.021269</td>\n",
                            "      <td>0.111683</td>\n",
                            "      <td>0.073298</td>\n",
                            "      <td>0.062605</td>\n",
                            "      <td>0.192864</td>\n",
                            "      <td>0.120837</td>\n",
                            "      <td>0.181649</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>28.8</td>\n",
                            "      <td>26.4</td>\n",
                            "      <td>0.094280</td>\n",
                            "      <td>0.076036</td>\n",
                            "      <td>0.014692</td>\n",
                            "      <td>0.093381</td>\n",
                            "      <td>0.065664</td>\n",
                            "      <td>0.014115</td>\n",
                            "      <td>0.133762</td>\n",
                            "      <td>0.064998</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0.006585</td>\n",
                            "      <td>0.009532</td>\n",
                            "      <td>0.136410</td>\n",
                            "      <td>0.039297</td>\n",
                            "      <td>0.022444</td>\n",
                            "      <td>0.054796</td>\n",
                            "      <td>1.756047</td>\n",
                            "      <td>0.152581</td>\n",
                            "      <td>0.531915</td>\n",
                            "      <td>0.448163</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>38.4</td>\n",
                            "      <td>35.2</td>\n",
                            "      <td>0.080207</td>\n",
                            "      <td>0.072637</td>\n",
                            "      <td>0.051343</td>\n",
                            "      <td>0.027299</td>\n",
                            "      <td>0.068231</td>\n",
                            "      <td>0.050842</td>\n",
                            "      <td>0.113471</td>\n",
                            "      <td>0.065836</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0.007476</td>\n",
                            "      <td>0.659641</td>\n",
                            "      <td>0.060657</td>\n",
                            "      <td>0.009764</td>\n",
                            "      <td>0.141788</td>\n",
                            "      <td>0.114334</td>\n",
                            "      <td>0.029884</td>\n",
                            "      <td>0.028527</td>\n",
                            "      <td>0.229736</td>\n",
                            "      <td>0.145609</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "<p>5 rows  29 columns</p>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "      x     y  ref_stress_x  ref_stress_y  ref_stress_xy  spr_stress_x  \\\n",
                            "0   0.0   0.0      0.020590      0.066856       0.114837      0.063443   \n",
                            "1   9.6   8.8      0.142259      0.142736       0.116694      0.060733   \n",
                            "2  19.2  17.6      0.073042      0.093437       0.099048      0.063212   \n",
                            "3  28.8  26.4      0.094280      0.076036       0.014692      0.093381   \n",
                            "4  38.4  35.2      0.080207      0.072637       0.051343      0.027299   \n",
                            "\n",
                            "   spr_stress_y  spr_stress_xy  ann_stress_x  ann_stress_y  ...  \\\n",
                            "0      0.059761       0.057295      0.056644      0.032010  ...   \n",
                            "1      0.062001       0.065805      0.080643      0.041843  ...   \n",
                            "2      0.086114       0.096941      0.112460      0.054878  ...   \n",
                            "3      0.065664       0.014115      0.133762      0.064998  ...   \n",
                            "4      0.068231       0.050842      0.113471      0.065836  ...   \n",
                            "\n",
                            "   err_dc_abs_xy  err_spr_perc_x  err_spr_perc_y  err_spr_perc_xy  \\\n",
                            "0       0.003450        2.081206        0.106128         0.501073   \n",
                            "1       0.285664        0.573084        0.565624         0.436090   \n",
                            "2       0.017992        0.134571        0.078366         0.021269   \n",
                            "3       0.006585        0.009532        0.136410         0.039297   \n",
                            "4       0.007476        0.659641        0.060657         0.009764   \n",
                            "\n",
                            "   err_ann_perc_x  err_ann_perc_y  err_ann_perc_xy  err_dc_perc_x  \\\n",
                            "0        1.751031        0.206221         0.020695       2.244944   \n",
                            "1        0.059730        0.205023         0.399891       0.489825   \n",
                            "2        0.111683        0.073298         0.062605       0.192864   \n",
                            "3        0.022444        0.054796         1.756047       0.152581   \n",
                            "4        0.141788        0.114334         0.029884       0.028527   \n",
                            "\n",
                            "   err_dc_perc_y  err_dc_perc_xy  \n",
                            "0       0.033750        0.030039  \n",
                            "1       0.133649        2.447965  \n",
                            "2       0.120837        0.181649  \n",
                            "3       0.531915        0.448163  \n",
                            "4       0.229736        0.145609  \n",
                            "\n",
                            "[5 rows x 29 columns]"
                        ]
                    },
                    "execution_count": 193,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "tdf.to_csv('mult_e_data/ms5/all_matlab_train_model2_ref_'+var+'.csv')\n",
                "tdf.head()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 194,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "0.6860461513578601"
                        ]
                    },
                    "execution_count": 194,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "tdf['err_spr_perc_x'].mean()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 195,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "0.32947246179473"
                        ]
                    },
                    "execution_count": 195,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "tdf['err_spr_perc_y'].mean()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 196,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "0.5658925933085241"
                        ]
                    },
                    "execution_count": 196,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "tdf['err_spr_perc_xy'].mean()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": 197,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "0.7493842927119523"
                        ]
                    },
                    "execution_count": 197,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "tdf['err_ann_perc_x'].mean()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 198,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "0.7812233367437786"
                        ]
                    },
                    "execution_count": 198,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "tdf['err_ann_perc_y'].mean()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 199,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "0.7433034974780829"
                        ]
                    },
                    "execution_count": 199,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "tdf['err_ann_perc_xy'].mean()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.9.13 ('base')",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.6"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "0c72c36e56a90c0115cb01eebece97049a9c51106feacd19e0fe42a458fac2fc"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
