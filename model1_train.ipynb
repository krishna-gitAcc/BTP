{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2023-04-07 09:15:29.178714: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
                        "2023-04-07 09:15:30.254696: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
                        "2023-04-07 09:15:33.435923: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
                        "2023-04-07 09:15:33.438526: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
                        "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
                        "2023-04-07 09:15:40.393066: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
                    ]
                }
            ],
            "source": [
                "import matplotlib.pyplot as plt\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import tensorflow as tf\n",
                "from joblib import Parallel, delayed\n",
                "from keras.models import model_from_json\n",
                "from sklearn.preprocessing import MinMaxScaler\n",
                "from tensorflow.keras.layers import Dense\n",
                "from tensorflow.keras.models import Sequential\n",
                "\n",
                "\n",
                "import constitutive\n",
                "import displacement_solver\n",
                "import gauss_pt_coord\n",
                "import mesh_gen\n",
                "import quadrature\n",
                "import stress_gauss\n",
                "import spr_stress\n",
                "import patch_n_int_nodes\n",
                "import stress_nodes_dc\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ............................. Inputs Parameters................................#\n",
                "\n",
                "#Domain geometry\n",
                "domain_coord = np.array([[0, 0], [48, 44], [48, 60],[0, 44],[24, 22], [48, 52], [24, 52], [0, 22]]);\n",
                "\n",
                "# Body force components\n",
                "b = np.array([[0], [0]]);\n",
                "\n",
                "#Traction components\n",
                "q = 1/16;\n",
                "\n",
                "T = np.array([[0, 0], [0, q], [0, 0]]);\n",
                "\n",
                "# Young's modulus\n",
                "E = 1.0;\n",
                "\n",
                "# Poisson's ration\n",
                "nu = 1/3;\n",
                "\n",
                "# problem type (0--->plane stress, 1----->plane starin)\n",
                "problem_type = 0;\n",
                "\n",
                "#Element type used for meshing (0--->4 nodes quadrilateral, 1---->8 node quadrilateral, 2-----> 9 node quadrilateral)\n",
                "el_type_q4 = 0;\n",
                "# el_type_q8 = 1;\n",
                "# el_type_q9 = 2;\n",
                "\n",
                "# No. of Gauss points required for integration \n",
                "ngp2d = 1;\n",
                "ngp1d = 2;\n",
                "\n",
                "# Mesh sizes to be tested\n",
                "N = [5];\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
                        "(25, 8)\n",
                        "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.8s\n",
                        "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.8s finished\n",
                        "[24.364007351422813]\n"
                    ]
                }
            ],
            "source": [
                "# Q4 elements\n",
                "\n",
                "u_list_q4 = Parallel(n_jobs = -1 , verbose = 100)(\n",
                "    delayed(displacement_solver.solve_fem)(N[i], E, nu, ngp2d, ngp1d,el_type_q4, problem_type,domain_coord, b, T)\n",
                "    for i in range(len(N)));\n",
                "\n",
                "u_q4 = [];\n",
                "for i in range(len(N)):\n",
                "    nx = N[i];\n",
                "    ny = N[i];\n",
                "    node_2d = np.arange((nx+1)*(ny+1)).reshape(nx+1, ny+1);\n",
                "    # print(node_2d)\n",
                "    # print(node_2d[int(ny/2), -1])\n",
                "    node = node_2d[int(nx/2),-1];\n",
                "    dof = 2*node+1\n",
                "    u_q4.append(u_list_q4[i][dof]);\n",
                "print(u_q4); "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "#ms = mesh size\n",
                "ms = N[0]\n",
                "\n",
                "#u = displacements at the nodes calculated directly form FEM fromulations of mesh size \"ms\" (u is an 1D array)\n",
                "u = u_list_q4[N.index(ms)]\n",
                "\n",
                "#total number of elements\n",
                "nel = ms*ms\n",
                "\n",
                "#reshaping u into u_nodes with displacment in x-direction in first column and y-direction in the second column\n",
                "u_nodes = u.reshape(((ms+1)*(ms+1), 2))\n",
                "# print(u_nodes);\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "# constitutive relation matrix, calculated using the fuction \"Constitutube\" with input E->(Young's Modulus), nu(Poisson's raton), problem_type(plane stress or plane strain)\n",
                "C = constitutive.constitutive(E, nu, problem_type)\n",
                "# print(C)\n",
                "\n",
                "# mesh_obj = object created to calculate\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "# mesh generation\n",
                "nx = ms  # number of element in x-direction\n",
                "ny = ms  # number of element in y-direction\n",
                "\n",
                "# el_type = element type specifiedc. 0----> q4, q-----> q8, 2-----> q9\n",
                "el_type = 0\n",
                "\n",
                "#mesh_obj = object created to calculated nodal coordinates ans connectivity array using functon \"connectivity\" and \"coord_array\"\n",
                "#input nx->number of element in x-direction, xy->number of element in y-direction, domain_coord->coordinates of the corner points and mid-points of the cook's skew beam problem, el_type->element type specidied.\n",
                "\n",
                "mesh_obj = mesh_gen.MeshGenerator(nx, ny, domain_coord.reshape(16, 1), el_type)\n",
                "connect = mesh_obj.connectivity()\n",
                "# print(connect)\n",
                "coord = mesh_obj.coord_array()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": [
                "# print(len(coord))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "strs_ref = pd.read_csv('Data/res_superconv_gauss_pt_1_stress_ms_256.csv');"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [],
            "source": [
                "# strs_ref.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": [
                "X = pd.read_csv('Coord/coord_gauss_pt_256.csv');\n",
                "X = X.loc[:, ~X.columns.str.contains('Unnamed')];\n",
                "y = strs_ref;\n",
                "y = y.loc[:, ~y.columns.str.contains('Unnamed')];"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": [
                "# print(X.head())\n",
                "# print(y.head());\n",
                "# print(len(y));"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/krishna/Desktop/btp_499_code/btp_env/lib/python3.10/site-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
                        "  warnings.warn(\n"
                    ]
                }
            ],
            "source": [
                "# form sklearn.preprocessing import MinMaxScaler \n",
                "scaler = MinMaxScaler()\n",
                "scaler.fit(X)\n",
                "scaled_x = scaler.transform(X)\n",
                "scaled_test = scaler.transform(coord)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [],
            "source": [
                "# print(X);\n",
                "# print(scaled_x);\n",
                "# print(scaled_test);\n",
                "# print(len(scaled_x));\n",
                "# print(len(scaled_test));"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 178,
            "metadata": {},
            "outputs": [],
            "source": [
                "#ANN one model in whole domain for 3 output layer\n",
                "model1 = Sequential()\n",
                "model1.add(Dense(units=50,  activation='relu'))\n",
                "model1.add(Dense(units=40, activation='relu'))\n",
                "model1.add(Dense(units=30, activation='relu'))\n",
                "model1.add(Dense(units=20, activation='relu'))\n",
                "model1.add(Dense(units=10, activation='relu'))\n",
                "model1.add(Dense(units=3, activation='linear'))\n",
                "model1.compile(\n",
                "    loss='mse', optimizer=tf.keras.optimizers.SGD(learning_rate=0.01))\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 179,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 1/300\n",
                        "116/116 [==============================] - 3s 9ms/step - loss: 0.0038 - val_loss: 0.0142\n",
                        "Epoch 2/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 0.0030 - val_loss: 0.0142\n",
                        "Epoch 3/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 0.0027 - val_loss: 0.0140\n",
                        "Epoch 4/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 0.0025 - val_loss: 0.0135\n",
                        "Epoch 5/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 0.0023 - val_loss: 0.0130\n",
                        "Epoch 6/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 0.0022 - val_loss: 0.0128\n",
                        "Epoch 7/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 0.0022 - val_loss: 0.0126\n",
                        "Epoch 8/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 0.0021 - val_loss: 0.0125\n",
                        "Epoch 9/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 0.0021 - val_loss: 0.0123\n",
                        "Epoch 10/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 0.0021 - val_loss: 0.0121\n",
                        "Epoch 11/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 0.0020 - val_loss: 0.0120\n",
                        "Epoch 12/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 0.0020 - val_loss: 0.0118\n",
                        "Epoch 13/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 0.0020 - val_loss: 0.0118\n",
                        "Epoch 14/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 0.0019 - val_loss: 0.0116\n",
                        "Epoch 15/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 0.0019 - val_loss: 0.0115\n",
                        "Epoch 16/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 0.0019 - val_loss: 0.0114\n",
                        "Epoch 17/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 0.0019 - val_loss: 0.0112\n",
                        "Epoch 18/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 0.0018 - val_loss: 0.0111\n",
                        "Epoch 19/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 0.0018 - val_loss: 0.0110\n",
                        "Epoch 20/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 0.0018 - val_loss: 0.0109\n",
                        "Epoch 21/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 0.0018 - val_loss: 0.0108\n",
                        "Epoch 22/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 0.0018 - val_loss: 0.0107\n",
                        "Epoch 23/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 0.0017 - val_loss: 0.0106\n",
                        "Epoch 24/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 0.0017 - val_loss: 0.0104\n",
                        "Epoch 25/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 0.0017 - val_loss: 0.0104\n",
                        "Epoch 26/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 0.0017 - val_loss: 0.0103\n",
                        "Epoch 27/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 0.0017 - val_loss: 0.0102\n",
                        "Epoch 28/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 0.0016 - val_loss: 0.0100\n",
                        "Epoch 29/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 0.0016 - val_loss: 0.0099\n",
                        "Epoch 30/300\n",
                        "116/116 [==============================] - 1s 7ms/step - loss: 0.0016 - val_loss: 0.0098\n",
                        "Epoch 31/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 0.0015 - val_loss: 0.0096\n",
                        "Epoch 32/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 0.0015 - val_loss: 0.0095\n",
                        "Epoch 33/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 0.0015 - val_loss: 0.0094\n",
                        "Epoch 34/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 0.0015 - val_loss: 0.0093\n",
                        "Epoch 35/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 0.0015 - val_loss: 0.0092\n",
                        "Epoch 36/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 0.0014 - val_loss: 0.0090\n",
                        "Epoch 37/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 0.0014 - val_loss: 0.0090\n",
                        "Epoch 38/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 0.0014 - val_loss: 0.0089\n",
                        "Epoch 39/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 0.0014 - val_loss: 0.0087\n",
                        "Epoch 40/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 0.0014 - val_loss: 0.0087\n",
                        "Epoch 41/300\n",
                        "116/116 [==============================] - 1s 7ms/step - loss: 0.0013 - val_loss: 0.0086\n",
                        "Epoch 42/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 0.0013 - val_loss: 0.0085\n",
                        "Epoch 43/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 0.0013 - val_loss: 0.0084\n",
                        "Epoch 44/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 0.0013 - val_loss: 0.0083\n",
                        "Epoch 45/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 0.0013 - val_loss: 0.0082\n",
                        "Epoch 46/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 0.0013 - val_loss: 0.0081\n",
                        "Epoch 47/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0080\n",
                        "Epoch 48/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0079\n",
                        "Epoch 49/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0078\n",
                        "Epoch 50/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0077\n",
                        "Epoch 51/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0076\n",
                        "Epoch 52/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0076\n",
                        "Epoch 53/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0075\n",
                        "Epoch 54/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0074\n",
                        "Epoch 55/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0073\n",
                        "Epoch 56/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0073\n",
                        "Epoch 57/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0071\n",
                        "Epoch 58/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0071\n",
                        "Epoch 59/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0070\n",
                        "Epoch 60/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0069\n",
                        "Epoch 61/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0069\n",
                        "Epoch 62/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0068\n",
                        "Epoch 63/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0067\n",
                        "Epoch 64/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0066\n",
                        "Epoch 65/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0066\n",
                        "Epoch 66/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 9.9215e-04 - val_loss: 0.0065\n",
                        "Epoch 67/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 9.7974e-04 - val_loss: 0.0064\n",
                        "Epoch 68/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 9.6725e-04 - val_loss: 0.0063\n",
                        "Epoch 69/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 9.5473e-04 - val_loss: 0.0062\n",
                        "Epoch 70/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 9.4218e-04 - val_loss: 0.0061\n",
                        "Epoch 71/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 9.2969e-04 - val_loss: 0.0061\n",
                        "Epoch 72/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 9.1715e-04 - val_loss: 0.0060\n",
                        "Epoch 73/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 9.0449e-04 - val_loss: 0.0059\n",
                        "Epoch 74/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 8.9165e-04 - val_loss: 0.0058\n",
                        "Epoch 75/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 8.7859e-04 - val_loss: 0.0058\n",
                        "Epoch 76/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 8.6542e-04 - val_loss: 0.0057\n",
                        "Epoch 77/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 8.5239e-04 - val_loss: 0.0056\n",
                        "Epoch 78/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 8.3963e-04 - val_loss: 0.0055\n",
                        "Epoch 79/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 8.2725e-04 - val_loss: 0.0054\n",
                        "Epoch 80/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 8.1541e-04 - val_loss: 0.0054\n",
                        "Epoch 81/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 8.0412e-04 - val_loss: 0.0053\n",
                        "Epoch 82/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 7.9344e-04 - val_loss: 0.0052\n",
                        "Epoch 83/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 7.8335e-04 - val_loss: 0.0052\n",
                        "Epoch 84/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 7.7374e-04 - val_loss: 0.0051\n",
                        "Epoch 85/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 7.6451e-04 - val_loss: 0.0051\n",
                        "Epoch 86/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 7.5555e-04 - val_loss: 0.0050\n",
                        "Epoch 87/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 7.4687e-04 - val_loss: 0.0050\n",
                        "Epoch 88/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 7.3839e-04 - val_loss: 0.0049\n",
                        "Epoch 89/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 7.3009e-04 - val_loss: 0.0048\n",
                        "Epoch 90/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 7.2199e-04 - val_loss: 0.0048\n",
                        "Epoch 91/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 7.1405e-04 - val_loss: 0.0047\n",
                        "Epoch 92/300\n",
                        "116/116 [==============================] - 1s 7ms/step - loss: 7.0625e-04 - val_loss: 0.0047\n",
                        "Epoch 93/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 6.9859e-04 - val_loss: 0.0046\n",
                        "Epoch 94/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 6.9107e-04 - val_loss: 0.0046\n",
                        "Epoch 95/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 6.8367e-04 - val_loss: 0.0045\n",
                        "Epoch 96/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 6.7639e-04 - val_loss: 0.0045\n",
                        "Epoch 97/300\n",
                        "116/116 [==============================] - 1s 7ms/step - loss: 6.6923e-04 - val_loss: 0.0044\n",
                        "Epoch 98/300\n",
                        "116/116 [==============================] - 1s 7ms/step - loss: 6.6216e-04 - val_loss: 0.0044\n",
                        "Epoch 99/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 6.5520e-04 - val_loss: 0.0043\n",
                        "Epoch 100/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 6.4833e-04 - val_loss: 0.0043\n",
                        "Epoch 101/300\n",
                        "116/116 [==============================] - 1s 7ms/step - loss: 6.4159e-04 - val_loss: 0.0043\n",
                        "Epoch 102/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 6.3490e-04 - val_loss: 0.0042\n",
                        "Epoch 103/300\n",
                        "116/116 [==============================] - 1s 7ms/step - loss: 6.2831e-04 - val_loss: 0.0042\n",
                        "Epoch 104/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 6.2180e-04 - val_loss: 0.0041\n",
                        "Epoch 105/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 6.1535e-04 - val_loss: 0.0041\n",
                        "Epoch 106/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 6.0896e-04 - val_loss: 0.0041\n",
                        "Epoch 107/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 6.0264e-04 - val_loss: 0.0040\n",
                        "Epoch 108/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 5.9636e-04 - val_loss: 0.0040\n",
                        "Epoch 109/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 5.9011e-04 - val_loss: 0.0039\n",
                        "Epoch 110/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 5.8393e-04 - val_loss: 0.0039\n",
                        "Epoch 111/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 5.7778e-04 - val_loss: 0.0039\n",
                        "Epoch 112/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 5.7166e-04 - val_loss: 0.0038\n",
                        "Epoch 113/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 5.6555e-04 - val_loss: 0.0038\n",
                        "Epoch 114/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 5.5949e-04 - val_loss: 0.0038\n",
                        "Epoch 115/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 5.5343e-04 - val_loss: 0.0037\n",
                        "Epoch 116/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 5.4739e-04 - val_loss: 0.0037\n",
                        "Epoch 117/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 5.4137e-04 - val_loss: 0.0036\n",
                        "Epoch 118/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 5.3535e-04 - val_loss: 0.0036\n",
                        "Epoch 119/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 5.2934e-04 - val_loss: 0.0036\n",
                        "Epoch 120/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 5.2335e-04 - val_loss: 0.0035\n",
                        "Epoch 121/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 5.1738e-04 - val_loss: 0.0035\n",
                        "Epoch 122/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 5.1144e-04 - val_loss: 0.0035\n",
                        "Epoch 123/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 5.0557e-04 - val_loss: 0.0034\n",
                        "Epoch 124/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 4.9976e-04 - val_loss: 0.0034\n",
                        "Epoch 125/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 4.9401e-04 - val_loss: 0.0034\n",
                        "Epoch 126/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 4.8833e-04 - val_loss: 0.0033\n",
                        "Epoch 127/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 4.8272e-04 - val_loss: 0.0033\n",
                        "Epoch 128/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 4.7721e-04 - val_loss: 0.0033\n",
                        "Epoch 129/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 4.7177e-04 - val_loss: 0.0033\n",
                        "Epoch 130/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 4.6645e-04 - val_loss: 0.0032\n",
                        "Epoch 131/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 4.6120e-04 - val_loss: 0.0032\n",
                        "Epoch 132/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 4.5606e-04 - val_loss: 0.0032\n",
                        "Epoch 133/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 4.5100e-04 - val_loss: 0.0031\n",
                        "Epoch 134/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 4.4604e-04 - val_loss: 0.0031\n",
                        "Epoch 135/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 4.4117e-04 - val_loss: 0.0031\n",
                        "Epoch 136/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 4.3640e-04 - val_loss: 0.0030\n",
                        "Epoch 137/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 4.3170e-04 - val_loss: 0.0030\n",
                        "Epoch 138/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 4.2711e-04 - val_loss: 0.0030\n",
                        "Epoch 139/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 4.2261e-04 - val_loss: 0.0030\n",
                        "Epoch 140/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 4.1818e-04 - val_loss: 0.0029\n",
                        "Epoch 141/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 4.1383e-04 - val_loss: 0.0029\n",
                        "Epoch 142/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 4.0957e-04 - val_loss: 0.0029\n",
                        "Epoch 143/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 4.0538e-04 - val_loss: 0.0028\n",
                        "Epoch 144/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 4.0126e-04 - val_loss: 0.0028\n",
                        "Epoch 145/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 3.9722e-04 - val_loss: 0.0028\n",
                        "Epoch 146/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 3.9325e-04 - val_loss: 0.0028\n",
                        "Epoch 147/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 3.8936e-04 - val_loss: 0.0027\n",
                        "Epoch 148/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 3.8551e-04 - val_loss: 0.0027\n",
                        "Epoch 149/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 3.8174e-04 - val_loss: 0.0027\n",
                        "Epoch 150/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 3.7803e-04 - val_loss: 0.0027\n",
                        "Epoch 151/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 3.7440e-04 - val_loss: 0.0026\n",
                        "Epoch 152/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 3.7081e-04 - val_loss: 0.0026\n",
                        "Epoch 153/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 3.6728e-04 - val_loss: 0.0026\n",
                        "Epoch 154/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 3.6381e-04 - val_loss: 0.0026\n",
                        "Epoch 155/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 3.6041e-04 - val_loss: 0.0025\n",
                        "Epoch 156/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 3.5705e-04 - val_loss: 0.0025\n",
                        "Epoch 157/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 3.5375e-04 - val_loss: 0.0025\n",
                        "Epoch 158/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 3.5050e-04 - val_loss: 0.0025\n",
                        "Epoch 159/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 3.4731e-04 - val_loss: 0.0025\n",
                        "Epoch 160/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 3.4416e-04 - val_loss: 0.0024\n",
                        "Epoch 161/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 3.4107e-04 - val_loss: 0.0024\n",
                        "Epoch 162/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 3.3802e-04 - val_loss: 0.0024\n",
                        "Epoch 163/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 3.3503e-04 - val_loss: 0.0024\n",
                        "Epoch 164/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 3.3209e-04 - val_loss: 0.0024\n",
                        "Epoch 165/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 3.2919e-04 - val_loss: 0.0023\n",
                        "Epoch 166/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 3.2633e-04 - val_loss: 0.0023\n",
                        "Epoch 167/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 3.2352e-04 - val_loss: 0.0023\n",
                        "Epoch 168/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 3.2076e-04 - val_loss: 0.0023\n",
                        "Epoch 169/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 3.1803e-04 - val_loss: 0.0023\n",
                        "Epoch 170/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 3.1535e-04 - val_loss: 0.0022\n",
                        "Epoch 171/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 3.1271e-04 - val_loss: 0.0022\n",
                        "Epoch 172/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 3.1010e-04 - val_loss: 0.0022\n",
                        "Epoch 173/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 3.0754e-04 - val_loss: 0.0022\n",
                        "Epoch 174/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 3.0502e-04 - val_loss: 0.0022\n",
                        "Epoch 175/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 3.0253e-04 - val_loss: 0.0021\n",
                        "Epoch 176/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 3.0009e-04 - val_loss: 0.0021\n",
                        "Epoch 177/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 2.9767e-04 - val_loss: 0.0021\n",
                        "Epoch 178/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 2.9530e-04 - val_loss: 0.0021\n",
                        "Epoch 179/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 2.9296e-04 - val_loss: 0.0021\n",
                        "Epoch 180/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 2.9066e-04 - val_loss: 0.0021\n",
                        "Epoch 181/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 2.8839e-04 - val_loss: 0.0021\n",
                        "Epoch 182/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 2.8616e-04 - val_loss: 0.0020\n",
                        "Epoch 183/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 2.8396e-04 - val_loss: 0.0020\n",
                        "Epoch 184/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 2.8178e-04 - val_loss: 0.0020\n",
                        "Epoch 185/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 2.7964e-04 - val_loss: 0.0020\n",
                        "Epoch 186/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 2.7755e-04 - val_loss: 0.0020\n",
                        "Epoch 187/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 2.7547e-04 - val_loss: 0.0020\n",
                        "Epoch 188/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 2.7343e-04 - val_loss: 0.0019\n",
                        "Epoch 189/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 2.7141e-04 - val_loss: 0.0019\n",
                        "Epoch 190/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 2.6943e-04 - val_loss: 0.0019\n",
                        "Epoch 191/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 2.6747e-04 - val_loss: 0.0019\n",
                        "Epoch 192/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 2.6555e-04 - val_loss: 0.0019\n",
                        "Epoch 193/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 2.6364e-04 - val_loss: 0.0019\n",
                        "Epoch 194/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 2.6177e-04 - val_loss: 0.0019\n",
                        "Epoch 195/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 2.5992e-04 - val_loss: 0.0018\n",
                        "Epoch 196/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 2.5811e-04 - val_loss: 0.0018\n",
                        "Epoch 197/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 2.5632e-04 - val_loss: 0.0018\n",
                        "Epoch 198/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 2.5455e-04 - val_loss: 0.0018\n",
                        "Epoch 199/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 2.5281e-04 - val_loss: 0.0018\n",
                        "Epoch 200/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 2.5108e-04 - val_loss: 0.0018\n",
                        "Epoch 201/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 2.4939e-04 - val_loss: 0.0018\n",
                        "Epoch 202/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 2.4772e-04 - val_loss: 0.0018\n",
                        "Epoch 203/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 2.4607e-04 - val_loss: 0.0018\n",
                        "Epoch 204/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 2.4445e-04 - val_loss: 0.0017\n",
                        "Epoch 205/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 2.4284e-04 - val_loss: 0.0017\n",
                        "Epoch 206/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 2.4126e-04 - val_loss: 0.0017\n",
                        "Epoch 207/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 2.3971e-04 - val_loss: 0.0017\n",
                        "Epoch 208/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 2.3817e-04 - val_loss: 0.0017\n",
                        "Epoch 209/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 2.3665e-04 - val_loss: 0.0017\n",
                        "Epoch 210/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 2.3517e-04 - val_loss: 0.0017\n",
                        "Epoch 211/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 2.3369e-04 - val_loss: 0.0017\n",
                        "Epoch 212/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 2.3223e-04 - val_loss: 0.0017\n",
                        "Epoch 213/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 2.3080e-04 - val_loss: 0.0017\n",
                        "Epoch 214/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 2.2939e-04 - val_loss: 0.0016\n",
                        "Epoch 215/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 2.2800e-04 - val_loss: 0.0016\n",
                        "Epoch 216/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 2.2662e-04 - val_loss: 0.0016\n",
                        "Epoch 217/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 2.2526e-04 - val_loss: 0.0016\n",
                        "Epoch 218/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 2.2392e-04 - val_loss: 0.0016\n",
                        "Epoch 219/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 2.2260e-04 - val_loss: 0.0016\n",
                        "Epoch 220/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 2.2130e-04 - val_loss: 0.0016\n",
                        "Epoch 221/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 2.2001e-04 - val_loss: 0.0016\n",
                        "Epoch 222/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 2.1874e-04 - val_loss: 0.0016\n",
                        "Epoch 223/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 2.1749e-04 - val_loss: 0.0016\n",
                        "Epoch 224/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 2.1626e-04 - val_loss: 0.0016\n",
                        "Epoch 225/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 2.1504e-04 - val_loss: 0.0015\n",
                        "Epoch 226/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 2.1384e-04 - val_loss: 0.0015\n",
                        "Epoch 227/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 2.1266e-04 - val_loss: 0.0015\n",
                        "Epoch 228/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 2.1148e-04 - val_loss: 0.0015\n",
                        "Epoch 229/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 2.1033e-04 - val_loss: 0.0015\n",
                        "Epoch 230/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 2.0920e-04 - val_loss: 0.0015\n",
                        "Epoch 231/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 2.0807e-04 - val_loss: 0.0015\n",
                        "Epoch 232/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 2.0696e-04 - val_loss: 0.0015\n",
                        "Epoch 233/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 2.0587e-04 - val_loss: 0.0015\n",
                        "Epoch 234/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 2.0479e-04 - val_loss: 0.0015\n",
                        "Epoch 235/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 2.0373e-04 - val_loss: 0.0015\n",
                        "Epoch 236/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 2.0268e-04 - val_loss: 0.0015\n",
                        "Epoch 237/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 2.0164e-04 - val_loss: 0.0015\n",
                        "Epoch 238/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 2.0062e-04 - val_loss: 0.0014\n",
                        "Epoch 239/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 1.9960e-04 - val_loss: 0.0014\n",
                        "Epoch 240/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 1.9861e-04 - val_loss: 0.0014\n",
                        "Epoch 241/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 1.9762e-04 - val_loss: 0.0014\n",
                        "Epoch 242/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 1.9665e-04 - val_loss: 0.0014\n",
                        "Epoch 243/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 1.9569e-04 - val_loss: 0.0014\n",
                        "Epoch 244/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 1.9474e-04 - val_loss: 0.0014\n",
                        "Epoch 245/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 1.9380e-04 - val_loss: 0.0014\n",
                        "Epoch 246/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 1.9287e-04 - val_loss: 0.0014\n",
                        "Epoch 247/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 1.9196e-04 - val_loss: 0.0014\n",
                        "Epoch 248/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 1.9106e-04 - val_loss: 0.0014\n",
                        "Epoch 249/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 1.9017e-04 - val_loss: 0.0014\n",
                        "Epoch 250/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 1.8929e-04 - val_loss: 0.0014\n",
                        "Epoch 251/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 1.8842e-04 - val_loss: 0.0014\n",
                        "Epoch 252/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 1.8756e-04 - val_loss: 0.0014\n",
                        "Epoch 253/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 1.8672e-04 - val_loss: 0.0014\n",
                        "Epoch 254/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 1.8588e-04 - val_loss: 0.0013\n",
                        "Epoch 255/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 1.8505e-04 - val_loss: 0.0013\n",
                        "Epoch 256/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 1.8423e-04 - val_loss: 0.0013\n",
                        "Epoch 257/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 1.8342e-04 - val_loss: 0.0013\n",
                        "Epoch 258/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 1.8263e-04 - val_loss: 0.0013\n",
                        "Epoch 259/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 1.8184e-04 - val_loss: 0.0013\n",
                        "Epoch 260/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 1.8106e-04 - val_loss: 0.0013\n",
                        "Epoch 261/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 1.8030e-04 - val_loss: 0.0013\n",
                        "Epoch 262/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 1.7953e-04 - val_loss: 0.0013\n",
                        "Epoch 263/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 1.7879e-04 - val_loss: 0.0013\n",
                        "Epoch 264/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 1.7805e-04 - val_loss: 0.0013\n",
                        "Epoch 265/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 1.7732e-04 - val_loss: 0.0013\n",
                        "Epoch 266/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 1.7659e-04 - val_loss: 0.0013\n",
                        "Epoch 267/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 1.7588e-04 - val_loss: 0.0013\n",
                        "Epoch 268/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 1.7517e-04 - val_loss: 0.0013\n",
                        "Epoch 269/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 1.7448e-04 - val_loss: 0.0013\n",
                        "Epoch 270/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 1.7378e-04 - val_loss: 0.0013\n",
                        "Epoch 271/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 1.7310e-04 - val_loss: 0.0013\n",
                        "Epoch 272/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 1.7243e-04 - val_loss: 0.0013\n",
                        "Epoch 273/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 1.7177e-04 - val_loss: 0.0013\n",
                        "Epoch 274/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 1.7110e-04 - val_loss: 0.0013\n",
                        "Epoch 275/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 1.7046e-04 - val_loss: 0.0012\n",
                        "Epoch 276/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 1.6981e-04 - val_loss: 0.0012\n",
                        "Epoch 277/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 1.6918e-04 - val_loss: 0.0012\n",
                        "Epoch 278/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 1.6855e-04 - val_loss: 0.0012\n",
                        "Epoch 279/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 1.6793e-04 - val_loss: 0.0012\n",
                        "Epoch 280/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 1.6731e-04 - val_loss: 0.0012\n",
                        "Epoch 281/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 1.6671e-04 - val_loss: 0.0012\n",
                        "Epoch 282/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 1.6611e-04 - val_loss: 0.0012\n",
                        "Epoch 283/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 1.6551e-04 - val_loss: 0.0012\n",
                        "Epoch 284/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 1.6493e-04 - val_loss: 0.0012\n",
                        "Epoch 285/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 1.6435e-04 - val_loss: 0.0012\n",
                        "Epoch 286/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 1.6377e-04 - val_loss: 0.0012\n",
                        "Epoch 287/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 1.6321e-04 - val_loss: 0.0012\n",
                        "Epoch 288/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 1.6264e-04 - val_loss: 0.0012\n",
                        "Epoch 289/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 1.6209e-04 - val_loss: 0.0012\n",
                        "Epoch 290/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 1.6154e-04 - val_loss: 0.0012\n",
                        "Epoch 291/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 1.6100e-04 - val_loss: 0.0012\n",
                        "Epoch 292/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 1.6046e-04 - val_loss: 0.0012\n",
                        "Epoch 293/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 1.5993e-04 - val_loss: 0.0012\n",
                        "Epoch 294/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 1.5940e-04 - val_loss: 0.0012\n",
                        "Epoch 295/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 1.5889e-04 - val_loss: 0.0012\n",
                        "Epoch 296/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 1.5837e-04 - val_loss: 0.0012\n",
                        "Epoch 297/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 1.5786e-04 - val_loss: 0.0012\n",
                        "Epoch 298/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 1.5736e-04 - val_loss: 0.0012\n",
                        "Epoch 299/300\n",
                        "116/116 [==============================] - 1s 5ms/step - loss: 1.5686e-04 - val_loss: 0.0012\n",
                        "Epoch 300/300\n",
                        "116/116 [==============================] - 1s 6ms/step - loss: 1.5636e-04 - val_loss: 0.0012\n"
                    ]
                }
            ],
            "source": [
                " es = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss',  mode = 'min', verbose = 1, patience = 50);\n",
                " np.random.seed(1)\n",
                " history = model1.fit(x = scaled_x, y = y, batch_size=512, epochs=300, verbose = 1, validation_split = 0.1, callbacks= [es]);"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 180,
            "metadata": {},
            "outputs": [],
            "source": [
                "var = 'x_y_xy'"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 181,
            "metadata": {},
            "outputs": [],
            "source": [
                "# loss = pd.DataFrame(model1.history.history);"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 182,
            "metadata": {},
            "outputs": [],
            "source": [
                "# plt.plot(history.history['loss'])\n",
                "# plt.plot(history.history['val_loss'])\n",
                "# plt.title('train_loss', fontsize=15)\n",
                "# plt.ylabel('Loss', fontsize=15)\n",
                "# plt.xlabel('Epoch', fontsize=15)\n",
                "# plt.legend(['train', 'val'], loc='upper right')\n",
                "# plt.xticks(fontsize=15)\n",
                "# plt.yticks(fontsize=15)\n",
                "# plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 183,
            "metadata": {},
            "outputs": [],
            "source": [
                "# print(loss.head());"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 184,
            "metadata": {},
            "outputs": [],
            "source": [
                "#  model_json = model1.to_json();\n",
                "#  with open('Saved_model/train_model1_ref_'+var+'.json', 'w') as json_file:\n",
                "#      json_file.write(model_json);\n",
                "#  #serialize weights to HDF5 file\n",
                "#  model1.save_weights('Saved_model/train_model1_ref_'+var+'.h5')\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 185,
            "metadata": {},
            "outputs": [],
            "source": [
                " #Model With different Optimizer.\n",
                " model_json = model1.to_json();\n",
                " with open('Model/Model1/SGD_'+var+'.json', 'w') as json_file:\n",
                "     json_file.write(model_json);\n",
                " #serialize weights to HDF5 file\n",
                " model1.save_weights('Model/Model1/SGD_'+var+'.h5')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": 186,
            "metadata": {},
            "outputs": [],
            "source": [
                "# load json and create model\n",
                "# json_file = open('Saved_model/train_model1_ref_'+var+'.json', 'r')\n",
                "# loaded_model_json = json_file.read()\n",
                "# json_file.close()\n",
                "# loaded_model = model_from_json(loaded_model_json);\n",
                "\n",
                "# #load weights into new model\n",
                "# loaded_model.load_weights('Saved_model/train_model1_ref_'+var+'.h5') "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 187,
            "metadata": {},
            "outputs": [],
            "source": [
                "#load json and create model for different optimizer.\n",
                "json_file = open('Model/Model1/SGD_x_y_xy.json', 'r')\n",
                "loaded_model_json = json_file.read()\n",
                "json_file.close()\n",
                "loaded_model = model_from_json(loaded_model_json);\n",
                "\n",
                "#load weights into new model\n",
                "loaded_model.load_weights('Model/Model1/SGD_x_y_xy.h5') "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 188,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Stress calculation at Gauss points\n",
                "stress = np.zeros((nel, ngp2d*ngp2d, 3))\n",
                "strains = np.zeros((nel, ngp2d*ngp2d, 3))\n",
                "\n",
                "for i in range(nel):\n",
                "    stress_i_g = np.zeros((ngp2d*ngp2d, 3))\n",
                "    strains_i_g = np.zeros((ngp2d*ngp2d, 3))\n",
                "\n",
                "    stress_i_g, strains_i_g = stress_gauss.get_element_stress(\n",
                "        i, ngp2d, el_type_q4, connect, coord, u, C)\n",
                "\n",
                "    stress[i][:][:] = stress_i_g\n",
                "    strains[i][:][:] = strains_i_g.reshape((1, 3))\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 189,
            "metadata": {},
            "outputs": [],
            "source": [
                "# calcuation of gauss coordinates.\n",
                "gauss_coords = np.zeros((nel, ngp2d*ngp2d, 2))\n",
                "gp, weights = quadrature.quadrature(ngp2d);\n",
                "for i in range(nel):\n",
                "    node = connect[i, :]\n",
                "    vertex_coord = coord[node, :].reshape(-1);\n",
                "    gauss_coords[i][:][:] = gauss_pt_coord.gauss_pts(ngp2d, vertex_coord, gp, el_type);\n",
                "gauss_coords = gauss_coords.reshape(gauss_coords.shape[0], -1);\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 190,
            "metadata": {},
            "outputs": [],
            "source": [
                "#creation of patches for spr_stress;\n",
                "patch, n_patches, int_nodes = patch_n_int_nodes.patch_n_int_nodes(ms)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 191,
            "metadata": {},
            "outputs": [],
            "source": [
                "#spr_stress STRESS Calculations\n",
                "stress_spr = spr_stress.spr(gauss_coords, coord, connect, stress,\n",
                "                     int_nodes, n_patches, patch, ms)\n",
                "# stress_spr\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 192,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Directly calculated stress\n",
                "stress_dc, strain_dc = stress_nodes_dc.stress_dc(\n",
                "    connect, coord, u, nel, el_type, C);\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 193,
            "metadata": {},
            "outputs": [],
            "source": [
                "# coord\n",
                "# np.random.seed(1);\n",
                "# pts = np.random.choice(np.arange(36),5);\n",
                "# coord_test = coord[pts];\n",
                "# coord_test\n",
                "# stress_spr\n",
                "total_nodes = (ms+1)**2\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 194,
            "metadata": {},
            "outputs": [],
            "source": [
                "#outter points in\n",
                "sp = []\n",
                "# print(ms)\n",
                "temp = ms+1\n",
                "for i in range(ms-1):\n",
                "    sp.append(temp)\n",
                "    sp.append(temp+ms)\n",
                "    temp = temp+ms+1\n",
                "for i in range(ms+1):\n",
                "    sp.append(temp)\n",
                "    temp = temp+1\n",
                "\n",
                "for i in range(ms+1):\n",
                "    sp.append(i)\n",
                "\n",
                "sp = sorted(sp)\n",
                "# print(sp);\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 195,
            "metadata": {},
            "outputs": [],
            "source": [
                "coord_corner = coord[sp]\n",
                "# coord_corner"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 196,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/krishna/Desktop/btp_499_code/btp_env/lib/python3.10/site-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
                        "  warnings.warn(\n"
                    ]
                }
            ],
            "source": [
                "scaled_test_corner = scaler.transform(coord_corner)\n",
                "# scaled_test_corner"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 197,
            "metadata": {},
            "outputs": [],
            "source": [
                "ref_stress = pd.read_csv('Ref/ref_stress_for_ms_5_from_320.csv');\n",
                "ref_stress = ref_stress.loc[:, ~ref_stress.columns.str.contains('^Unnamed')];\n",
                "ref_stress = ref_stress.to_numpy();\n",
                "# ref_stress"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 198,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "3\n"
                    ]
                }
            ],
            "source": [
                "# a ---->reference stress \n",
                "a = ref_stress.T\n",
                "print(len(a));\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 199,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "3\n"
                    ]
                }
            ],
            "source": [
                "# a--->plane stress calculated from spr\n",
                "b = stress_spr.T\n",
                "print(len(b))\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 200,
            "metadata": {},
            "outputs": [],
            "source": [
                "err_spr_abs = np.abs((a-b));\n",
                "err_spr_perc = np.abs((a-b)/a);\n",
                "err_dc_abs = np.abs((a-stress_dc.T));\n",
                "err_dc_perc = np.abs((a-stress_dc.T)/a);\n",
                "# err_spr_abs\n",
                "# err_dc_abs"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 201,
            "metadata": {},
            "outputs": [],
            "source": [
                "test = pd.DataFrame(scaled_test, columns =['a', 'b']);\n",
                "# test"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 202,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "2/2 [==============================] - 0s 5ms/step\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "36"
                        ]
                    },
                    "execution_count": 202,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# c --->stress calculated using ANN trained model\n",
                "c = loaded_model.predict(test);\n",
                "len(c)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 203,
            "metadata": {},
            "outputs": [],
            "source": [
                "err_ann_abs = np.abs((a-c.T))\n",
                "err_ann_perc = np.abs((a-c.T)/a)\n",
                "# err_ann_abs"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 204,
            "metadata": {},
            "outputs": [],
            "source": [
                "# print(b.shape[0]);"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 205,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "alll = np.concatenate([coord, \n",
                "                        a.reshape(a.T.shape[0], 3), \n",
                "                        b.reshape(b.T.shape[0], 3), \n",
                "                        c.reshape(c.shape[0], 3), \n",
                "                        err_spr_abs.reshape(err_spr_abs.T.shape[0], 3), \n",
                "                        err_ann_abs.reshape(err_ann_abs.T.shape[0],3), \n",
                "                        err_dc_abs.reshape(err_dc_abs.T.shape[0],3),\n",
                "                        err_spr_perc.reshape(err_spr_perc.T.shape[0],3),\n",
                "                        err_ann_perc.reshape(err_ann_perc.T.shape[0],3),\n",
                "                        err_dc_perc.reshape(err_dc_perc.T.shape[0],3) \n",
                "                        ], \n",
                "                        axis = 1);\n",
                "# alll"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 206,
            "metadata": {},
            "outputs": [],
            "source": [
                "tdf =pd.DataFrame(alll, columns=['x', \n",
                "                                'y', \n",
                "                                'ref_stress_x',\n",
                "                                'ref_stress_y',\n",
                "                                'ref_stress_xy', \n",
                "                                'spr_stress_x',\n",
                "                                'spr_stress_y',\n",
                "                                'spr_stress_xy', \n",
                "                                'ann_stress_x',\n",
                "                                'ann_stress_y',\n",
                "                                'ann_stress_xy', \n",
                "                                'err_spr_abs_x',\n",
                "                                'err_spr_abs_y',\n",
                "                                'err_spr_abs_xy', \n",
                "                                'err_ann_abs_x',\n",
                "                                'err_ann_abs_y',\n",
                "                                'err_ann_abs_xy', \n",
                "                                'err_dc_abs_x',\n",
                "                                'err_dc_abs_y',\n",
                "                                'err_dc_abs_xy',\n",
                "                                'err_spr_perc_x',\n",
                "                                'err_spr_perc_y',\n",
                "                                'err_spr_perc_xy', \n",
                "                                'err_ann_perc_x',\n",
                "                                'err_ann_perc_y',\n",
                "                                'err_ann_perc_xy', \n",
                "                                'err_dc_perc_x',\n",
                "                                'err_dc_perc_y',\n",
                "                                'err_dc_perc_xy'\n",
                "                                ]);\n",
                "# print(tdf.head());"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 207,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>x</th>\n",
                            "      <th>y</th>\n",
                            "      <th>ref_stress_x</th>\n",
                            "      <th>ref_stress_y</th>\n",
                            "      <th>ref_stress_xy</th>\n",
                            "      <th>spr_stress_x</th>\n",
                            "      <th>spr_stress_y</th>\n",
                            "      <th>spr_stress_xy</th>\n",
                            "      <th>ann_stress_x</th>\n",
                            "      <th>ann_stress_y</th>\n",
                            "      <th>...</th>\n",
                            "      <th>err_dc_abs_xy</th>\n",
                            "      <th>err_spr_perc_x</th>\n",
                            "      <th>err_spr_perc_y</th>\n",
                            "      <th>err_spr_perc_xy</th>\n",
                            "      <th>err_ann_perc_x</th>\n",
                            "      <th>err_ann_perc_y</th>\n",
                            "      <th>err_ann_perc_xy</th>\n",
                            "      <th>err_dc_perc_x</th>\n",
                            "      <th>err_dc_perc_y</th>\n",
                            "      <th>err_dc_perc_xy</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.020590</td>\n",
                            "      <td>0.066856</td>\n",
                            "      <td>0.114837</td>\n",
                            "      <td>0.063443</td>\n",
                            "      <td>0.059761</td>\n",
                            "      <td>0.057295</td>\n",
                            "      <td>0.069542</td>\n",
                            "      <td>0.026373</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0.003450</td>\n",
                            "      <td>2.081206</td>\n",
                            "      <td>0.106128</td>\n",
                            "      <td>0.501073</td>\n",
                            "      <td>2.377417</td>\n",
                            "      <td>0.443747</td>\n",
                            "      <td>0.002641</td>\n",
                            "      <td>2.244944</td>\n",
                            "      <td>0.033750</td>\n",
                            "      <td>0.030039</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>9.6</td>\n",
                            "      <td>8.8</td>\n",
                            "      <td>0.142259</td>\n",
                            "      <td>0.142736</td>\n",
                            "      <td>0.116694</td>\n",
                            "      <td>0.060733</td>\n",
                            "      <td>0.062001</td>\n",
                            "      <td>0.065805</td>\n",
                            "      <td>0.096523</td>\n",
                            "      <td>0.032084</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0.285664</td>\n",
                            "      <td>0.573084</td>\n",
                            "      <td>0.565624</td>\n",
                            "      <td>0.436090</td>\n",
                            "      <td>0.171162</td>\n",
                            "      <td>0.290079</td>\n",
                            "      <td>0.459584</td>\n",
                            "      <td>0.489825</td>\n",
                            "      <td>0.133649</td>\n",
                            "      <td>2.447965</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>19.2</td>\n",
                            "      <td>17.6</td>\n",
                            "      <td>0.073042</td>\n",
                            "      <td>0.093437</td>\n",
                            "      <td>0.099048</td>\n",
                            "      <td>0.063212</td>\n",
                            "      <td>0.086114</td>\n",
                            "      <td>0.096941</td>\n",
                            "      <td>0.114533</td>\n",
                            "      <td>0.056490</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0.017992</td>\n",
                            "      <td>0.134571</td>\n",
                            "      <td>0.078366</td>\n",
                            "      <td>0.021269</td>\n",
                            "      <td>0.145262</td>\n",
                            "      <td>0.003276</td>\n",
                            "      <td>0.050526</td>\n",
                            "      <td>0.192864</td>\n",
                            "      <td>0.120837</td>\n",
                            "      <td>0.181649</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>28.8</td>\n",
                            "      <td>26.4</td>\n",
                            "      <td>0.094280</td>\n",
                            "      <td>0.076036</td>\n",
                            "      <td>0.014692</td>\n",
                            "      <td>0.093381</td>\n",
                            "      <td>0.065664</td>\n",
                            "      <td>0.014115</td>\n",
                            "      <td>0.117910</td>\n",
                            "      <td>0.079845</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0.006585</td>\n",
                            "      <td>0.009532</td>\n",
                            "      <td>0.136410</td>\n",
                            "      <td>0.039297</td>\n",
                            "      <td>0.023913</td>\n",
                            "      <td>0.120338</td>\n",
                            "      <td>1.586548</td>\n",
                            "      <td>0.152581</td>\n",
                            "      <td>0.531915</td>\n",
                            "      <td>0.448163</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>38.4</td>\n",
                            "      <td>35.2</td>\n",
                            "      <td>0.080207</td>\n",
                            "      <td>0.072637</td>\n",
                            "      <td>0.051343</td>\n",
                            "      <td>0.027299</td>\n",
                            "      <td>0.068231</td>\n",
                            "      <td>0.050842</td>\n",
                            "      <td>0.101331</td>\n",
                            "      <td>0.091348</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0.007476</td>\n",
                            "      <td>0.659641</td>\n",
                            "      <td>0.060657</td>\n",
                            "      <td>0.009764</td>\n",
                            "      <td>0.190699</td>\n",
                            "      <td>0.012768</td>\n",
                            "      <td>0.025842</td>\n",
                            "      <td>0.028527</td>\n",
                            "      <td>0.229736</td>\n",
                            "      <td>0.145609</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "<p>5 rows  29 columns</p>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "      x     y  ref_stress_x  ref_stress_y  ref_stress_xy  spr_stress_x  \\\n",
                            "0   0.0   0.0      0.020590      0.066856       0.114837      0.063443   \n",
                            "1   9.6   8.8      0.142259      0.142736       0.116694      0.060733   \n",
                            "2  19.2  17.6      0.073042      0.093437       0.099048      0.063212   \n",
                            "3  28.8  26.4      0.094280      0.076036       0.014692      0.093381   \n",
                            "4  38.4  35.2      0.080207      0.072637       0.051343      0.027299   \n",
                            "\n",
                            "   spr_stress_y  spr_stress_xy  ann_stress_x  ann_stress_y  ...  \\\n",
                            "0      0.059761       0.057295      0.069542      0.026373  ...   \n",
                            "1      0.062001       0.065805      0.096523      0.032084  ...   \n",
                            "2      0.086114       0.096941      0.114533      0.056490  ...   \n",
                            "3      0.065664       0.014115      0.117910      0.079845  ...   \n",
                            "4      0.068231       0.050842      0.101331      0.091348  ...   \n",
                            "\n",
                            "   err_dc_abs_xy  err_spr_perc_x  err_spr_perc_y  err_spr_perc_xy  \\\n",
                            "0       0.003450        2.081206        0.106128         0.501073   \n",
                            "1       0.285664        0.573084        0.565624         0.436090   \n",
                            "2       0.017992        0.134571        0.078366         0.021269   \n",
                            "3       0.006585        0.009532        0.136410         0.039297   \n",
                            "4       0.007476        0.659641        0.060657         0.009764   \n",
                            "\n",
                            "   err_ann_perc_x  err_ann_perc_y  err_ann_perc_xy  err_dc_perc_x  \\\n",
                            "0        2.377417        0.443747         0.002641       2.244944   \n",
                            "1        0.171162        0.290079         0.459584       0.489825   \n",
                            "2        0.145262        0.003276         0.050526       0.192864   \n",
                            "3        0.023913        0.120338         1.586548       0.152581   \n",
                            "4        0.190699        0.012768         0.025842       0.028527   \n",
                            "\n",
                            "   err_dc_perc_y  err_dc_perc_xy  \n",
                            "0       0.033750        0.030039  \n",
                            "1       0.133649        2.447965  \n",
                            "2       0.120837        0.181649  \n",
                            "3       0.531915        0.448163  \n",
                            "4       0.229736        0.145609  \n",
                            "\n",
                            "[5 rows x 29 columns]"
                        ]
                    },
                    "execution_count": 207,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "tdf.to_csv('mult_e_data/ms5/all_matlab_train_model1_ref_'+var+'.csv');\n",
                "tdf.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 208,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "0.6860461513578601"
                        ]
                    },
                    "execution_count": 208,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "tdf['err_spr_perc_x'].mean()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 209,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "0.32947246179473"
                        ]
                    },
                    "execution_count": 209,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "tdf['err_spr_perc_y'].mean()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 210,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "0.5658925933085241"
                        ]
                    },
                    "execution_count": 210,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "tdf['err_spr_perc_xy'].mean()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 211,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "0.5643268966684017"
                        ]
                    },
                    "execution_count": 211,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "tdf['err_ann_perc_x'].mean()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 212,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "0.43204254104027684"
                        ]
                    },
                    "execution_count": 212,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "tdf['err_ann_perc_y'].mean()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 213,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "0.5718885658531502"
                        ]
                    },
                    "execution_count": 213,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "tdf['err_ann_perc_xy'].mean()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "btp_env",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.6"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "bc5ee6968e4085bd90f0c9ab40e7d6ac03ca6327ccf856e0c00d97cd6ebd91ac"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
