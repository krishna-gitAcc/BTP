{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import displacement_solver\n",
    "import constitutive\n",
    "import mesh_gen\n",
    "import quadrature\n",
    "import stress_gauss\n",
    "import patch_n_int_nodes\n",
    "import gauss_pt_coord\n",
    "import stress_nodes_dc\n",
    "import spr_stress\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ............................Inputs Parameters......................#\n",
    "\n",
    "#Doamin geometry\n",
    "domain_coord = np.array([[2, 0], [20, 0], [20, 10], [0, 10], [0, 2]]);\n",
    "\n",
    "# Body force components\n",
    "b = np.array([[0], [0]])\n",
    "\n",
    "# Traction Components\n",
    "q = 1/8      #unirt force for unit length\n",
    "\n",
    "T = np.array([[q, 0]]);\n",
    "\n",
    "# Young's modulus\n",
    "E = 1.0\n",
    "\n",
    "# Poission's ration\n",
    "nu = 1/3;\n",
    "\n",
    "# problem type (0--->plane stress, 1---->plane strain)\n",
    "problem_type = 0;\n",
    "\n",
    "#Element type used for meshing (0---->4 nodes quadrilateral)\n",
    "el_type = 0;\n",
    "\n",
    "# No. of Gauss points required forintegration\n",
    "ngp2d = 1;\n",
    "ngp1d = 2;\n",
    "\n",
    "# Number of mesh in one direction.\n",
    "N = 5;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = displacement_solver.solve_fem_plat_with_hole(N, E, nu, ngp2d, ngp1d, el_type, problem_type, domain_coord, b, T)\n",
    "# print(u_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ms = mesh size ----> Number of element in one direction\n",
    "ms = N;\n",
    "\n",
    "#total number of elements\n",
    "nel = 2*ms*ms \n",
    "\n",
    "# reshaping u into u_nodes with displacement in x-direction in first column and y-direciton in second column\n",
    "u_nodes = u.reshape((2*(ms+1)*(ms+1)-(ms+1), 2))\n",
    "# print(u_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constitutive relation matrix, calculated using the fuction \"Constitutube\" with input E->(Young's Modulus), nu(Poisson's raton), problem_type(plane stress or plane strain)\n",
    "C = constitutive.constitutive(E, nu, problem_type)\n",
    "# print(C);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mesh generation \n",
    "nx = ms #number of element in x-direction\n",
    "ny = ms #number of element in y-direction\n",
    "\n",
    "# el_type = element type specifiedc. 0----> q4, q-----> q8, 2-----> q9\n",
    "el_type = 0;\n",
    "\n",
    "#mesh_obj = object created to calculated nodal coordinates ans connectivity array using functon \"connectivity\" and \"coord_array\" \n",
    "#input nx->number of element in x-direction, xy->number of element in y-direction, domain_coord->coordinates of the corner points and mid-points of the cook's skew beam problem, el_type->element type specidied.\n",
    "\n",
    "mesh_obj = mesh_gen.platWithHole(nx, ny, domain_coord.reshape(10, 1), el_type);\n",
    "connect = mesh_obj.connectivity();\n",
    "# print(connect)\n",
    "coord = mesh_obj.coord_array();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matplotlib import pyplot as plt\n",
    "# xs = [x[0] for x in coord]\n",
    "# ys = [x[1] for x in coord]\n",
    "# plt.scatter(xs, ys)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "strs_ref = pd.read_csv('Data/superconv_gauss_stress_ms_256.csv')\n",
    "# strs_ref = strs_ref.abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(strs_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('Coord/coord_gauss_pt_256.csv')\n",
    "X = X.loc[:, ~X.columns.str.contains('Unnamed')];\n",
    "y = strs_ref;\n",
    "y = y.loc[:, ~y.columns.str.contains('Unnamed')];\n",
    "# y = y.loc[:, ~y.columns.str.contains('x')];\n",
    "# y = y.drop(columns=['x', 'y'])\n",
    "# y = y.loc[:, ~y.columns.str.contains('y')];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X.head())\n",
    "# print(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krishna/Desktop/btp_499_code/btp_env/lib/python3.10/site-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X)\n",
    "scaled_x = scaler.transform(X)\n",
    "scaled_test = scaler.transform(coord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X.head());\n",
    "# print(scaled_x);\n",
    "# print(scaled_test);\n",
    "# print(len(scaled_x));\n",
    "# print(len(scaled_test));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ANN one model in whole domain for 3 output layer\n",
    "\n",
    "model1 = Sequential()\n",
    "model1.add(Dense(units=50,  activation='relu'))\n",
    "model1.add(Dense(units=40, activation='relu'))\n",
    "model1.add(Dense(units=30, activation='relu'))\n",
    "model1.add(Dense(units=20, activation='relu'))\n",
    "model1.add(Dense(units=10, activation='relu'))\n",
    "model1.add(Dense(units=3, activation='relu'))\n",
    "model1.compile(\n",
    "    loss='mse', optimizer=tf.keras.optimizers.Adam(learning_rate=0.01))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "461/461 [==============================] - 9s 10ms/step - loss: 0.2050 - val_loss: 0.6390\n",
      "Epoch 2/300\n",
      "461/461 [==============================] - 3s 7ms/step - loss: 0.0710 - val_loss: 0.2705\n",
      "Epoch 3/300\n",
      "461/461 [==============================] - 3s 7ms/step - loss: 0.0700 - val_loss: 0.2348\n",
      "Epoch 4/300\n",
      "461/461 [==============================] - 3s 7ms/step - loss: 0.0696 - val_loss: 0.2011\n",
      "Epoch 5/300\n",
      "461/461 [==============================] - 3s 7ms/step - loss: 0.0692 - val_loss: 0.2218\n",
      "Epoch 6/300\n",
      "461/461 [==============================] - 3s 7ms/step - loss: 0.0691 - val_loss: 0.1719\n",
      "Epoch 7/300\n",
      "461/461 [==============================] - 3s 7ms/step - loss: 0.0689 - val_loss: 0.1691\n",
      "Epoch 8/300\n",
      "461/461 [==============================] - 3s 7ms/step - loss: 0.0688 - val_loss: 0.1489\n",
      "Epoch 9/300\n",
      "461/461 [==============================] - 3s 7ms/step - loss: 0.0688 - val_loss: 0.1428\n",
      "Epoch 10/300\n",
      "461/461 [==============================] - 4s 8ms/step - loss: 0.0686 - val_loss: 0.1496\n",
      "Epoch 11/300\n",
      "461/461 [==============================] - 4s 8ms/step - loss: 0.0687 - val_loss: 0.1577\n",
      "Epoch 12/300\n",
      "461/461 [==============================] - 3s 8ms/step - loss: 0.0688 - val_loss: 0.1522\n",
      "Epoch 13/300\n",
      "461/461 [==============================] - 4s 8ms/step - loss: 0.0686 - val_loss: 0.1660\n",
      "Epoch 14/300\n",
      "461/461 [==============================] - 3s 7ms/step - loss: 0.0686 - val_loss: 0.1497\n",
      "Epoch 15/300\n",
      "461/461 [==============================] - 3s 7ms/step - loss: 0.0684 - val_loss: 0.1780\n",
      "Epoch 16/300\n",
      "461/461 [==============================] - 4s 8ms/step - loss: 0.0685 - val_loss: 0.1576\n",
      "Epoch 17/300\n",
      "461/461 [==============================] - 4s 8ms/step - loss: 0.0686 - val_loss: 0.1937\n",
      "Epoch 18/300\n",
      "461/461 [==============================] - 3s 8ms/step - loss: 0.0685 - val_loss: 0.1441\n",
      "Epoch 19/300\n",
      "461/461 [==============================] - 4s 8ms/step - loss: 0.0685 - val_loss: 0.1313\n",
      "Epoch 20/300\n",
      "461/461 [==============================] - 3s 7ms/step - loss: 0.0685 - val_loss: 0.1665\n",
      "Epoch 21/300\n",
      "461/461 [==============================] - 3s 7ms/step - loss: 0.0685 - val_loss: 0.1583\n",
      "Epoch 22/300\n",
      "461/461 [==============================] - 3s 7ms/step - loss: 0.0684 - val_loss: 0.1727\n",
      "Epoch 23/300\n",
      "461/461 [==============================] - 3s 7ms/step - loss: 0.0684 - val_loss: 0.1478\n",
      "Epoch 24/300\n",
      "461/461 [==============================] - 3s 7ms/step - loss: 0.0685 - val_loss: 0.1736\n",
      "Epoch 25/300\n",
      "461/461 [==============================] - 3s 7ms/step - loss: 0.0685 - val_loss: 0.1533\n",
      "Epoch 26/300\n",
      "461/461 [==============================] - 3s 7ms/step - loss: 0.0684 - val_loss: 0.1781\n",
      "Epoch 27/300\n",
      "461/461 [==============================] - 3s 7ms/step - loss: 0.0684 - val_loss: 0.1474\n",
      "Epoch 28/300\n",
      "461/461 [==============================] - 3s 7ms/step - loss: 0.0685 - val_loss: 0.1562\n",
      "Epoch 29/300\n",
      "461/461 [==============================] - 3s 7ms/step - loss: 0.0683 - val_loss: 0.1503\n",
      "Epoch 30/300\n",
      "461/461 [==============================] - 3s 6ms/step - loss: 0.0684 - val_loss: 0.1514\n",
      "Epoch 31/300\n",
      "461/461 [==============================] - 3s 7ms/step - loss: 0.0684 - val_loss: 0.1433\n",
      "Epoch 32/300\n",
      "461/461 [==============================] - 3s 7ms/step - loss: 0.0683 - val_loss: 0.1413\n",
      "Epoch 33/300\n",
      "461/461 [==============================] - 3s 8ms/step - loss: 0.0683 - val_loss: 0.1352\n",
      "Epoch 34/300\n",
      "461/461 [==============================] - 3s 7ms/step - loss: 0.0684 - val_loss: 0.1397\n",
      "Epoch 35/300\n",
      "461/461 [==============================] - 3s 7ms/step - loss: 0.0683 - val_loss: 0.1316\n",
      "Epoch 36/300\n",
      "461/461 [==============================] - 3s 7ms/step - loss: 0.0683 - val_loss: 0.1405\n",
      "Epoch 37/300\n",
      "461/461 [==============================] - 3s 7ms/step - loss: 0.0684 - val_loss: 0.1378\n",
      "Epoch 38/300\n",
      "461/461 [==============================] - 3s 8ms/step - loss: 0.0683 - val_loss: 0.1339\n",
      "Epoch 39/300\n",
      "461/461 [==============================] - 4s 8ms/step - loss: 0.0682 - val_loss: 0.1318\n",
      "Epoch 40/300\n",
      "461/461 [==============================] - 5s 11ms/step - loss: 0.0684 - val_loss: 0.1318\n",
      "Epoch 41/300\n",
      "461/461 [==============================] - 4s 10ms/step - loss: 0.0683 - val_loss: 0.1425\n",
      "Epoch 42/300\n",
      "461/461 [==============================] - 4s 9ms/step - loss: 0.0682 - val_loss: 0.1374\n",
      "Epoch 43/300\n",
      "461/461 [==============================] - 4s 10ms/step - loss: 0.0683 - val_loss: 0.1383\n",
      "Epoch 44/300\n",
      "461/461 [==============================] - 4s 9ms/step - loss: 0.0683 - val_loss: 0.1347\n",
      "Epoch 45/300\n",
      "461/461 [==============================] - 3s 7ms/step - loss: 0.0683 - val_loss: 0.1336\n",
      "Epoch 46/300\n",
      "461/461 [==============================] - 3s 7ms/step - loss: 0.0683 - val_loss: 0.1360\n",
      "Epoch 47/300\n",
      "461/461 [==============================] - 3s 7ms/step - loss: 0.0683 - val_loss: 0.1385\n",
      "Epoch 48/300\n",
      "461/461 [==============================] - 3s 7ms/step - loss: 0.0682 - val_loss: 0.1374\n",
      "Epoch 49/300\n",
      "461/461 [==============================] - 3s 7ms/step - loss: 0.0683 - val_loss: 0.1372\n",
      "Epoch 50/300\n",
      "461/461 [==============================] - 3s 7ms/step - loss: 0.0683 - val_loss: 0.1413\n",
      "Epoch 51/300\n",
      "461/461 [==============================] - 3s 7ms/step - loss: 0.0683 - val_loss: 0.1389\n",
      "Epoch 52/300\n",
      "461/461 [==============================] - 3s 7ms/step - loss: 0.0683 - val_loss: 0.1371\n",
      "Epoch 53/300\n",
      "461/461 [==============================] - 3s 7ms/step - loss: 0.0682 - val_loss: 0.1353\n",
      "Epoch 54/300\n",
      "461/461 [==============================] - 3s 7ms/step - loss: 0.0683 - val_loss: 0.1311\n",
      "Epoch 55/300\n",
      "461/461 [==============================] - 3s 7ms/step - loss: 0.0683 - val_loss: 0.1321\n",
      "Epoch 56/300\n",
      "461/461 [==============================] - 3s 7ms/step - loss: 0.0683 - val_loss: 0.1324\n",
      "Epoch 57/300\n",
      "461/461 [==============================] - 3s 7ms/step - loss: 0.0683 - val_loss: 0.1280\n",
      "Epoch 58/300\n",
      "461/461 [==============================] - 3s 7ms/step - loss: 0.0683 - val_loss: 0.1308\n",
      "Epoch 59/300\n",
      "461/461 [==============================] - 3s 7ms/step - loss: 0.0683 - val_loss: 0.1299\n",
      "Epoch 60/300\n",
      "461/461 [==============================] - 3s 7ms/step - loss: 0.0683 - val_loss: 0.1373\n",
      "Epoch 61/300\n",
      "461/461 [==============================] - 3s 7ms/step - loss: 0.0683 - val_loss: 0.1352\n",
      "Epoch 62/300\n",
      "461/461 [==============================] - 3s 7ms/step - loss: 0.0683 - val_loss: 0.1373\n",
      "Epoch 63/300\n",
      "461/461 [==============================] - 3s 7ms/step - loss: 0.0682 - val_loss: 0.1332\n",
      "Epoch 64/300\n",
      "461/461 [==============================] - 3s 7ms/step - loss: 0.0683 - val_loss: 0.1357\n",
      "Epoch 65/300\n",
      "461/461 [==============================] - 3s 7ms/step - loss: 0.0682 - val_loss: 0.1353\n",
      "Epoch 66/300\n",
      "461/461 [==============================] - 3s 7ms/step - loss: 0.0682 - val_loss: 0.1336\n",
      "Epoch 67/300\n",
      "461/461 [==============================] - 3s 7ms/step - loss: 0.0682 - val_loss: 0.1300\n",
      "Epoch 68/300\n",
      "461/461 [==============================] - 3s 7ms/step - loss: 0.0683 - val_loss: 0.1366\n",
      "Epoch 69/300\n",
      "461/461 [==============================] - 3s 7ms/step - loss: 0.0682 - val_loss: 0.1292\n",
      "Epoch 70/300\n",
      "461/461 [==============================] - 3s 7ms/step - loss: 0.0682 - val_loss: 0.1278\n",
      "Epoch 71/300\n",
      "461/461 [==============================] - 3s 7ms/step - loss: 0.0682 - val_loss: 0.1336\n",
      "Epoch 72/300\n",
      "461/461 [==============================] - 3s 7ms/step - loss: 0.0682 - val_loss: 0.1299\n",
      "Epoch 73/300\n",
      "461/461 [==============================] - 3s 7ms/step - loss: 0.0683 - val_loss: 0.1278\n",
      "Epoch 74/300\n",
      "461/461 [==============================] - 3s 7ms/step - loss: 0.0682 - val_loss: 0.1325\n",
      "Epoch 75/300\n",
      "461/461 [==============================] - 4s 8ms/step - loss: 0.0682 - val_loss: 0.1272\n",
      "Epoch 76/300\n",
      "461/461 [==============================] - 3s 7ms/step - loss: 0.0682 - val_loss: 0.1314\n",
      "Epoch 77/300\n",
      "461/461 [==============================] - 4s 8ms/step - loss: 0.0682 - val_loss: 0.1314\n",
      "Epoch 78/300\n",
      "461/461 [==============================] - 3s 7ms/step - loss: 0.0682 - val_loss: 0.1329\n",
      "Epoch 79/300\n",
      "461/461 [==============================] - 3s 7ms/step - loss: 0.0682 - val_loss: 0.1265\n",
      "Epoch 80/300\n",
      "461/461 [==============================] - 3s 7ms/step - loss: 0.0683 - val_loss: 0.1328\n",
      "Epoch 81/300\n",
      "461/461 [==============================] - 3s 7ms/step - loss: 0.0682 - val_loss: 0.1305\n",
      "Epoch 82/300\n",
      "461/461 [==============================] - 3s 7ms/step - loss: 0.0683 - val_loss: 0.1315\n",
      "Epoch 83/300\n",
      "461/461 [==============================] - 3s 7ms/step - loss: 0.0682 - val_loss: 0.1331\n",
      "Epoch 84/300\n",
      "461/461 [==============================] - 3s 7ms/step - loss: 0.0682 - val_loss: 0.1350\n",
      "Epoch 85/300\n",
      "461/461 [==============================] - 3s 7ms/step - loss: 0.0682 - val_loss: 0.1307\n",
      "Epoch 86/300\n",
      "461/461 [==============================] - 3s 7ms/step - loss: 0.0682 - val_loss: 0.1286\n",
      "Epoch 87/300\n",
      "461/461 [==============================] - 3s 7ms/step - loss: 0.0682 - val_loss: 0.1284\n",
      "Epoch 88/300\n",
      "461/461 [==============================] - 3s 7ms/step - loss: 0.0683 - val_loss: 0.1308\n",
      "Epoch 89/300\n",
      "461/461 [==============================] - 3s 7ms/step - loss: 0.0682 - val_loss: 0.1300\n",
      "Epoch 90/300\n",
      "461/461 [==============================] - 3s 7ms/step - loss: 0.0682 - val_loss: 0.1333\n",
      "Epoch 91/300\n",
      "461/461 [==============================] - 3s 7ms/step - loss: 0.0682 - val_loss: 0.1302\n",
      "Epoch 92/300\n",
      "461/461 [==============================] - 3s 7ms/step - loss: 0.0683 - val_loss: 0.1319\n",
      "Epoch 93/300\n",
      "461/461 [==============================] - 3s 7ms/step - loss: 0.0682 - val_loss: 0.1290\n",
      "Epoch 94/300\n",
      "461/461 [==============================] - 3s 7ms/step - loss: 0.0682 - val_loss: 0.1298\n",
      "Epoch 95/300\n",
      "461/461 [==============================] - 3s 7ms/step - loss: 0.0682 - val_loss: 0.1265\n",
      "Epoch 96/300\n",
      "461/461 [==============================] - 3s 7ms/step - loss: 0.0682 - val_loss: 0.1276\n",
      "Epoch 97/300\n",
      "461/461 [==============================] - 3s 7ms/step - loss: 0.0682 - val_loss: 0.1297\n",
      "Epoch 98/300\n",
      "461/461 [==============================] - 3s 7ms/step - loss: 0.0682 - val_loss: 0.1287\n",
      "Epoch 99/300\n",
      "461/461 [==============================] - 3s 7ms/step - loss: 0.0683 - val_loss: 0.1245\n",
      "Epoch 100/300\n",
      "461/461 [==============================] - 3s 8ms/step - loss: 0.0682 - val_loss: 0.1221\n",
      "Epoch 101/300\n",
      "461/461 [==============================] - 3s 6ms/step - loss: 0.0682 - val_loss: 0.1307\n",
      "Epoch 102/300\n",
      "461/461 [==============================] - 3s 6ms/step - loss: 0.0682 - val_loss: 0.1269\n",
      "Epoch 103/300\n",
      "461/461 [==============================] - 2s 5ms/step - loss: 0.0682 - val_loss: 0.1273\n",
      "Epoch 104/300\n",
      "461/461 [==============================] - 3s 6ms/step - loss: 0.0682 - val_loss: 0.1306\n",
      "Epoch 105/300\n",
      "461/461 [==============================] - 3s 6ms/step - loss: 0.0682 - val_loss: 0.1329\n",
      "Epoch 106/300\n",
      "461/461 [==============================] - 3s 6ms/step - loss: 0.0683 - val_loss: 0.1274\n",
      "Epoch 107/300\n",
      "461/461 [==============================] - 3s 6ms/step - loss: 0.0682 - val_loss: 0.1244\n",
      "Epoch 108/300\n",
      "461/461 [==============================] - 2s 5ms/step - loss: 0.0682 - val_loss: 0.1333\n",
      "Epoch 109/300\n",
      "461/461 [==============================] - 2s 5ms/step - loss: 0.0682 - val_loss: 0.1287\n",
      "Epoch 110/300\n",
      "461/461 [==============================] - 2s 4ms/step - loss: 0.0683 - val_loss: 0.1347\n",
      "Epoch 111/300\n",
      "461/461 [==============================] - 2s 5ms/step - loss: 0.0682 - val_loss: 0.1289\n",
      "Epoch 112/300\n",
      "461/461 [==============================] - 2s 5ms/step - loss: 0.0682 - val_loss: 0.1280\n",
      "Epoch 113/300\n",
      "461/461 [==============================] - 2s 5ms/step - loss: 0.0682 - val_loss: 0.1288\n",
      "Epoch 114/300\n",
      "461/461 [==============================] - 2s 5ms/step - loss: 0.0682 - val_loss: 0.1256\n",
      "Epoch 115/300\n",
      "461/461 [==============================] - 2s 4ms/step - loss: 0.0683 - val_loss: 0.1265\n",
      "Epoch 116/300\n",
      "461/461 [==============================] - 2s 5ms/step - loss: 0.0682 - val_loss: 0.1252\n",
      "Epoch 117/300\n",
      "461/461 [==============================] - 2s 5ms/step - loss: 0.0682 - val_loss: 0.1303\n",
      "Epoch 118/300\n",
      "461/461 [==============================] - 2s 5ms/step - loss: 0.0682 - val_loss: 0.1263\n",
      "Epoch 119/300\n",
      "461/461 [==============================] - 2s 4ms/step - loss: 0.0682 - val_loss: 0.1235\n",
      "Epoch 120/300\n",
      "461/461 [==============================] - 2s 5ms/step - loss: 0.0682 - val_loss: 0.1275\n",
      "Epoch 121/300\n",
      "461/461 [==============================] - 2s 4ms/step - loss: 0.0682 - val_loss: 0.1284\n",
      "Epoch 122/300\n",
      "461/461 [==============================] - 2s 4ms/step - loss: 0.0682 - val_loss: 0.1283\n",
      "Epoch 123/300\n",
      "461/461 [==============================] - 2s 5ms/step - loss: 0.0682 - val_loss: 0.1251\n",
      "Epoch 124/300\n",
      "461/461 [==============================] - 2s 5ms/step - loss: 0.0683 - val_loss: 0.1274\n",
      "Epoch 125/300\n",
      "461/461 [==============================] - 2s 4ms/step - loss: 0.0682 - val_loss: 0.1271\n",
      "Epoch 126/300\n",
      "461/461 [==============================] - 2s 5ms/step - loss: 0.0649 - val_loss: 0.0872\n",
      "Epoch 127/300\n",
      "461/461 [==============================] - 2s 5ms/step - loss: 0.0618 - val_loss: 0.0548\n",
      "Epoch 128/300\n",
      "461/461 [==============================] - 2s 5ms/step - loss: 0.0616 - val_loss: 0.0693\n",
      "Epoch 129/300\n",
      "461/461 [==============================] - 2s 5ms/step - loss: 0.0615 - val_loss: 0.0693\n",
      "Epoch 130/300\n",
      "461/461 [==============================] - 2s 4ms/step - loss: 0.0615 - val_loss: 0.0667\n",
      "Epoch 131/300\n",
      "461/461 [==============================] - 2s 4ms/step - loss: 0.0615 - val_loss: 0.0427\n",
      "Epoch 132/300\n",
      "461/461 [==============================] - 2s 5ms/step - loss: 0.0615 - val_loss: 0.0468\n",
      "Epoch 133/300\n",
      "461/461 [==============================] - 2s 4ms/step - loss: 0.0615 - val_loss: 0.0473\n",
      "Epoch 134/300\n",
      "461/461 [==============================] - 2s 5ms/step - loss: 0.0615 - val_loss: 0.0409\n",
      "Epoch 135/300\n",
      "461/461 [==============================] - 2s 5ms/step - loss: 0.0615 - val_loss: 0.0451\n",
      "Epoch 136/300\n",
      "461/461 [==============================] - 2s 5ms/step - loss: 0.0615 - val_loss: 0.0391\n",
      "Epoch 137/300\n",
      "461/461 [==============================] - 2s 5ms/step - loss: 0.0615 - val_loss: 0.0560\n",
      "Epoch 138/300\n",
      "461/461 [==============================] - 2s 5ms/step - loss: 0.0615 - val_loss: 0.0615\n",
      "Epoch 139/300\n",
      "461/461 [==============================] - 2s 5ms/step - loss: 0.0615 - val_loss: 0.0558\n",
      "Epoch 140/300\n",
      "461/461 [==============================] - 2s 5ms/step - loss: 0.0615 - val_loss: 0.0473\n",
      "Epoch 141/300\n",
      "461/461 [==============================] - 2s 5ms/step - loss: 0.0615 - val_loss: 0.0450\n",
      "Epoch 142/300\n",
      "461/461 [==============================] - 3s 6ms/step - loss: 0.0614 - val_loss: 0.0496\n",
      "Epoch 143/300\n",
      "461/461 [==============================] - 3s 6ms/step - loss: 0.0615 - val_loss: 0.0495\n",
      "Epoch 144/300\n",
      "461/461 [==============================] - 2s 5ms/step - loss: 0.0615 - val_loss: 0.0562\n",
      "Epoch 145/300\n",
      "461/461 [==============================] - 3s 6ms/step - loss: 0.0615 - val_loss: 0.0418\n",
      "Epoch 146/300\n",
      "461/461 [==============================] - 3s 6ms/step - loss: 0.0615 - val_loss: 0.0416\n",
      "Epoch 147/300\n",
      "461/461 [==============================] - 2s 5ms/step - loss: 0.0615 - val_loss: 0.0458\n",
      "Epoch 148/300\n",
      "461/461 [==============================] - 2s 5ms/step - loss: 0.0614 - val_loss: 0.0507\n",
      "Epoch 149/300\n",
      "461/461 [==============================] - 2s 5ms/step - loss: 0.0615 - val_loss: 0.0411\n",
      "Epoch 150/300\n",
      "461/461 [==============================] - 2s 5ms/step - loss: 0.0615 - val_loss: 0.0492\n",
      "Epoch 151/300\n",
      "461/461 [==============================] - 2s 5ms/step - loss: 0.0615 - val_loss: 0.0417\n",
      "Epoch 152/300\n",
      "461/461 [==============================] - 2s 5ms/step - loss: 0.0615 - val_loss: 0.0440\n",
      "Epoch 153/300\n",
      "461/461 [==============================] - 2s 5ms/step - loss: 0.0615 - val_loss: 0.0396\n",
      "Epoch 154/300\n",
      "461/461 [==============================] - 2s 5ms/step - loss: 0.0615 - val_loss: 0.0373\n",
      "Epoch 155/300\n",
      "461/461 [==============================] - 2s 5ms/step - loss: 0.0615 - val_loss: 0.0417\n",
      "Epoch 156/300\n",
      "461/461 [==============================] - 2s 5ms/step - loss: 0.0615 - val_loss: 0.0366\n",
      "Epoch 157/300\n",
      "461/461 [==============================] - 2s 5ms/step - loss: 0.0615 - val_loss: 0.0412\n",
      "Epoch 158/300\n",
      "461/461 [==============================] - 3s 6ms/step - loss: 0.0614 - val_loss: 0.0433\n",
      "Epoch 159/300\n",
      "461/461 [==============================] - 2s 5ms/step - loss: 0.0615 - val_loss: 0.0448\n",
      "Epoch 160/300\n",
      "461/461 [==============================] - 2s 5ms/step - loss: 0.0615 - val_loss: 0.0335\n",
      "Epoch 161/300\n",
      "461/461 [==============================] - 2s 5ms/step - loss: 0.0615 - val_loss: 0.0437\n",
      "Epoch 162/300\n",
      "461/461 [==============================] - 3s 6ms/step - loss: 0.0614 - val_loss: 0.0383\n",
      "Epoch 163/300\n",
      "461/461 [==============================] - 2s 5ms/step - loss: 0.0615 - val_loss: 0.0516\n",
      "Epoch 164/300\n",
      "461/461 [==============================] - 2s 5ms/step - loss: 0.0614 - val_loss: 0.0412\n",
      "Epoch 165/300\n",
      "461/461 [==============================] - 2s 5ms/step - loss: 0.0615 - val_loss: 0.0374\n",
      "Epoch 166/300\n",
      "461/461 [==============================] - 2s 5ms/step - loss: 0.0615 - val_loss: 0.0420\n",
      "Epoch 167/300\n",
      "461/461 [==============================] - 3s 5ms/step - loss: 0.0615 - val_loss: 0.0396\n",
      "Epoch 168/300\n",
      "461/461 [==============================] - 3s 6ms/step - loss: 0.0614 - val_loss: 0.0373\n",
      "Epoch 169/300\n",
      "461/461 [==============================] - 3s 7ms/step - loss: 0.0614 - val_loss: 0.0422\n",
      "Epoch 170/300\n",
      "461/461 [==============================] - 3s 6ms/step - loss: 0.0614 - val_loss: 0.0370\n",
      "Epoch 171/300\n",
      "461/461 [==============================] - 3s 6ms/step - loss: 0.0615 - val_loss: 0.0390\n",
      "Epoch 172/300\n",
      "461/461 [==============================] - 3s 7ms/step - loss: 0.0614 - val_loss: 0.0420\n",
      "Epoch 173/300\n",
      "461/461 [==============================] - 3s 6ms/step - loss: 0.0615 - val_loss: 0.0413\n",
      "Epoch 174/300\n",
      "461/461 [==============================] - 3s 6ms/step - loss: 0.0614 - val_loss: 0.0369\n",
      "Epoch 175/300\n",
      "461/461 [==============================] - 3s 6ms/step - loss: 0.0615 - val_loss: 0.0488\n",
      "Epoch 176/300\n",
      "461/461 [==============================] - 3s 7ms/step - loss: 0.0614 - val_loss: 0.0353\n",
      "Epoch 177/300\n",
      "461/461 [==============================] - 3s 6ms/step - loss: 0.0614 - val_loss: 0.0457\n",
      "Epoch 178/300\n",
      "461/461 [==============================] - 3s 6ms/step - loss: 0.0615 - val_loss: 0.0417\n",
      "Epoch 179/300\n",
      "461/461 [==============================] - 3s 6ms/step - loss: 0.0614 - val_loss: 0.0368\n",
      "Epoch 180/300\n",
      "461/461 [==============================] - 3s 6ms/step - loss: 0.0614 - val_loss: 0.0447\n",
      "Epoch 181/300\n",
      "461/461 [==============================] - 3s 6ms/step - loss: 0.0614 - val_loss: 0.0413\n",
      "Epoch 182/300\n",
      "461/461 [==============================] - 3s 6ms/step - loss: 0.0615 - val_loss: 0.0400\n",
      "Epoch 183/300\n",
      "461/461 [==============================] - 3s 6ms/step - loss: 0.0615 - val_loss: 0.0400\n",
      "Epoch 184/300\n",
      "461/461 [==============================] - 3s 6ms/step - loss: 0.0614 - val_loss: 0.0399\n",
      "Epoch 185/300\n",
      "461/461 [==============================] - 3s 6ms/step - loss: 0.0614 - val_loss: 0.0432\n",
      "Epoch 186/300\n",
      "461/461 [==============================] - 3s 6ms/step - loss: 0.0615 - val_loss: 0.0402\n",
      "Epoch 187/300\n",
      "461/461 [==============================] - 3s 5ms/step - loss: 0.0614 - val_loss: 0.0391\n",
      "Epoch 188/300\n",
      "461/461 [==============================] - 3s 6ms/step - loss: 0.0615 - val_loss: 0.0472\n",
      "Epoch 189/300\n",
      "461/461 [==============================] - 3s 5ms/step - loss: 0.0614 - val_loss: 0.0415\n",
      "Epoch 190/300\n",
      "461/461 [==============================] - 3s 6ms/step - loss: 0.0614 - val_loss: 0.0393\n",
      "Epoch 191/300\n",
      "461/461 [==============================] - 2s 5ms/step - loss: 0.0614 - val_loss: 0.0447\n",
      "Epoch 192/300\n",
      "461/461 [==============================] - 3s 6ms/step - loss: 0.0615 - val_loss: 0.0447\n",
      "Epoch 193/300\n",
      "461/461 [==============================] - 3s 6ms/step - loss: 0.0614 - val_loss: 0.0423\n",
      "Epoch 194/300\n",
      "461/461 [==============================] - 3s 6ms/step - loss: 0.0614 - val_loss: 0.0409\n",
      "Epoch 195/300\n",
      "461/461 [==============================] - 3s 6ms/step - loss: 0.0615 - val_loss: 0.0449\n",
      "Epoch 196/300\n",
      "461/461 [==============================] - 3s 6ms/step - loss: 0.0614 - val_loss: 0.0503\n",
      "Epoch 197/300\n",
      "461/461 [==============================] - 3s 6ms/step - loss: 0.0612 - val_loss: 0.0418\n",
      "Epoch 198/300\n",
      "461/461 [==============================] - 3s 6ms/step - loss: 0.0610 - val_loss: 0.0410\n",
      "Epoch 199/300\n",
      "461/461 [==============================] - 3s 6ms/step - loss: 0.0609 - val_loss: 0.0382\n",
      "Epoch 200/300\n",
      "461/461 [==============================] - 3s 7ms/step - loss: 0.0609 - val_loss: 0.0383\n",
      "Epoch 201/300\n",
      "461/461 [==============================] - 3s 6ms/step - loss: 0.0609 - val_loss: 0.0344\n",
      "Epoch 202/300\n",
      "461/461 [==============================] - 3s 7ms/step - loss: 0.0610 - val_loss: 0.0394\n",
      "Epoch 203/300\n",
      "461/461 [==============================] - 3s 6ms/step - loss: 0.0609 - val_loss: 0.0483\n",
      "Epoch 204/300\n",
      "461/461 [==============================] - 3s 6ms/step - loss: 0.0609 - val_loss: 0.0464\n",
      "Epoch 205/300\n",
      "461/461 [==============================] - 3s 7ms/step - loss: 0.0609 - val_loss: 0.0446\n",
      "Epoch 206/300\n",
      "461/461 [==============================] - 3s 6ms/step - loss: 0.0609 - val_loss: 0.0468\n",
      "Epoch 207/300\n",
      "461/461 [==============================] - 3s 6ms/step - loss: 0.0609 - val_loss: 0.0463\n",
      "Epoch 208/300\n",
      "461/461 [==============================] - 3s 6ms/step - loss: 0.0609 - val_loss: 0.0436\n",
      "Epoch 209/300\n",
      "461/461 [==============================] - 3s 6ms/step - loss: 0.0609 - val_loss: 0.0465\n",
      "Epoch 210/300\n",
      "461/461 [==============================] - 3s 6ms/step - loss: 0.0610 - val_loss: 0.0512\n",
      "Epoch 210: early stopping\n"
     ]
    }
   ],
   "source": [
    " es = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss',  mode = 'min', verbose = 1, patience = 50);\n",
    " np.random.seed(1)\n",
    " history = model1.fit(x = scaled_x, y = y, batch_size=256, epochs=300, verbose = 1, validation_split = 0.1, callbacks= [es]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 'x_y_xy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss = pd.DataFrame(model1.history.history);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# plt.plot(history.history['loss'])\n",
    "# plt.plot(history.history['val_loss'])\n",
    "# plt.title('train_loss', fontsize=15)\n",
    "# plt.ylabel('Loss', fontsize=15)\n",
    "# plt.xlabel('Epoch', fontsize=15)\n",
    "# plt.legend(['train', 'val'], loc='upper right')\n",
    "# plt.xticks(fontsize=15)\n",
    "# plt.yticks(fontsize=15)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving train model with different optimizer.\n",
    "# model_json = model1.to_json()\n",
    "# with open('Model/model1_'+var+'.json', 'w') as json_file:\n",
    "#     json_file.write(model_json)\n",
    "\n",
    "# #serialize weights to HDF5 file\n",
    "# model1.save_weights('Model/model1_'+var+'.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load json and create model\n",
    "json_file = open('Model/model1_x_y_xy.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json);\n",
    "\n",
    "# #load weights into new model\n",
    "loaded_model.load_weights('Model/model1_x_y_xy.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stress calculation at Gauss points\n",
    "stress = np.zeros((nel, ngp2d*ngp2d, 3))\n",
    "strains = np.zeros((nel, ngp2d*ngp2d, 3))\n",
    "\n",
    "for i in range(nel):\n",
    "    stress_i_g = np.zeros((ngp2d*ngp2d, 3))\n",
    "    strains_i_g = np.zeros((ngp2d*ngp2d, 3))\n",
    "\n",
    "    stress_i_g, strains_i_g = stress_gauss.get_element_stress(\n",
    "        i, ngp2d, el_type, connect, coord, u, C)\n",
    "\n",
    "    stress[i][:][:] = stress_i_g\n",
    "    strains[i][:][:] = strains_i_g.reshape((1, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcuation of gauss coordinates.\n",
    "gauss_coords = np.zeros((nel, ngp2d*ngp2d, 2))\n",
    "gp, weights = quadrature.quadrature(ngp2d)\n",
    "for i in range(nel):\n",
    "    node = connect[i, :]\n",
    "    vertex_coord = coord[node, :].reshape(-1)\n",
    "    gauss_coords[i][:][:] = gauss_pt_coord.gauss_pts(\n",
    "        ngp2d, vertex_coord, gp, el_type)\n",
    "gauss_coords = gauss_coords.reshape(gauss_coords.shape[0], -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creation of patches for spr_stress;\n",
    "patch, n_patches, int_nodes = patch_n_int_nodes.patch_n_int_nodes_plat_with_hole(ms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spr_stress STRESS Calculations\n",
    "stress_spr = spr_stress.spr_plat_with_hole(gauss_coords, coord, connect, stress,\n",
    "                     int_nodes, n_patches, patch, ms)\n",
    "# stress_spr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Directly calculated stress\n",
    "stress_dc, strain_dc = stress_nodes_dc.stress_dc(\n",
    "    connect, coord, u, nel, el_type, C);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#outter points in\n",
    "sp = []\n",
    "# print(ms)\n",
    "# ms = 4\n",
    "temp = ms+1\n",
    "for i in range(2*ms-1):\n",
    "    sp.append(temp)\n",
    "    sp.append(temp+ms)\n",
    "    temp = temp+ms+1\n",
    "for i in range(ms+1):\n",
    "    sp.append(temp)\n",
    "    temp = temp+1\n",
    "\n",
    "for i in range(ms+1):\n",
    "    sp.append(i)\n",
    "\n",
    "sp = sorted(sp)\n",
    "# print(sp);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_corner = coord[sp]\n",
    "# print(coord_corner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krishna/Desktop/btp_499_code/btp_env/lib/python3.10/site-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "scaled_test_corner = scaler.transform(coord_corner)\n",
    "# scaled_test_corner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_stress = pd.read_csv('ref_stress/ref_stress_for_ms_5_from_320.csv');\n",
    "ref_stress = ref_stress.loc[:, ~ref_stress.columns.str.contains('^Unnamed')];\n",
    "ref_stress = ref_stress.drop(columns=['x', 'y'])\n",
    "# print(ref_stress)\n",
    "\n",
    "ref_stress = ref_stress.to_numpy();\n",
    "# ref_stress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ref_stress.T\n",
    "# print(len(a));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = stress_spr.T\n",
    "# print(len(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_spr_abs = np.abs((a-b));\n",
    "err_spr_perc = np.abs((a-b)/a);\n",
    "err_dc_abs = np.abs((a-stress_dc.T));\n",
    "err_dc_perc = np.abs((a-stress_dc.T)/a);\n",
    "# err_spr_abs\n",
    "# err_dc_abs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame(scaled_test, columns =['a', 'b']);\n",
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "c = loaded_model.predict(test);\n",
    "# len(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_ann_abs = np.abs((a-c.T))\n",
    "err_ann_perc = np.abs((a-c.T)/a)\n",
    "# err_ann_abs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "alll = np.concatenate([coord, \n",
    "                        a.reshape(a.T.shape[0], 3), \n",
    "                        b.reshape(b.T.shape[0], 3), \n",
    "                        c.reshape(c.shape[0], 3), \n",
    "                        err_spr_abs.reshape(err_spr_abs.T.shape[0], 3), \n",
    "                        err_ann_abs.reshape(err_ann_abs.T.shape[0],3), \n",
    "                        err_dc_abs.reshape(err_dc_abs.T.shape[0],3),\n",
    "                        err_spr_perc.reshape(err_spr_perc.T.shape[0],3),\n",
    "                        err_ann_perc.reshape(err_ann_perc.T.shape[0],3),\n",
    "                        err_dc_perc.reshape(err_dc_perc.T.shape[0],3) \n",
    "                        ], \n",
    "                        axis = 1);\n",
    "# alll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "xs = [x[0] for x in coord]\n",
    "ys = [x[1] for x in coord]\n",
    "plt.scatter(xs, ys)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               x     y  ref_stress_x  ref_stress_y  ref_stress_xy  \\\n",
      "0   2.000000e+00   0.0     -0.010481  9.569092e-01       1.201440   \n",
      "1   5.600000e+00   0.0      1.278801  1.314046e+00       2.841037   \n",
      "2   9.200000e+00   0.0     -0.034956  2.945819e+00       3.631842   \n",
      "3   1.280000e+01   0.0      3.850629  3.951957e+00       1.333365   \n",
      "4   1.640000e+01   0.0     -0.089738  3.151642e+00       3.707194   \n",
      "..           ...   ...           ...           ...            ...   \n",
      "61  9.797174e-17   3.6      0.064660  1.285945e-02       0.000012   \n",
      "62  7.347881e-17   5.2     -0.628158  3.409312e-01       0.314106   \n",
      "63  4.898587e-17   6.8      0.239362  1.606353e-01       0.000007   \n",
      "64  2.449294e-17   8.4     -0.002644  6.027514e-07       0.000025   \n",
      "65  0.000000e+00  10.0      0.000017  1.932879e-05      -0.000165   \n",
      "\n",
      "    spr_stress_x  spr_stress_y  spr_stress_xy  ann_stress_x  ann_stress_y  \\\n",
      "0      -0.016217      0.013098       0.022988      0.000000           0.0   \n",
      "1       0.013367      0.019995       0.039879      2.271190           0.0   \n",
      "2      -0.010521      0.022752       0.050993      2.883606           0.0   \n",
      "3       0.057357      0.055431       0.039334      3.064341           0.0   \n",
      "4      -0.005518      0.029367       0.057235      3.130401           0.0   \n",
      "..           ...           ...            ...           ...           ...   \n",
      "61     -0.000857      0.005730       0.002674      4.630536           0.0   \n",
      "62     -0.003653     -0.000565       0.000341      3.717340           0.0   \n",
      "63     -0.003203     -0.005005      -0.015456      3.580866           0.0   \n",
      "64     -0.003575      0.002277      -0.000041      3.484732           0.0   \n",
      "65      0.000523      0.002802       0.009640      3.408763           0.0   \n",
      "\n",
      "    ...  err_dc_abs_xy  err_spr_perc_x  err_spr_perc_y  err_spr_perc_xy  \\\n",
      "0   ...       1.268801        0.547284        0.986312         0.980866   \n",
      "1   ...       4.614684        0.989547        0.984784         0.985963   \n",
      "2   ...       3.453235        0.699020        0.992277         0.985960   \n",
      "3   ...       0.483469        0.985104        0.985974         0.970500   \n",
      "4   ...       3.832258        0.938508        0.990682         0.984561   \n",
      "..  ...            ...             ...             ...              ...   \n",
      "61  ...       0.656710        1.013251        0.554423       215.012328   \n",
      "62  ...       0.433478        0.994185        1.001659         0.998915   \n",
      "63  ...       0.333701        1.013379        1.031155      2173.498748   \n",
      "64  ...       2.471204        0.351999     3777.335569         2.601600   \n",
      "65  ...       0.545487       29.281491      143.968479        59.364561   \n",
      "\n",
      "    err_ann_perc_x  err_ann_perc_y  err_ann_perc_xy  err_dc_perc_x  \\\n",
      "0         1.000000        1.373465         1.400125     258.700678   \n",
      "1         1.396261        1.382261         0.116707       0.907602   \n",
      "2         1.000000        0.205729         0.199601      77.074369   \n",
      "3         0.199590        0.200700         1.401159       1.005498   \n",
      "4         1.000000        0.203646         0.199800      30.503711   \n",
      "..             ...             ...              ...            ...   \n",
      "61        1.000000        1.000000         1.000000       3.429232   \n",
      "62        1.000000        1.000000         1.000000       0.612511   \n",
      "63        1.000000        1.000000         1.000000       0.685134   \n",
      "64        1.000000        1.000000         1.000000    6126.724476   \n",
      "65        1.000000        1.000000         1.000000   88596.126346   \n",
      "\n",
      "    err_dc_perc_y  err_dc_perc_xy  \n",
      "0    7.457404e-01        1.056067  \n",
      "1    9.871929e-01        1.624296  \n",
      "2    1.064391e+00        0.950822  \n",
      "3    9.751876e-01        0.362593  \n",
      "4    8.870057e-01        1.033736  \n",
      "..            ...             ...  \n",
      "61   7.217760e+00    53045.312746  \n",
      "62   3.571317e-01        1.380039  \n",
      "63   1.362550e+00    46906.164153  \n",
      "64   7.595208e+06    97581.144409  \n",
      "65   4.974621e+04     3302.494806  \n",
      "\n",
      "[66 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "tdf =pd.DataFrame(alll, columns=['x', \n",
    "                                'y', \n",
    "                                'ref_stress_x',\n",
    "                                'ref_stress_y',\n",
    "                                'ref_stress_xy', \n",
    "                                'spr_stress_x',\n",
    "                                'spr_stress_y',\n",
    "                                'spr_stress_xy', \n",
    "                                'ann_stress_x',\n",
    "                                'ann_stress_y',\n",
    "                                'ann_stress_xy', \n",
    "                                'err_spr_abs_x',\n",
    "                                'err_spr_abs_y',\n",
    "                                'err_spr_abs_xy', \n",
    "                                'err_ann_abs_x',\n",
    "                                'err_ann_abs_y',\n",
    "                                'err_ann_abs_xy', \n",
    "                                'err_dc_abs_x',\n",
    "                                'err_dc_abs_y',\n",
    "                                'err_dc_abs_xy',\n",
    "                                'err_spr_perc_x',\n",
    "                                'err_spr_perc_y',\n",
    "                                'err_spr_perc_xy', \n",
    "                                'err_ann_perc_x',\n",
    "                                'err_ann_perc_y',\n",
    "                                'err_ann_perc_xy', \n",
    "                                'err_dc_perc_x',\n",
    "                                'err_dc_perc_y',\n",
    "                                'err_dc_perc_xy'\n",
    "                                ]);\n",
    "print(tdf);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>ref_stress_x</th>\n",
       "      <th>ref_stress_y</th>\n",
       "      <th>ref_stress_xy</th>\n",
       "      <th>spr_stress_x</th>\n",
       "      <th>spr_stress_y</th>\n",
       "      <th>spr_stress_xy</th>\n",
       "      <th>ann_stress_x</th>\n",
       "      <th>ann_stress_y</th>\n",
       "      <th>...</th>\n",
       "      <th>err_dc_abs_xy</th>\n",
       "      <th>err_spr_perc_x</th>\n",
       "      <th>err_spr_perc_y</th>\n",
       "      <th>err_spr_perc_xy</th>\n",
       "      <th>err_ann_perc_x</th>\n",
       "      <th>err_ann_perc_y</th>\n",
       "      <th>err_ann_perc_xy</th>\n",
       "      <th>err_dc_perc_x</th>\n",
       "      <th>err_dc_perc_y</th>\n",
       "      <th>err_dc_perc_xy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.010481</td>\n",
       "      <td>0.956909</td>\n",
       "      <td>1.201440</td>\n",
       "      <td>-0.016217</td>\n",
       "      <td>0.013098</td>\n",
       "      <td>0.022988</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.268801</td>\n",
       "      <td>0.547284</td>\n",
       "      <td>0.986312</td>\n",
       "      <td>0.980866</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.373465</td>\n",
       "      <td>1.400125</td>\n",
       "      <td>258.700678</td>\n",
       "      <td>0.745740</td>\n",
       "      <td>1.056067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.278801</td>\n",
       "      <td>1.314046</td>\n",
       "      <td>2.841037</td>\n",
       "      <td>0.013367</td>\n",
       "      <td>0.019995</td>\n",
       "      <td>0.039879</td>\n",
       "      <td>2.271190</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.614684</td>\n",
       "      <td>0.989547</td>\n",
       "      <td>0.984784</td>\n",
       "      <td>0.985963</td>\n",
       "      <td>1.396261</td>\n",
       "      <td>1.382261</td>\n",
       "      <td>0.116707</td>\n",
       "      <td>0.907602</td>\n",
       "      <td>0.987193</td>\n",
       "      <td>1.624296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.034956</td>\n",
       "      <td>2.945819</td>\n",
       "      <td>3.631842</td>\n",
       "      <td>-0.010521</td>\n",
       "      <td>0.022752</td>\n",
       "      <td>0.050993</td>\n",
       "      <td>2.883606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.453235</td>\n",
       "      <td>0.699020</td>\n",
       "      <td>0.992277</td>\n",
       "      <td>0.985960</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.205729</td>\n",
       "      <td>0.199601</td>\n",
       "      <td>77.074369</td>\n",
       "      <td>1.064391</td>\n",
       "      <td>0.950822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.850629</td>\n",
       "      <td>3.951957</td>\n",
       "      <td>1.333365</td>\n",
       "      <td>0.057357</td>\n",
       "      <td>0.055431</td>\n",
       "      <td>0.039334</td>\n",
       "      <td>3.064341</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.483469</td>\n",
       "      <td>0.985104</td>\n",
       "      <td>0.985974</td>\n",
       "      <td>0.970500</td>\n",
       "      <td>0.199590</td>\n",
       "      <td>0.200700</td>\n",
       "      <td>1.401159</td>\n",
       "      <td>1.005498</td>\n",
       "      <td>0.975188</td>\n",
       "      <td>0.362593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.089738</td>\n",
       "      <td>3.151642</td>\n",
       "      <td>3.707194</td>\n",
       "      <td>-0.005518</td>\n",
       "      <td>0.029367</td>\n",
       "      <td>0.057235</td>\n",
       "      <td>3.130401</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.832258</td>\n",
       "      <td>0.938508</td>\n",
       "      <td>0.990682</td>\n",
       "      <td>0.984561</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.203646</td>\n",
       "      <td>0.199800</td>\n",
       "      <td>30.503711</td>\n",
       "      <td>0.887006</td>\n",
       "      <td>1.033736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      x    y  ref_stress_x  ref_stress_y  ref_stress_xy  spr_stress_x  \\\n",
       "0   2.0  0.0     -0.010481      0.956909       1.201440     -0.016217   \n",
       "1   5.6  0.0      1.278801      1.314046       2.841037      0.013367   \n",
       "2   9.2  0.0     -0.034956      2.945819       3.631842     -0.010521   \n",
       "3  12.8  0.0      3.850629      3.951957       1.333365      0.057357   \n",
       "4  16.4  0.0     -0.089738      3.151642       3.707194     -0.005518   \n",
       "\n",
       "   spr_stress_y  spr_stress_xy  ann_stress_x  ann_stress_y  ...  \\\n",
       "0      0.013098       0.022988      0.000000           0.0  ...   \n",
       "1      0.019995       0.039879      2.271190           0.0  ...   \n",
       "2      0.022752       0.050993      2.883606           0.0  ...   \n",
       "3      0.055431       0.039334      3.064341           0.0  ...   \n",
       "4      0.029367       0.057235      3.130401           0.0  ...   \n",
       "\n",
       "   err_dc_abs_xy  err_spr_perc_x  err_spr_perc_y  err_spr_perc_xy  \\\n",
       "0       1.268801        0.547284        0.986312         0.980866   \n",
       "1       4.614684        0.989547        0.984784         0.985963   \n",
       "2       3.453235        0.699020        0.992277         0.985960   \n",
       "3       0.483469        0.985104        0.985974         0.970500   \n",
       "4       3.832258        0.938508        0.990682         0.984561   \n",
       "\n",
       "   err_ann_perc_x  err_ann_perc_y  err_ann_perc_xy  err_dc_perc_x  \\\n",
       "0        1.000000        1.373465         1.400125     258.700678   \n",
       "1        1.396261        1.382261         0.116707       0.907602   \n",
       "2        1.000000        0.205729         0.199601      77.074369   \n",
       "3        0.199590        0.200700         1.401159       1.005498   \n",
       "4        1.000000        0.203646         0.199800      30.503711   \n",
       "\n",
       "   err_dc_perc_y  err_dc_perc_xy  \n",
       "0       0.745740        1.056067  \n",
       "1       0.987193        1.624296  \n",
       "2       1.064391        0.950822  \n",
       "3       0.975188        0.362593  \n",
       "4       0.887006        1.033736  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdf.to_csv('Results/all_matlab_train_model1_ref_'+var+'.csv');\n",
    "tdf.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "btp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
